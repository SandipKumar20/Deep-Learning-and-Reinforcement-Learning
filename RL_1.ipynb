{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35cbf29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da20fe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the environment for the reinforcement learning problem\n",
    "class Sample_Environment:\n",
    "    \"\"\"A sample environment that provides observations, actions, and rewards.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the environment, setting the number of steps available.\"\"\"\n",
    "        self.steps_left = 20\n",
    "\n",
    "    def get_observation(self)-> List[float]:\n",
    "        \"\"\"Return the current observation of the environment. In this case, it's a fixed list.\"\"\"\n",
    "        return [0.0, 0.0, 0.0]\n",
    "    \n",
    "    def get_actions(self) -> List[int]:\n",
    "        \"\"\"Return the list of possible actions the agent can take.\"\"\"\n",
    "        return [0, 1]\n",
    "    \n",
    "    def is_done(self) -> bool:\n",
    "        \"\"\"Check if the episode is finished (i.e., no steps are left).\"\"\"\n",
    "        return self.steps_left == 0\n",
    "    \n",
    "    def action(self, action: int) -> float:\n",
    "        \"\"\" \n",
    "        Performs an action in the environment.\n",
    "        Returns a random reward regardless of the action taken.\n",
    "        \"\"\"\n",
    "        if self.is_done():\n",
    "            raise ValueError(\"Cannot take action, environment is done.\")\n",
    "        self.steps_left -= 1\n",
    "        return np.random.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9c90bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the agent that interacts with the environment\n",
    "class Sample_Agent:\n",
    "    \"\"\"A sample agent that takes random actions in the environment.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the agent and set the total_reward to 0.\"\"\"\n",
    "        self.total_reward = 0.0\n",
    "\n",
    "    def step(self, env: Sample_Environment):\n",
    "        \"\"\"\n",
    "        Take a single step in the environment.\n",
    "        The agent gets the current observation and available actions, \n",
    "        chooses an action randomly, and collects the reward.\n",
    "        \"\"\"\n",
    "        current_observation = env.get_observation()\n",
    "        actions = env.get_actions()\n",
    "        # Choose a random action from the list of available actions.\n",
    "        reward = env.action(np.random.choice(actions))\n",
    "        self.total_reward += reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13101fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward collected:  10.055\n",
      "Environment is done.\n"
     ]
    }
   ],
   "source": [
    "# Main execution block\n",
    "if __name__ == \"__main__\":\n",
    "    # Create instances of the environment and the agent\n",
    "    env = Sample_Environment()\n",
    "    agent = Sample_Agent()\n",
    "\n",
    "    # Loop until the environment signals that it's done\n",
    "    while not env.is_done():\n",
    "        # The agent takes a step in the environment\n",
    "        agent.step(env)\n",
    "        \n",
    "    # Print the total reward collected by the agent\n",
    "    print(f\"Total reward collected: {agent.total_reward: .3f}\")\n",
    "    print(\"Environment is done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99edf7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.02791194, 0.04834921, 0.04127705, 0.01171807], dtype=float32), {})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "obs, info = env.reset()\n",
    "obs, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9430402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2226d06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8               -inf -0.41887903        -inf], [4.8               inf 0.41887903        inf], (4,), float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f164e07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.02887893,  0.24285562,  0.04151141, -0.26766104], dtype=float32),\n",
       " 1.0,\n",
       " False,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dab9201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.03373604, 0.04716659, 0.03615819, 0.0378205 ], dtype=float32),\n",
       " 1.0,\n",
       " False,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54ef94d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()  # Take a random action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3258c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8f87faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.4572866 , -0.6179386 , -0.10923515, -0.55597115], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "678d259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\"\"\"A random agent that interacts with the CartPole environment.\"\"\"\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\") # Create the environment\n",
    "total_reward = 0.0 \n",
    "total_steps = 0\n",
    "obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb4ac675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: 32.0, Total steps: 34\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    env.render()  # Render the environment\n",
    "    action = env.action_space.sample()  # Take a random action\n",
    "    obs, reward, terminated, truncated, info = env.step(action) # Execute the action\n",
    "    total_reward += reward\n",
    "    total_steps += 1\n",
    "    if terminated: # Check if the episode is done\n",
    "        break\n",
    "print(f\"Total reward: {total_reward}, Total steps: {total_steps}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "603ac1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TimeLimit<OrderEnforcing<PassiveEnvChecker<HalfCheetahEnv<HalfCheetah-v4>>>>>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "gym.make(\"HalfCheetah-v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5987c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\.venv\\Lib\\site-packages\\gymnasium\\envs\\registration.py:512: DeprecationWarning: \u001b[33mWARN: The environment HalfCheetah-v4 is out of date. You should consider upgrading to version `v5`.\u001b[0m\n",
      "  logger.deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 01 — length=1000, total_reward=-182.143\n",
      "Episode 02 — length=1000, total_reward=-271.506\n",
      "Episode 03 — length=1000, total_reward=-285.212\n",
      "Episode 04 — length=1000, total_reward=-375.975\n",
      "Episode 05 — length=1000, total_reward=-202.475\n"
     ]
    }
   ],
   "source": [
    "# random_mujoco_agent.py\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from gymnasium.wrappers import RecordEpisodeStatistics\n",
    "import time\n",
    "\n",
    "ENV_ID = \"HalfCheetah-v4\"   # change to Ant-v4, Hopper-v4, Walker2d-v4, etc.\n",
    "NUM_EPISODES = 5\n",
    "MAX_STEPS = 1000\n",
    "SEED = 42\n",
    "\n",
    "def run_random_agent():\n",
    "    # create env. set render_mode=\"human\" if you want to see a window (requires a display)\n",
    "    env = gym.make(ENV_ID, render_mode=\"human\")   # None => no rendering; use \"human\" or \"rgb_array\" if set up\n",
    "    #env = RecordEpisodeStatistics(env)\n",
    "    obs, info = env.reset(seed=SEED)\n",
    "\n",
    "    for ep in range(NUM_EPISODES):\n",
    "        obs, info = env.reset(seed=SEED + ep)\n",
    "        total_reward = 0.0\n",
    "        for t in range(MAX_STEPS):\n",
    "            env.render()\n",
    "            # sample random action from action space\n",
    "            action = env.action_space.sample()\n",
    "\n",
    "            # step the env\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            total_reward += float(reward)\n",
    "\n",
    "            # optional: render to a window (only works if render_mode was set to \"human\")\n",
    "            # env.render()\n",
    "\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "\n",
    "        print(f\"Episode {ep+1:02d} — length={t+1}, total_reward={total_reward:.3f}\")\n",
    "\n",
    "    env.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_random_agent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673e291b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\.venv\\Lib\\site-packages\\gymnasium\\wrappers\\rendering.py:296: UserWarning: \u001b[33mWARN: Overwriting existing videos at c:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video of the random agent has been saved in the 'videos' folder.\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "import ale_py\n",
    "gym.register_envs(ale_py)\n",
    "\n",
    "# Create the Atari environment Breakout.\n",
    "env = gym.make(\"ALE/Breakout-v5\", render_mode=\"rgb_array\")\n",
    "\n",
    "# Wrap the environment to record a video.\n",
    "# The video will be saved in a \"videos\" folder.\n",
    "env = RecordVideo(env, video_folder=\"./videos\")\n",
    "\n",
    "# The following line is needed to start the recording.\n",
    "# The reset method returns the initial observation.\n",
    "obs, info = env.reset()\n",
    "\n",
    "# Run the environment for a total of 1000 steps.\n",
    "for _ in range(1000):\n",
    "    # Take a random action from the environment's action space.\n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    # The step method returns the next observation, the reward, whether the episode is terminated or truncated, and additional info.\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # If the episode is over, reset the environment.\n",
    "    if terminated or truncated:\n",
    "        obs, info = env.reset()\n",
    "\n",
    "# Close the environment.\n",
    "env.close()\n",
    "\n",
    "print(\"Video of the random agent has been saved in the 'videos' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3ecbcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebe0e727",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomActionWrapper(gym.ActionWrapper):\n",
    "    \"\"\"A wrapper that takes random actions with a probability of epsilon.\"\"\"\n",
    "    \n",
    "    def __init__(self, env: gym.Env, epsilon: float = 0.2):\n",
    "        super(RandomActionWrapper, self).__init__(env)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def action(self, action):\n",
    "        \"\"\"Override the action method to take random actions with probability epsilon.\"\"\"\n",
    "        if random.random() < self.epsilon:\n",
    "            action = self.env.action_space.sample()  # Take a random action\n",
    "            print(f\"Random action: {action}\")\n",
    "            return action\n",
    "        else:\n",
    "            print(f\"Original action: {action}\")\n",
    "            return action  # Otherwise, return the original action\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04b9fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original action: 0\n",
      "Original action: 0\n",
      "Random action: 1\n",
      "Original action: 0\n",
      "Original action: 0\n",
      "Random action: 1\n",
      "Original action: 0\n",
      "Original action: 0\n",
      "Original action: 0\n",
      "Original action: 0\n",
      "Original action: 0\n",
      "Original action: 0\n",
      "Total reward: 12.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Create the CartPole environment\n",
    "    env = RandomActionWrapper(gym.make(\"CartPole-v1\"))\n",
    "    obs = env.reset()\n",
    "    total_reward = 0.0\n",
    "    while True:\n",
    "        obs, reward, terminated, truncated, info = env.step(0) # Take action 0\n",
    "        total_reward += reward\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "    print(f\"Total reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c503dc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode done in 104 steps, total reward -19.88\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = gym.make(\"Ant-v5\", render_mode=\"rgb_array\")\n",
    "    #env = gym.wrappers.HumanRendering(env)\n",
    "    env = gym.wrappers.RecordVideo(env, video_folder=\"video\")\n",
    "\n",
    "    total_reward = 0.0\n",
    "    total_steps = 0\n",
    "    obs = env.reset()\n",
    "\n",
    "    while True:\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, done, _, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        total_steps += 1\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    print(f\"Episode done in {total_steps} steps, total reward {total_reward:.2f}\")\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05708d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 finished with a total reward of: 4.97\n",
      "Episode 2 finished with a total reward of: -96.68\n",
      "Episode 3 finished with a total reward of: -2.28\n",
      "Episode 4 finished with a total reward of: 8.83\n",
      "Episode 5 finished with a total reward of: -32.11\n",
      "Episode 6 finished with a total reward of: -38.17\n",
      "Episode 7 finished with a total reward of: 22.00\n",
      "Episode 8 finished with a total reward of: -54.13\n",
      "Episode 9 finished with a total reward of: -33.40\n",
      "Episode 10 finished with a total reward of: 6.52\n",
      "Episode 11 finished with a total reward of: -23.65\n",
      "\n",
      "Video recording complete. Check the 'videos_ant' directory.\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "# Create the Ant-v5 environment with the render_mode set to \"rgb_array\" for video recording\n",
    "env = gym.make(\"Ant-v5\", render_mode=\"rgb_array\")\n",
    "\n",
    "# Wrap the environment with the RecordVideo wrapper to save the video\n",
    "# The video will be saved in a \"videos_ant\" directory\n",
    "env = RecordVideo(env, video_folder=\"videos_ant\")\n",
    "\n",
    "# Reset the environment to get the initial observation\n",
    "observation, info = env.reset()\n",
    "\n",
    "# Initialize total reward for the episode and episode counter\n",
    "total_reward = 0\n",
    "episode_count = 1\n",
    "\n",
    "# Run the simulation for a total of 2000 steps\n",
    "for i in range(2000):\n",
    "    # The render method is called by the RecordVideo wrapper, so you don't need to call it manually.\n",
    "    # Taking a random action from the environment's action space\n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    # Take a step in the environment with the random action\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # Add the reward from the step to the total reward for the current episode\n",
    "    total_reward += reward\n",
    "\n",
    "    # If the episode is terminated or truncated (e.g., the ant falls over or the time limit is reached),\n",
    "    # print the total reward for the episode and reset the environment to start a new one.\n",
    "    if terminated or truncated:\n",
    "        print(f\"Episode {episode_count} finished with a total reward of: {total_reward:.2f}\")\n",
    "        observation, info = env.reset()\n",
    "        # Reset the total reward for the next episode\n",
    "        total_reward = 0\n",
    "        episode_count += 1\n",
    "\n",
    "# Close the environment to clean up resources\n",
    "env.close()\n",
    "\n",
    "print(\"\\nVideo recording complete. Check the 'videos_ant' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c715e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 finished with a total reward of: -195.79\n",
      "Episode 2 finished with a total reward of: -232.35\n",
      "\n",
      "Video recording complete. Check the 'videos_cheetah' directory.\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "# Create the HalfCheetah-v5 environment with the render_mode set to \"rgb_array\" for video recording\n",
    "env = gym.make(\"HalfCheetah-v5\", render_mode=\"rgb_array\")\n",
    "\n",
    "# Wrap the environment with the RecordVideo wrapper to save the video\n",
    "# The video will be saved in a \"videos_cheetah\" directory\n",
    "env = RecordVideo(env, video_folder=\"videos_cheetah\")\n",
    "\n",
    "# Reset the environment to get the initial observation\n",
    "observation, info = env.reset()\n",
    "\n",
    "# Initialize total reward for the episode and episode counter\n",
    "total_reward = 0\n",
    "episode_count = 1\n",
    "\n",
    "# Run the simulation for a total of 2000 steps\n",
    "for i in range(2000):\n",
    "    # The render method is called by the RecordVideo wrapper, so you don't need to call it manually.\n",
    "    # Taking a random action from the environment's action space\n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    # Take a step in the environment with the random action\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # Add the reward from the step to the total reward for the current episode\n",
    "    total_reward += reward\n",
    "\n",
    "    # If the episode is terminated or truncated (e.g., the ant falls over or the time limit is reached),\n",
    "    # print the total reward for the episode and reset the environment to start a new one.\n",
    "    if terminated or truncated:\n",
    "        print(f\"Episode {episode_count} finished with a total reward of: {total_reward:.2f}\")\n",
    "        observation, info = env.reset()\n",
    "        # Reset the total reward for the next episode\n",
    "        total_reward = 0\n",
    "        episode_count += 1\n",
    "\n",
    "# Close the environment to clean up resources\n",
    "env.close()\n",
    "\n",
    "print(\"\\nVideo recording complete. Check the 'videos_cheetah' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198aa19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 finished with a total reward of: 0.00\n",
      "Episode 2 finished with a total reward of: 0.00\n",
      "Episode 3 finished with a total reward of: 0.00\n",
      "Episode 4 finished with a total reward of: 0.00\n",
      "Episode 5 finished with a total reward of: 0.00\n",
      "Episode 6 finished with a total reward of: 0.00\n",
      "Episode 7 finished with a total reward of: 0.00\n",
      "Episode 8 finished with a total reward of: 0.00\n",
      "Episode 9 finished with a total reward of: 0.00\n",
      "Episode 10 finished with a total reward of: 0.00\n",
      "Episode 11 finished with a total reward of: 0.00\n",
      "Episode 12 finished with a total reward of: 0.00\n",
      "Episode 13 finished with a total reward of: 0.00\n",
      "Episode 14 finished with a total reward of: 0.00\n",
      "Episode 15 finished with a total reward of: 0.00\n",
      "Episode 16 finished with a total reward of: 0.00\n",
      "Episode 17 finished with a total reward of: 0.00\n",
      "Episode 18 finished with a total reward of: 0.00\n",
      "Episode 19 finished with a total reward of: 0.00\n",
      "Episode 20 finished with a total reward of: 0.00\n",
      "Episode 21 finished with a total reward of: 0.00\n",
      "Episode 22 finished with a total reward of: 0.00\n",
      "Episode 23 finished with a total reward of: 0.00\n",
      "Episode 24 finished with a total reward of: 0.00\n",
      "Episode 25 finished with a total reward of: 0.00\n",
      "Episode 26 finished with a total reward of: 0.00\n",
      "Episode 27 finished with a total reward of: 0.00\n",
      "Episode 28 finished with a total reward of: 1.00\n",
      "Episode 29 finished with a total reward of: 0.00\n",
      "Episode 30 finished with a total reward of: 0.00\n",
      "Episode 31 finished with a total reward of: 0.00\n",
      "Episode 32 finished with a total reward of: 0.00\n",
      "Episode 33 finished with a total reward of: 0.00\n",
      "Episode 34 finished with a total reward of: 0.00\n",
      "Episode 35 finished with a total reward of: 0.00\n",
      "Episode 36 finished with a total reward of: 0.00\n",
      "Episode 37 finished with a total reward of: 0.00\n",
      "Episode 38 finished with a total reward of: 0.00\n",
      "Episode 39 finished with a total reward of: 0.00\n",
      "Episode 40 finished with a total reward of: 0.00\n",
      "Episode 41 finished with a total reward of: 0.00\n",
      "Episode 42 finished with a total reward of: 0.00\n",
      "Episode 43 finished with a total reward of: 0.00\n",
      "Episode 44 finished with a total reward of: 0.00\n",
      "Episode 45 finished with a total reward of: 0.00\n",
      "Episode 46 finished with a total reward of: 0.00\n",
      "Episode 47 finished with a total reward of: 0.00\n",
      "Episode 48 finished with a total reward of: 0.00\n",
      "Episode 49 finished with a total reward of: 0.00\n",
      "Episode 50 finished with a total reward of: 0.00\n",
      "Episode 51 finished with a total reward of: 0.00\n",
      "Episode 52 finished with a total reward of: 0.00\n",
      "Episode 53 finished with a total reward of: 0.00\n",
      "Episode 54 finished with a total reward of: 0.00\n",
      "Episode 55 finished with a total reward of: 0.00\n",
      "Episode 56 finished with a total reward of: 0.00\n",
      "Episode 57 finished with a total reward of: 0.00\n",
      "Episode 58 finished with a total reward of: 0.00\n",
      "Episode 59 finished with a total reward of: 0.00\n",
      "Episode 60 finished with a total reward of: 0.00\n",
      "Episode 61 finished with a total reward of: 0.00\n",
      "Episode 62 finished with a total reward of: 0.00\n",
      "Episode 63 finished with a total reward of: 0.00\n",
      "Episode 64 finished with a total reward of: 0.00\n",
      "Episode 65 finished with a total reward of: 0.00\n",
      "Episode 66 finished with a total reward of: 0.00\n",
      "Episode 67 finished with a total reward of: 0.00\n",
      "Episode 68 finished with a total reward of: 0.00\n",
      "Episode 69 finished with a total reward of: 0.00\n",
      "Episode 70 finished with a total reward of: 0.00\n",
      "Episode 71 finished with a total reward of: 0.00\n",
      "Episode 72 finished with a total reward of: 0.00\n",
      "Episode 73 finished with a total reward of: 0.00\n",
      "Episode 74 finished with a total reward of: 0.00\n",
      "Episode 75 finished with a total reward of: 0.00\n",
      "Episode 76 finished with a total reward of: 0.00\n",
      "Episode 77 finished with a total reward of: 0.00\n",
      "Episode 78 finished with a total reward of: 0.00\n",
      "Episode 79 finished with a total reward of: 0.00\n",
      "Episode 80 finished with a total reward of: 0.00\n",
      "Episode 81 finished with a total reward of: 0.00\n",
      "Episode 82 finished with a total reward of: 0.00\n",
      "Episode 83 finished with a total reward of: 0.00\n",
      "Episode 84 finished with a total reward of: 0.00\n",
      "Episode 85 finished with a total reward of: 0.00\n",
      "Episode 86 finished with a total reward of: 0.00\n",
      "Episode 87 finished with a total reward of: 0.00\n",
      "Episode 88 finished with a total reward of: 0.00\n",
      "Episode 89 finished with a total reward of: 0.00\n",
      "Episode 90 finished with a total reward of: 0.00\n",
      "Episode 91 finished with a total reward of: 0.00\n",
      "Episode 92 finished with a total reward of: 0.00\n",
      "Episode 93 finished with a total reward of: 0.00\n",
      "Episode 94 finished with a total reward of: 0.00\n",
      "Episode 95 finished with a total reward of: 0.00\n",
      "Episode 96 finished with a total reward of: 0.00\n",
      "Episode 97 finished with a total reward of: 0.00\n",
      "Episode 98 finished with a total reward of: 0.00\n",
      "Episode 99 finished with a total reward of: 0.00\n",
      "Episode 100 finished with a total reward of: 0.00\n",
      "Episode 101 finished with a total reward of: 0.00\n",
      "Episode 102 finished with a total reward of: 0.00\n",
      "Episode 103 finished with a total reward of: 0.00\n",
      "Episode 104 finished with a total reward of: 0.00\n",
      "Episode 105 finished with a total reward of: 0.00\n",
      "Episode 106 finished with a total reward of: 0.00\n",
      "Episode 107 finished with a total reward of: 0.00\n",
      "Episode 108 finished with a total reward of: 0.00\n",
      "Episode 109 finished with a total reward of: 0.00\n",
      "Episode 110 finished with a total reward of: 0.00\n",
      "Episode 111 finished with a total reward of: 0.00\n",
      "Episode 112 finished with a total reward of: 0.00\n",
      "Episode 113 finished with a total reward of: 0.00\n",
      "Episode 114 finished with a total reward of: 0.00\n",
      "Episode 115 finished with a total reward of: 0.00\n",
      "Episode 116 finished with a total reward of: 0.00\n",
      "Episode 117 finished with a total reward of: 0.00\n",
      "Episode 118 finished with a total reward of: 0.00\n",
      "Episode 119 finished with a total reward of: 0.00\n",
      "Episode 120 finished with a total reward of: 0.00\n",
      "Episode 121 finished with a total reward of: 0.00\n",
      "Episode 122 finished with a total reward of: 1.00\n",
      "Episode 123 finished with a total reward of: 0.00\n",
      "Episode 124 finished with a total reward of: 0.00\n",
      "Episode 125 finished with a total reward of: 0.00\n",
      "Episode 126 finished with a total reward of: 0.00\n",
      "Episode 127 finished with a total reward of: 1.00\n",
      "Episode 128 finished with a total reward of: 0.00\n",
      "Episode 129 finished with a total reward of: 0.00\n",
      "Episode 130 finished with a total reward of: 0.00\n",
      "Episode 131 finished with a total reward of: 0.00\n",
      "Episode 132 finished with a total reward of: 0.00\n",
      "Episode 133 finished with a total reward of: 0.00\n",
      "Episode 134 finished with a total reward of: 0.00\n",
      "Episode 135 finished with a total reward of: 0.00\n",
      "Episode 136 finished with a total reward of: 0.00\n",
      "Episode 137 finished with a total reward of: 0.00\n",
      "Episode 138 finished with a total reward of: 0.00\n",
      "Episode 139 finished with a total reward of: 0.00\n",
      "Episode 140 finished with a total reward of: 0.00\n",
      "Episode 141 finished with a total reward of: 0.00\n",
      "Episode 142 finished with a total reward of: 0.00\n",
      "Episode 143 finished with a total reward of: 0.00\n",
      "Episode 144 finished with a total reward of: 0.00\n",
      "Episode 145 finished with a total reward of: 0.00\n",
      "Episode 146 finished with a total reward of: 0.00\n",
      "Episode 147 finished with a total reward of: 0.00\n",
      "Episode 148 finished with a total reward of: 0.00\n",
      "Episode 149 finished with a total reward of: 0.00\n",
      "Episode 150 finished with a total reward of: 0.00\n",
      "Episode 151 finished with a total reward of: 0.00\n",
      "Episode 152 finished with a total reward of: 0.00\n",
      "Episode 153 finished with a total reward of: 0.00\n",
      "Episode 154 finished with a total reward of: 0.00\n",
      "Episode 155 finished with a total reward of: 0.00\n",
      "Episode 156 finished with a total reward of: 0.00\n",
      "Episode 157 finished with a total reward of: 0.00\n",
      "Episode 158 finished with a total reward of: 0.00\n",
      "Episode 159 finished with a total reward of: 0.00\n",
      "Episode 160 finished with a total reward of: 0.00\n",
      "Episode 161 finished with a total reward of: 0.00\n",
      "Episode 162 finished with a total reward of: 0.00\n",
      "Episode 163 finished with a total reward of: 0.00\n",
      "Episode 164 finished with a total reward of: 0.00\n",
      "Episode 165 finished with a total reward of: 0.00\n",
      "Episode 166 finished with a total reward of: 0.00\n",
      "Episode 167 finished with a total reward of: 0.00\n",
      "Episode 168 finished with a total reward of: 0.00\n",
      "Episode 169 finished with a total reward of: 0.00\n",
      "Episode 170 finished with a total reward of: 0.00\n",
      "Episode 171 finished with a total reward of: 0.00\n",
      "Episode 172 finished with a total reward of: 0.00\n",
      "Episode 173 finished with a total reward of: 0.00\n",
      "Episode 174 finished with a total reward of: 0.00\n",
      "Episode 175 finished with a total reward of: 0.00\n",
      "Episode 176 finished with a total reward of: 0.00\n",
      "Episode 177 finished with a total reward of: 0.00\n",
      "Episode 178 finished with a total reward of: 0.00\n",
      "Episode 179 finished with a total reward of: 0.00\n",
      "Episode 180 finished with a total reward of: 0.00\n",
      "Episode 181 finished with a total reward of: 0.00\n",
      "Episode 182 finished with a total reward of: 0.00\n",
      "Episode 183 finished with a total reward of: 0.00\n",
      "Episode 184 finished with a total reward of: 0.00\n",
      "Episode 185 finished with a total reward of: 0.00\n",
      "Episode 186 finished with a total reward of: 0.00\n",
      "Episode 187 finished with a total reward of: 0.00\n",
      "Episode 188 finished with a total reward of: 0.00\n",
      "Episode 189 finished with a total reward of: 0.00\n",
      "Episode 190 finished with a total reward of: 0.00\n",
      "Episode 191 finished with a total reward of: 0.00\n",
      "Episode 192 finished with a total reward of: 0.00\n",
      "Episode 193 finished with a total reward of: 0.00\n",
      "Episode 194 finished with a total reward of: 0.00\n",
      "Episode 195 finished with a total reward of: 0.00\n",
      "Episode 196 finished with a total reward of: 0.00\n",
      "Episode 197 finished with a total reward of: 0.00\n",
      "Episode 198 finished with a total reward of: 0.00\n",
      "Episode 199 finished with a total reward of: 0.00\n",
      "Episode 200 finished with a total reward of: 0.00\n",
      "Episode 201 finished with a total reward of: 0.00\n",
      "Episode 202 finished with a total reward of: 0.00\n",
      "Episode 203 finished with a total reward of: 0.00\n",
      "Episode 204 finished with a total reward of: 0.00\n",
      "Episode 205 finished with a total reward of: 0.00\n",
      "Episode 206 finished with a total reward of: 0.00\n",
      "Episode 207 finished with a total reward of: 0.00\n",
      "Episode 208 finished with a total reward of: 0.00\n",
      "Episode 209 finished with a total reward of: 0.00\n",
      "Episode 210 finished with a total reward of: 0.00\n",
      "Episode 211 finished with a total reward of: 0.00\n",
      "Episode 212 finished with a total reward of: 0.00\n",
      "Episode 213 finished with a total reward of: 0.00\n",
      "Episode 214 finished with a total reward of: 0.00\n",
      "Episode 215 finished with a total reward of: 0.00\n",
      "Episode 216 finished with a total reward of: 0.00\n",
      "Episode 217 finished with a total reward of: 0.00\n",
      "Episode 218 finished with a total reward of: 0.00\n",
      "Episode 219 finished with a total reward of: 0.00\n",
      "Episode 220 finished with a total reward of: 0.00\n",
      "Episode 221 finished with a total reward of: 0.00\n",
      "Episode 222 finished with a total reward of: 0.00\n",
      "Episode 223 finished with a total reward of: 0.00\n",
      "Episode 224 finished with a total reward of: 0.00\n",
      "Episode 225 finished with a total reward of: 0.00\n",
      "Episode 226 finished with a total reward of: 0.00\n",
      "Episode 227 finished with a total reward of: 0.00\n",
      "Episode 228 finished with a total reward of: 0.00\n",
      "Episode 229 finished with a total reward of: 0.00\n",
      "Episode 230 finished with a total reward of: 0.00\n",
      "Episode 231 finished with a total reward of: 0.00\n",
      "Episode 232 finished with a total reward of: 0.00\n",
      "Episode 233 finished with a total reward of: 0.00\n",
      "Episode 234 finished with a total reward of: 0.00\n",
      "Episode 235 finished with a total reward of: 0.00\n",
      "Episode 236 finished with a total reward of: 0.00\n",
      "Episode 237 finished with a total reward of: 0.00\n",
      "Episode 238 finished with a total reward of: 0.00\n",
      "Episode 239 finished with a total reward of: 0.00\n",
      "Episode 240 finished with a total reward of: 0.00\n",
      "Episode 241 finished with a total reward of: 0.00\n",
      "Episode 242 finished with a total reward of: 0.00\n",
      "Episode 243 finished with a total reward of: 0.00\n",
      "Episode 244 finished with a total reward of: 0.00\n",
      "Episode 245 finished with a total reward of: 0.00\n",
      "\n",
      "Video recording complete. Check the 'videos_FrozenLake' directory.\n"
     ]
    }
   ],
   "source": [
    "# A random agent on the FrozenLake environment\n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "# Create the FrozsenLake environment with the render_mode set to \"rgb_array\" for video recording\n",
    "env = gym.make(\"FrozenLake-v1\", render_mode=\"rgb_array\")\n",
    "\n",
    "# Wrap the environment with the RecordVideo wrapper to save the video\n",
    "# The video will be saved in a \"videos_FrozenLake\" directory\n",
    "env = RecordVideo(env, video_folder=\"videos_FrozenLake\")\n",
    "\n",
    "# Reset the environment to get the initial observation\n",
    "observation, info = env.reset()\n",
    "\n",
    "# Initialize total reward for the episode and episode counter\n",
    "total_reward = 0\n",
    "episode_count = 1\n",
    "\n",
    "# Run the simulation for a total of 2000 steps\n",
    "for i in range(2000):\n",
    "    # The render method is called by the RecordVideo wrapper, so you don't need to call it manually.\n",
    "    # Taking a random action from the environment's action space\n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    # Take a step in the environment with the random action\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # Add the reward from the step to the total reward for the current episode\n",
    "    total_reward += reward\n",
    "\n",
    "    # If the episode is terminated or truncated,\n",
    "    # print the total reward for the episode and reset the environment to start a new one.\n",
    "    if terminated or truncated:\n",
    "        print(f\"Episode {episode_count} finished with a total reward of: {total_reward:.2f}\")\n",
    "        observation, info = env.reset()\n",
    "        # Reset the total reward for the next episode\n",
    "        total_reward = 0\n",
    "        episode_count += 1\n",
    "\n",
    "# Close the environment to clean up resources\n",
    "env.close()\n",
    "\n",
    "print(\"\\nVideo recording complete. Check the 'videos_FrozenLake' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "554b8130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Discrete(16), Discrete(4))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "e = gym.make(\"FrozenLake-v1\", render_mode=\"ansi\")\n",
    "e.observation_space, e.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b237244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, {'prob': 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f109d0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.observation_space = gym.spaces.Box(low=0, high=1, shape=(16,), dtype=np.float32)\n",
    "e.observation_space.low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea9d9cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.observation_space.high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3cd26ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import A2C\n",
    "from gymnasium.wrappers import RecordVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a77823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(environment: gym.Env, total_timesteps: int):\n",
    "    \"\"\"Function to train an A2C agent on a specified environment for a given number of timesteps.\"\"\"\n",
    "    env = gym.make(environment, render_mode=None)\n",
    "    model = A2C(\"MlpPolicy\", env, verbose=1)\n",
    "    model.learn(total_timesteps=total_timesteps)\n",
    "    model.save(\"CartPole_A2C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aec00d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    \"\"\"Function to test a trained A2C agent on the CartPole environment and record a video.\"\"\"\n",
    "    env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "    env = RecordVideo(env, video_folder=\"videos_CartPole_A2c\")\n",
    "    obs, info = env.reset()\n",
    "    model = A2C.load(\"CartPole_A2C\")\n",
    "\n",
    "    total_reward = 0\n",
    "    episode_over = False\n",
    "    \n",
    "    while not episode_over:\n",
    "        action, state = model.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        episode_over = terminated or truncated\n",
    "    print(f\"total reward: {total_reward:.2f}\")\n",
    "    env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95f44bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 38.6     |\n",
      "|    ep_rew_mean        | 38.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.661   |\n",
      "|    explained_variance | -0.311   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 1.69     |\n",
      "|    value_loss         | 9.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 39.2     |\n",
      "|    ep_rew_mean        | 39.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.656   |\n",
      "|    explained_variance | -0.0602  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 1.09     |\n",
      "|    value_loss         | 6.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 36.3     |\n",
      "|    ep_rew_mean        | 36.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.544   |\n",
      "|    explained_variance | -0.2     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 1.65     |\n",
      "|    value_loss         | 8.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 35.5     |\n",
      "|    ep_rew_mean        | 35.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 568      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.542   |\n",
      "|    explained_variance | -0.019   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.839    |\n",
      "|    value_loss         | 6.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 35.3     |\n",
      "|    ep_rew_mean        | 35.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.6     |\n",
      "|    explained_variance | -0.0425  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 1.18     |\n",
      "|    value_loss         | 5.56     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 34.8     |\n",
      "|    ep_rew_mean        | 34.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 554      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.563   |\n",
      "|    explained_variance | -0.00296 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -7.2     |\n",
      "|    value_loss         | 494      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 35.3     |\n",
      "|    ep_rew_mean        | 35.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.47    |\n",
      "|    explained_variance | 0.00262  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 0.739    |\n",
      "|    value_loss         | 4.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 34.1     |\n",
      "|    ep_rew_mean        | 34.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 534      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.578   |\n",
      "|    explained_variance | 0.00068  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.974    |\n",
      "|    value_loss         | 4.19     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 34.1      |\n",
      "|    ep_rew_mean        | 34.1      |\n",
      "| time/                 |           |\n",
      "|    fps                | 531       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.356    |\n",
      "|    explained_variance | -0.000628 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | -45.1     |\n",
      "|    value_loss         | 1.41e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 35.6     |\n",
      "|    ep_rew_mean        | 35.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 528      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.603   |\n",
      "|    explained_variance | 0.000967 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.629    |\n",
      "|    value_loss         | 3.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 37.4     |\n",
      "|    ep_rew_mean        | 37.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.466   |\n",
      "|    explained_variance | 0.00408  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.481    |\n",
      "|    value_loss         | 2.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 40       |\n",
      "|    ep_rew_mean        | 40       |\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.614   |\n",
      "|    explained_variance | 0.000204 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.609    |\n",
      "|    value_loss         | 2.47     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 43.2     |\n",
      "|    ep_rew_mean        | 43.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 528      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.503   |\n",
      "|    explained_variance | -0.00027 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.857    |\n",
      "|    value_loss         | 2.1      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 45.9      |\n",
      "|    ep_rew_mean        | 45.9      |\n",
      "| time/                 |           |\n",
      "|    fps                | 529       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.523    |\n",
      "|    explained_variance | -0.000174 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 0.387     |\n",
      "|    value_loss         | 1.73      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 49.6     |\n",
      "|    ep_rew_mean        | 49.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 532      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.47    |\n",
      "|    explained_variance | 0.000145 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 0.746    |\n",
      "|    value_loss         | 1.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 53       |\n",
      "|    ep_rew_mean        | 53       |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.492   |\n",
      "|    explained_variance | 9.84e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.485    |\n",
      "|    value_loss         | 1.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 56.2     |\n",
      "|    ep_rew_mean        | 56.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 534      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.575   |\n",
      "|    explained_variance | 0.000145 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.341    |\n",
      "|    value_loss         | 0.828    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 60.5     |\n",
      "|    ep_rew_mean        | 60.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.569   |\n",
      "|    explained_variance | 2.05e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.443    |\n",
      "|    value_loss         | 0.592    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 65.4     |\n",
      "|    ep_rew_mean        | 65.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 532      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.514   |\n",
      "|    explained_variance | 3.25e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 0.172    |\n",
      "|    value_loss         | 0.392    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 68.6     |\n",
      "|    ep_rew_mean        | 68.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.588   |\n",
      "|    explained_variance | -8.5e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.207    |\n",
      "|    value_loss         | 0.235    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 72.4      |\n",
      "|    ep_rew_mean        | 72.4      |\n",
      "| time/                 |           |\n",
      "|    fps                | 526       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.431    |\n",
      "|    explained_variance | -0.000105 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 0.2       |\n",
      "|    value_loss         | 0.116     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 76.2     |\n",
      "|    ep_rew_mean        | 76.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 527      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.576   |\n",
      "|    explained_variance | 2.68e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 0.0736   |\n",
      "|    value_loss         | 0.0382   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 81        |\n",
      "|    ep_rew_mean        | 81        |\n",
      "| time/                 |           |\n",
      "|    fps                | 529       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.549    |\n",
      "|    explained_variance | -7.63e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 0.0202    |\n",
      "|    value_loss         | 0.00328   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 84.2     |\n",
      "|    ep_rew_mean        | 84.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.608   |\n",
      "|    explained_variance | 0.00344  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 0.00214  |\n",
      "|    value_loss         | 3.54e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 87.8     |\n",
      "|    ep_rew_mean        | 87.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.517   |\n",
      "|    explained_variance | -0.0967  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 0.000199 |\n",
      "|    value_loss         | 3.02e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 93.9     |\n",
      "|    ep_rew_mean        | 93.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 534      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.474   |\n",
      "|    explained_variance | 0.0222   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 0.000803 |\n",
      "|    value_loss         | 1.02e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 98.3     |\n",
      "|    ep_rew_mean        | 98.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 535      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.405   |\n",
      "|    explained_variance | 5.58e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 0.00298  |\n",
      "|    value_loss         | 1.01e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 101      |\n",
      "|    ep_rew_mean        | 101      |\n",
      "| time/                 |          |\n",
      "|    fps                | 536      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.556   |\n",
      "|    explained_variance | -2.33    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 1.18e-05 |\n",
      "|    value_loss         | 9.08e-10 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 106      |\n",
      "|    ep_rew_mean        | 106      |\n",
      "| time/                 |          |\n",
      "|    fps                | 537      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.417   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 4.23e-06 |\n",
      "|    value_loss         | 2.93e-09 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 110       |\n",
      "|    ep_rew_mean        | 110       |\n",
      "| time/                 |           |\n",
      "|    fps                | 539       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.487    |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | -1.72e-05 |\n",
      "|    value_loss         | 1.63e-09  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 115      |\n",
      "|    ep_rew_mean        | 115      |\n",
      "| time/                 |          |\n",
      "|    fps                | 539      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.494   |\n",
      "|    explained_variance | -4.08    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 2.08e-06 |\n",
      "|    value_loss         | 8.61e-10 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 120      |\n",
      "|    ep_rew_mean        | 120      |\n",
      "| time/                 |          |\n",
      "|    fps                | 540      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.385   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 2.91e-05 |\n",
      "|    value_loss         | 2.36e-09 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 124       |\n",
      "|    ep_rew_mean        | 124       |\n",
      "| time/                 |           |\n",
      "|    fps                | 541       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 30        |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.505    |\n",
      "|    explained_variance | -0.785    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | -3.87e-05 |\n",
      "|    value_loss         | 7.07e-09  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 129       |\n",
      "|    ep_rew_mean        | 129       |\n",
      "| time/                 |           |\n",
      "|    fps                | 543       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.494    |\n",
      "|    explained_variance | 0.115     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -0.000143 |\n",
      "|    value_loss         | 1.47e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 134      |\n",
      "|    ep_rew_mean        | 134      |\n",
      "| time/                 |          |\n",
      "|    fps                | 544      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.415   |\n",
      "|    explained_variance | -0.00279 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 0.000253 |\n",
      "|    value_loss         | 3.8e-07  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 138       |\n",
      "|    ep_rew_mean        | 138       |\n",
      "| time/                 |           |\n",
      "|    fps                | 545       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 33        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.342    |\n",
      "|    explained_variance | -0.0863   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -0.000568 |\n",
      "|    value_loss         | 1.34e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 143       |\n",
      "|    ep_rew_mean        | 143       |\n",
      "| time/                 |           |\n",
      "|    fps                | 546       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 33        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.391    |\n",
      "|    explained_variance | -0.0449   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -0.000743 |\n",
      "|    value_loss         | 1.92e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 146       |\n",
      "|    ep_rew_mean        | 146       |\n",
      "| time/                 |           |\n",
      "|    fps                | 547       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.39     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | -2.56e-05 |\n",
      "|    value_loss         | 6.01e-09  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 150      |\n",
      "|    ep_rew_mean        | 150      |\n",
      "| time/                 |          |\n",
      "|    fps                | 547      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.462   |\n",
      "|    explained_variance | -10.3    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 3.62e-07 |\n",
      "|    value_loss         | 5.12e-10 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 155      |\n",
      "|    ep_rew_mean        | 155      |\n",
      "| time/                 |          |\n",
      "|    fps                | 548      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.457   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 1.21e-05 |\n",
      "|    value_loss         | 1.68e-09 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 160       |\n",
      "|    ep_rew_mean        | 160       |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.398    |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | -2.45e-06 |\n",
      "|    value_loss         | 1.86e-10  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 165      |\n",
      "|    ep_rew_mean        | 165      |\n",
      "| time/                 |          |\n",
      "|    fps                | 549      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.432   |\n",
      "|    explained_variance | 0.13     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -3.1e-06 |\n",
      "|    value_loss         | 1.04e-09 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 169       |\n",
      "|    ep_rew_mean        | 169       |\n",
      "| time/                 |           |\n",
      "|    fps                | 549       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.303    |\n",
      "|    explained_variance | 0.281     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -0.000109 |\n",
      "|    value_loss         | 1.11e-08  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 177      |\n",
      "|    ep_rew_mean        | 177      |\n",
      "| time/                 |          |\n",
      "|    fps                | 550      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.347   |\n",
      "|    explained_variance | 0.0644   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 0.000102 |\n",
      "|    value_loss         | 1.69e-08 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 180      |\n",
      "|    ep_rew_mean        | 180      |\n",
      "| time/                 |          |\n",
      "|    fps                | 550      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.458   |\n",
      "|    explained_variance | 0.000632 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 0.000118 |\n",
      "|    value_loss         | 3.34e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 184      |\n",
      "|    ep_rew_mean        | 184      |\n",
      "| time/                 |          |\n",
      "|    fps                | 551      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.383   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -25.4    |\n",
      "|    value_loss         | 7.61e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 186      |\n",
      "|    ep_rew_mean        | 186      |\n",
      "| time/                 |          |\n",
      "|    fps                | 552      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.366   |\n",
      "|    explained_variance | 1.66e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 0.000289 |\n",
      "|    value_loss         | 3.13e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 190      |\n",
      "|    ep_rew_mean        | 190      |\n",
      "| time/                 |          |\n",
      "|    fps                | 552      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.416   |\n",
      "|    explained_variance | 0.325    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 3.56e-05 |\n",
      "|    value_loss         | 4.24e-08 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 194      |\n",
      "|    ep_rew_mean        | 194      |\n",
      "| time/                 |          |\n",
      "|    fps                | 550      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.415   |\n",
      "|    explained_variance | 0.0432   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 1.63e-05 |\n",
      "|    value_loss         | 1.31e-08 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 198      |\n",
      "|    ep_rew_mean        | 198      |\n",
      "| time/                 |          |\n",
      "|    fps                | 549      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.444   |\n",
      "|    explained_variance | -1.02    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 2.73e-05 |\n",
      "|    value_loss         | 1.2e-08  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 202      |\n",
      "|    ep_rew_mean        | 202      |\n",
      "| time/                 |          |\n",
      "|    fps                | 550      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.441   |\n",
      "|    explained_variance | -0.0429  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 7.51e-05 |\n",
      "|    value_loss         | 5e-08    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 206      |\n",
      "|    ep_rew_mean        | 206      |\n",
      "| time/                 |          |\n",
      "|    fps                | 551      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.353   |\n",
      "|    explained_variance | -0.00471 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 0.000734 |\n",
      "|    value_loss         | 2.98e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 208      |\n",
      "|    ep_rew_mean        | 208      |\n",
      "| time/                 |          |\n",
      "|    fps                | 552      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.379   |\n",
      "|    explained_variance | 0.0101   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 0.000425 |\n",
      "|    value_loss         | 4.1e-06  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 209       |\n",
      "|    ep_rew_mean        | 209       |\n",
      "| time/                 |           |\n",
      "|    fps                | 552       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.416    |\n",
      "|    explained_variance | -0.000174 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | 0.000202  |\n",
      "|    value_loss         | 1.22e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 211      |\n",
      "|    ep_rew_mean        | 211      |\n",
      "| time/                 |          |\n",
      "|    fps                | 552      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.461   |\n",
      "|    explained_variance | -0.0301  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 0.000568 |\n",
      "|    value_loss         | 1.83e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 215      |\n",
      "|    ep_rew_mean        | 215      |\n",
      "| time/                 |          |\n",
      "|    fps                | 553      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.352   |\n",
      "|    explained_variance | -0.0256  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 0.000805 |\n",
      "|    value_loss         | 5.93e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 215      |\n",
      "|    ep_rew_mean        | 215      |\n",
      "| time/                 |          |\n",
      "|    fps                | 553      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.339   |\n",
      "|    explained_variance | -0.0118  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 0.00249  |\n",
      "|    value_loss         | 1.54e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 215      |\n",
      "|    ep_rew_mean        | 215      |\n",
      "| time/                 |          |\n",
      "|    fps                | 553      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.361   |\n",
      "|    explained_variance | 0.0132   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 0.00215  |\n",
      "|    value_loss         | 1.66e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 215      |\n",
      "|    ep_rew_mean        | 215      |\n",
      "| time/                 |          |\n",
      "|    fps                | 554      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.413   |\n",
      "|    explained_variance | -0.396   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 0.001    |\n",
      "|    value_loss         | 4.5e-06  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 213      |\n",
      "|    ep_rew_mean        | 213      |\n",
      "| time/                 |          |\n",
      "|    fps                | 555      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.346   |\n",
      "|    explained_variance | -0.00561 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 0.00113  |\n",
      "|    value_loss         | 9.91e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 207      |\n",
      "|    ep_rew_mean        | 207      |\n",
      "| time/                 |          |\n",
      "|    fps                | 555      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.362   |\n",
      "|    explained_variance | -0.142   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 0.000281 |\n",
      "|    value_loss         | 5.58e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 200      |\n",
      "|    ep_rew_mean        | 200      |\n",
      "| time/                 |          |\n",
      "|    fps                | 555      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.326   |\n",
      "|    explained_variance | -0.0249  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 0.00288  |\n",
      "|    value_loss         | 7.59e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 198      |\n",
      "|    ep_rew_mean        | 198      |\n",
      "| time/                 |          |\n",
      "|    fps                | 556      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.389   |\n",
      "|    explained_variance | -0.00954 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 0.000671 |\n",
      "|    value_loss         | 2.99e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 185      |\n",
      "|    ep_rew_mean        | 185      |\n",
      "| time/                 |          |\n",
      "|    fps                | 557      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.286   |\n",
      "|    explained_variance | -0.0229  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 0.00113  |\n",
      "|    value_loss         | 2.3e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 163      |\n",
      "|    ep_rew_mean        | 163      |\n",
      "| time/                 |          |\n",
      "|    fps                | 558      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.364   |\n",
      "|    explained_variance | -0.00333 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 0.00373  |\n",
      "|    value_loss         | 0.000105 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 140      |\n",
      "|    ep_rew_mean        | 140      |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.377   |\n",
      "|    explained_variance | -0.00729 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 0.00129  |\n",
      "|    value_loss         | 5.16e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 114      |\n",
      "|    ep_rew_mean        | 114      |\n",
      "| time/                 |          |\n",
      "|    fps                | 559      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.396   |\n",
      "|    explained_variance | 0.0116   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 0.00359  |\n",
      "|    value_loss         | 6.45e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 112      |\n",
      "|    ep_rew_mean        | 112      |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.435   |\n",
      "|    explained_variance | 0.0507   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 0.00115  |\n",
      "|    value_loss         | 2.97e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 106      |\n",
      "|    ep_rew_mean        | 106      |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.21    |\n",
      "|    explained_variance | 0.000662 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -1.99    |\n",
      "|    value_loss         | 5.74e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 91.5     |\n",
      "|    ep_rew_mean        | 91.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.404   |\n",
      "|    explained_variance | 0.185    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -0.00618 |\n",
      "|    value_loss         | 0.00113  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 84.7     |\n",
      "|    ep_rew_mean        | 84.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.45    |\n",
      "|    explained_variance | -0.272   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | 0.00636  |\n",
      "|    value_loss         | 0.0012   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 70.4     |\n",
      "|    ep_rew_mean        | 70.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.393   |\n",
      "|    explained_variance | -24.5    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -0.388   |\n",
      "|    value_loss         | 2.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 63.1     |\n",
      "|    ep_rew_mean        | 63.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.197   |\n",
      "|    explained_variance | 0.544    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | 0.41     |\n",
      "|    value_loss         | 239      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 55.7     |\n",
      "|    ep_rew_mean        | 55.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.409   |\n",
      "|    explained_variance | 0.98     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -0.0733  |\n",
      "|    value_loss         | 0.294    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 53.1     |\n",
      "|    ep_rew_mean        | 53.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.46    |\n",
      "|    explained_variance | 0.993    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | 0.174    |\n",
      "|    value_loss         | 0.265    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 54.4     |\n",
      "|    ep_rew_mean        | 54.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.343   |\n",
      "|    explained_variance | -1.22    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 0.484    |\n",
      "|    value_loss         | 1.78     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 57.2     |\n",
      "|    ep_rew_mean        | 57.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.313   |\n",
      "|    explained_variance | -2.3     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 0.0305   |\n",
      "|    value_loss         | 0.00553  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 58       |\n",
      "|    ep_rew_mean        | 58       |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.424   |\n",
      "|    explained_variance | 0.481    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -0.00774 |\n",
      "|    value_loss         | 0.00189  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 54.5     |\n",
      "|    ep_rew_mean        | 54.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.274   |\n",
      "|    explained_variance | 0.0107   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 0.00988  |\n",
      "|    value_loss         | 0.000972 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 37.4     |\n",
      "|    ep_rew_mean        | 37.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.443   |\n",
      "|    explained_variance | -0.226   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | 0.00203  |\n",
      "|    value_loss         | 0.00217  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.2     |\n",
      "|    ep_rew_mean        | 10.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0579  |\n",
      "|    explained_variance | 0.16     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 0.0304   |\n",
      "|    value_loss         | 0.00202  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.4     |\n",
      "|    ep_rew_mean        | 10.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.218   |\n",
      "|    explained_variance | 0.598    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | -26.5    |\n",
      "|    value_loss         | 2.36e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12.2     |\n",
      "|    ep_rew_mean        | 12.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.619   |\n",
      "|    explained_variance | -4.99    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -0.34    |\n",
      "|    value_loss         | 2.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 14.6     |\n",
      "|    ep_rew_mean        | 14.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.422   |\n",
      "|    explained_variance | -7.43    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 0.00921  |\n",
      "|    value_loss         | 0.129    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 23.1     |\n",
      "|    ep_rew_mean        | 23.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.372   |\n",
      "|    explained_variance | 0.717    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | -0.0112  |\n",
      "|    value_loss         | 0.000945 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 28.2     |\n",
      "|    ep_rew_mean        | 28.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.382   |\n",
      "|    explained_variance | -0.019   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -10.7    |\n",
      "|    value_loss         | 1.99e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 32.4     |\n",
      "|    ep_rew_mean        | 32.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.354   |\n",
      "|    explained_variance | -0.746   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | 0.00429  |\n",
      "|    value_loss         | 0.000943 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 35.6     |\n",
      "|    ep_rew_mean        | 35.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.281   |\n",
      "|    explained_variance | -0.00663 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -14.4    |\n",
      "|    value_loss         | 5.92e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 38.4     |\n",
      "|    ep_rew_mean        | 38.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.385   |\n",
      "|    explained_variance | 0.568    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 0.00355  |\n",
      "|    value_loss         | 7.82e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 40.7     |\n",
      "|    ep_rew_mean        | 40.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.568   |\n",
      "|    explained_variance | -3.63    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 0.00805  |\n",
      "|    value_loss         | 0.000513 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 39.2     |\n",
      "|    ep_rew_mean        | 39.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.506   |\n",
      "|    explained_variance | -38.4    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 0.00335  |\n",
      "|    value_loss         | 0.000157 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 20.3     |\n",
      "|    ep_rew_mean        | 20.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.491   |\n",
      "|    explained_variance | -0.00151 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -38      |\n",
      "|    value_loss         | 7.51e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 18.6     |\n",
      "|    ep_rew_mean        | 18.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.337   |\n",
      "|    explained_variance | -0.00144 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -48      |\n",
      "|    value_loss         | 7.54e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 19       |\n",
      "|    ep_rew_mean        | 19       |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.499   |\n",
      "|    explained_variance | -0.656   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 0.00478  |\n",
      "|    value_loss         | 0.000255 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 21.2     |\n",
      "|    ep_rew_mean        | 21.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.366   |\n",
      "|    explained_variance | -2.03    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 0.00126  |\n",
      "|    value_loss         | 2.72e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 24.4     |\n",
      "|    ep_rew_mean        | 24.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.4     |\n",
      "|    explained_variance | -10.6    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 0.0133   |\n",
      "|    value_loss         | 0.000393 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 27.4     |\n",
      "|    ep_rew_mean        | 27.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.411   |\n",
      "|    explained_variance | -6.13    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | 0.00295  |\n",
      "|    value_loss         | 6.8e-05  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 31        |\n",
      "|    ep_rew_mean        | 31        |\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 87        |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.335    |\n",
      "|    explained_variance | -1.02     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | -0.000677 |\n",
      "|    value_loss         | 4.89e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 34.8     |\n",
      "|    ep_rew_mean        | 34.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.43    |\n",
      "|    explained_variance | -1.27    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -0.0153  |\n",
      "|    value_loss         | 0.00307  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 35.6     |\n",
      "|    ep_rew_mean        | 35.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.432   |\n",
      "|    explained_variance | -1.02    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 0.0537   |\n",
      "|    value_loss         | 0.0441   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 38.1     |\n",
      "|    ep_rew_mean        | 38.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.465   |\n",
      "|    explained_variance | 0.176    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | 0.0337   |\n",
      "|    value_loss         | 0.00916  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 42.9     |\n",
      "|    ep_rew_mean        | 42.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.379   |\n",
      "|    explained_variance | -13.1    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | -0.0662  |\n",
      "|    value_loss         | 0.0104   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 47.1     |\n",
      "|    ep_rew_mean        | 47.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.344   |\n",
      "|    explained_variance | 0.147    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | -0.00492 |\n",
      "|    value_loss         | 0.000213 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 51.2     |\n",
      "|    ep_rew_mean        | 51.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.395   |\n",
      "|    explained_variance | -40      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -0.026   |\n",
      "|    value_loss         | 0.0468   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 55.8     |\n",
      "|    ep_rew_mean        | 55.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.394   |\n",
      "|    explained_variance | -9.6     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -0.986   |\n",
      "|    value_loss         | 35       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 60.4     |\n",
      "|    ep_rew_mean        | 60.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.348   |\n",
      "|    explained_variance | 0.502    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | 0.00718  |\n",
      "|    value_loss         | 0.0299   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 65.4     |\n",
      "|    ep_rew_mean        | 65.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.355   |\n",
      "|    explained_variance | 0.682    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 0.00547  |\n",
      "|    value_loss         | 0.000101 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 64.9     |\n",
      "|    ep_rew_mean        | 64.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.524   |\n",
      "|    explained_variance | -1.28    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | 0.0373   |\n",
      "|    value_loss         | 0.00891  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 63.5     |\n",
      "|    ep_rew_mean        | 63.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.413   |\n",
      "|    explained_variance | 0.187    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | 0.0127   |\n",
      "|    value_loss         | 0.00926  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 65.9     |\n",
      "|    ep_rew_mean        | 65.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.395   |\n",
      "|    explained_variance | 0.775    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -0.0134  |\n",
      "|    value_loss         | 0.000252 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 70.8     |\n",
      "|    ep_rew_mean        | 70.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.45    |\n",
      "|    explained_variance | -12.7    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | 0.00217  |\n",
      "|    value_loss         | 0.000499 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 74       |\n",
      "|    ep_rew_mean        | 74       |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.422   |\n",
      "|    explained_variance | -3.84    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 0.000175 |\n",
      "|    value_loss         | 5.45e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 78.4      |\n",
      "|    ep_rew_mean        | 78.4      |\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 11300     |\n",
      "|    time_elapsed       | 99        |\n",
      "|    total_timesteps    | 56500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.494    |\n",
      "|    explained_variance | 0.367     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11299     |\n",
      "|    policy_loss        | -0.000837 |\n",
      "|    value_loss         | 1.13e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 82.8     |\n",
      "|    ep_rew_mean        | 82.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.398   |\n",
      "|    explained_variance | -270     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | 0.000945 |\n",
      "|    value_loss         | 0.000123 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 87.1     |\n",
      "|    ep_rew_mean        | 87.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.379   |\n",
      "|    explained_variance | -257     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | 0.00411  |\n",
      "|    value_loss         | 0.000403 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 91.8     |\n",
      "|    ep_rew_mean        | 91.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.425   |\n",
      "|    explained_variance | -1.06    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | -0.00078 |\n",
      "|    value_loss         | 4.79e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 96.2     |\n",
      "|    ep_rew_mean        | 96.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.418   |\n",
      "|    explained_variance | -26.3    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 0.00161  |\n",
      "|    value_loss         | 6.4e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 101      |\n",
      "|    ep_rew_mean        | 101      |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.324   |\n",
      "|    explained_variance | -3.5e+03 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | 0.00344  |\n",
      "|    value_loss         | 0.000196 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 105      |\n",
      "|    ep_rew_mean        | 105      |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.411   |\n",
      "|    explained_variance | -513     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | -1.1e-05 |\n",
      "|    value_loss         | 1.72e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 110      |\n",
      "|    ep_rew_mean        | 110      |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.491   |\n",
      "|    explained_variance | -12.6    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | 0.00181  |\n",
      "|    value_loss         | 9.25e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 114      |\n",
      "|    ep_rew_mean        | 114      |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.355   |\n",
      "|    explained_variance | -9.46    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -0.00116 |\n",
      "|    value_loss         | 6.59e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 118      |\n",
      "|    ep_rew_mean        | 118      |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.538   |\n",
      "|    explained_variance | -4.52    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | -0.00226 |\n",
      "|    value_loss         | 5.15e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 120      |\n",
      "|    ep_rew_mean        | 120      |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.405   |\n",
      "|    explained_variance | -7.34    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | -0.00222 |\n",
      "|    value_loss         | 0.000505 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 124       |\n",
      "|    ep_rew_mean        | 124       |\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 12400     |\n",
      "|    time_elapsed       | 109       |\n",
      "|    total_timesteps    | 62000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.551    |\n",
      "|    explained_variance | -13.4     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12399     |\n",
      "|    policy_loss        | -0.000734 |\n",
      "|    value_loss         | 5.47e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 129       |\n",
      "|    ep_rew_mean        | 129       |\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 12500     |\n",
      "|    time_elapsed       | 110       |\n",
      "|    total_timesteps    | 62500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.541    |\n",
      "|    explained_variance | -3.39     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12499     |\n",
      "|    policy_loss        | -0.000856 |\n",
      "|    value_loss         | 2.18e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 133      |\n",
      "|    ep_rew_mean        | 133      |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.524   |\n",
      "|    explained_variance | -10.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | 0.000355 |\n",
      "|    value_loss         | 3.01e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 138       |\n",
      "|    ep_rew_mean        | 138       |\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 12700     |\n",
      "|    time_elapsed       | 112       |\n",
      "|    total_timesteps    | 63500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.525    |\n",
      "|    explained_variance | 0.501     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12699     |\n",
      "|    policy_loss        | -0.000735 |\n",
      "|    value_loss         | 1.73e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 142      |\n",
      "|    ep_rew_mean        | 142      |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.402   |\n",
      "|    explained_variance | -5.56    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | -0.00113 |\n",
      "|    value_loss         | 0.000102 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 147       |\n",
      "|    ep_rew_mean        | 147       |\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 12900     |\n",
      "|    time_elapsed       | 113       |\n",
      "|    total_timesteps    | 64500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.448    |\n",
      "|    explained_variance | -0.317    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12899     |\n",
      "|    policy_loss        | -0.000201 |\n",
      "|    value_loss         | 1.97e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 151      |\n",
      "|    ep_rew_mean        | 151      |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.34    |\n",
      "|    explained_variance | -4.29    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -0.00354 |\n",
      "|    value_loss         | 6.06e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 156      |\n",
      "|    ep_rew_mean        | 156      |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.344   |\n",
      "|    explained_variance | -29.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -0.00205 |\n",
      "|    value_loss         | 1.1e-05  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 160       |\n",
      "|    ep_rew_mean        | 160       |\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 13200     |\n",
      "|    time_elapsed       | 116       |\n",
      "|    total_timesteps    | 66000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.249    |\n",
      "|    explained_variance | -0.851    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13199     |\n",
      "|    policy_loss        | -0.000263 |\n",
      "|    value_loss         | 1.5e-05   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 165       |\n",
      "|    ep_rew_mean        | 165       |\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 13300     |\n",
      "|    time_elapsed       | 117       |\n",
      "|    total_timesteps    | 66500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.428    |\n",
      "|    explained_variance | -13.9     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13299     |\n",
      "|    policy_loss        | -0.000254 |\n",
      "|    value_loss         | 3.56e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 170      |\n",
      "|    ep_rew_mean        | 170      |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.394   |\n",
      "|    explained_variance | 0.192    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | 0.000994 |\n",
      "|    value_loss         | 7e-06    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 174      |\n",
      "|    ep_rew_mean        | 174      |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.327   |\n",
      "|    explained_variance | -6.78    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | 0.000541 |\n",
      "|    value_loss         | 1.83e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 179      |\n",
      "|    ep_rew_mean        | 179      |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.431   |\n",
      "|    explained_variance | -43.5    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | -0.00164 |\n",
      "|    value_loss         | 8.75e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 184      |\n",
      "|    ep_rew_mean        | 184      |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.406   |\n",
      "|    explained_variance | -4.54    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | 0.000188 |\n",
      "|    value_loss         | 1.87e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 189      |\n",
      "|    ep_rew_mean        | 189      |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.432   |\n",
      "|    explained_variance | -205     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -0.00152 |\n",
      "|    value_loss         | 9.09e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 194      |\n",
      "|    ep_rew_mean        | 194      |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.328   |\n",
      "|    explained_variance | -9.14    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | 0.00109  |\n",
      "|    value_loss         | 1.21e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 199      |\n",
      "|    ep_rew_mean        | 199      |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.47    |\n",
      "|    explained_variance | -881     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | 0.00303  |\n",
      "|    value_loss         | 0.000352 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 203      |\n",
      "|    ep_rew_mean        | 203      |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.508   |\n",
      "|    explained_variance | -6.03    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -0.00726 |\n",
      "|    value_loss         | 0.000228 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 208      |\n",
      "|    ep_rew_mean        | 208      |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.422   |\n",
      "|    explained_variance | -183     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | -0.00275 |\n",
      "|    value_loss         | 4.08e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 213       |\n",
      "|    ep_rew_mean        | 213       |\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 14300     |\n",
      "|    time_elapsed       | 126       |\n",
      "|    total_timesteps    | 71500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.328    |\n",
      "|    explained_variance | -4.65     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14299     |\n",
      "|    policy_loss        | -0.000677 |\n",
      "|    value_loss         | 1.1e-05   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 218      |\n",
      "|    ep_rew_mean        | 218      |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.459   |\n",
      "|    explained_variance | -2.99    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | -0.00107 |\n",
      "|    value_loss         | 6.4e-06  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 223      |\n",
      "|    ep_rew_mean        | 223      |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.477   |\n",
      "|    explained_variance | -19.3    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 0.000261 |\n",
      "|    value_loss         | 2.09e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 228      |\n",
      "|    ep_rew_mean        | 228      |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.17    |\n",
      "|    explained_variance | -108     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | -0.0105  |\n",
      "|    value_loss         | 7.21e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 233      |\n",
      "|    ep_rew_mean        | 233      |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.24    |\n",
      "|    explained_variance | -4.25    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | 0.00348  |\n",
      "|    value_loss         | 0.000109 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 238      |\n",
      "|    ep_rew_mean        | 238      |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.41    |\n",
      "|    explained_variance | -11.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | -0.00042 |\n",
      "|    value_loss         | 6.4e-06  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 243       |\n",
      "|    ep_rew_mean        | 243       |\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 14900     |\n",
      "|    time_elapsed       | 131       |\n",
      "|    total_timesteps    | 74500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.45     |\n",
      "|    explained_variance | -9.4      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14899     |\n",
      "|    policy_loss        | -0.000673 |\n",
      "|    value_loss         | 8.24e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 248       |\n",
      "|    ep_rew_mean        | 248       |\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 15000     |\n",
      "|    time_elapsed       | 132       |\n",
      "|    total_timesteps    | 75000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.314    |\n",
      "|    explained_variance | -1.06e+03 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14999     |\n",
      "|    policy_loss        | 0.00193   |\n",
      "|    value_loss         | 7.14e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 252       |\n",
      "|    ep_rew_mean        | 252       |\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 15100     |\n",
      "|    time_elapsed       | 133       |\n",
      "|    total_timesteps    | 75500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.439    |\n",
      "|    explained_variance | -0.555    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15099     |\n",
      "|    policy_loss        | -0.000391 |\n",
      "|    value_loss         | 1.29e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 257      |\n",
      "|    ep_rew_mean        | 257      |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.349   |\n",
      "|    explained_variance | 0.92     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | -3.5e-05 |\n",
      "|    value_loss         | 2.79e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 262       |\n",
      "|    ep_rew_mean        | 262       |\n",
      "| time/                 |           |\n",
      "|    fps                | 567       |\n",
      "|    iterations         | 15300     |\n",
      "|    time_elapsed       | 134       |\n",
      "|    total_timesteps    | 76500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.421    |\n",
      "|    explained_variance | -574      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15299     |\n",
      "|    policy_loss        | -0.000925 |\n",
      "|    value_loss         | 5.22e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 267       |\n",
      "|    ep_rew_mean        | 267       |\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 15400     |\n",
      "|    time_elapsed       | 136       |\n",
      "|    total_timesteps    | 77000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.377    |\n",
      "|    explained_variance | -1.37e+03 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15399     |\n",
      "|    policy_loss        | -0.00114  |\n",
      "|    value_loss         | 7.28e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 272       |\n",
      "|    ep_rew_mean        | 272       |\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 15500     |\n",
      "|    time_elapsed       | 137       |\n",
      "|    total_timesteps    | 77500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.193    |\n",
      "|    explained_variance | -138      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15499     |\n",
      "|    policy_loss        | -6.62e-08 |\n",
      "|    value_loss         | 4.78e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 277      |\n",
      "|    ep_rew_mean        | 277      |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.405   |\n",
      "|    explained_variance | -1.14    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | -0.00228 |\n",
      "|    value_loss         | 4.11e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 281       |\n",
      "|    ep_rew_mean        | 281       |\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 15700     |\n",
      "|    time_elapsed       | 139       |\n",
      "|    total_timesteps    | 78500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.36     |\n",
      "|    explained_variance | -5.12     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15699     |\n",
      "|    policy_loss        | -0.000851 |\n",
      "|    value_loss         | 2.09e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 286      |\n",
      "|    ep_rew_mean        | 286      |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.125   |\n",
      "|    explained_variance | -8.45    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 0.00704  |\n",
      "|    value_loss         | 0.000813 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 291      |\n",
      "|    ep_rew_mean        | 291      |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.343   |\n",
      "|    explained_variance | -29.1    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -0.00294 |\n",
      "|    value_loss         | 1.63e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 295      |\n",
      "|    ep_rew_mean        | 295      |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.417   |\n",
      "|    explained_variance | -8.28    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | -0.00192 |\n",
      "|    value_loss         | 1.39e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 300       |\n",
      "|    ep_rew_mean        | 300       |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 16100     |\n",
      "|    time_elapsed       | 143       |\n",
      "|    total_timesteps    | 80500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.361    |\n",
      "|    explained_variance | -31.2     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16099     |\n",
      "|    policy_loss        | -0.000142 |\n",
      "|    value_loss         | 3.47e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 304      |\n",
      "|    ep_rew_mean        | 304      |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.424   |\n",
      "|    explained_variance | -1.17    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | 0.000672 |\n",
      "|    value_loss         | 1.41e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 309       |\n",
      "|    ep_rew_mean        | 309       |\n",
      "| time/                 |           |\n",
      "|    fps                | 560       |\n",
      "|    iterations         | 16300     |\n",
      "|    time_elapsed       | 145       |\n",
      "|    total_timesteps    | 81500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.437    |\n",
      "|    explained_variance | -9.73     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16299     |\n",
      "|    policy_loss        | -0.000759 |\n",
      "|    value_loss         | 4.93e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 313      |\n",
      "|    ep_rew_mean        | 313      |\n",
      "| time/                 |          |\n",
      "|    fps                | 560      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.421   |\n",
      "|    explained_variance | 0.601    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | -0.00163 |\n",
      "|    value_loss         | 2.3e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 317      |\n",
      "|    ep_rew_mean        | 317      |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.275   |\n",
      "|    explained_variance | 0.57     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | 4.61e-05 |\n",
      "|    value_loss         | 4.18e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 320      |\n",
      "|    ep_rew_mean        | 320      |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.302   |\n",
      "|    explained_variance | -47.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | -0.00462 |\n",
      "|    value_loss         | 6.78e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 324      |\n",
      "|    ep_rew_mean        | 324      |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.358   |\n",
      "|    explained_variance | -3.29    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | 3.24e-05 |\n",
      "|    value_loss         | 2.59e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 327      |\n",
      "|    ep_rew_mean        | 327      |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.363   |\n",
      "|    explained_variance | -3.49    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 0.00218  |\n",
      "|    value_loss         | 0.000128 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 331      |\n",
      "|    ep_rew_mean        | 331      |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.349   |\n",
      "|    explained_variance | 0.566    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | 0.000234 |\n",
      "|    value_loss         | 2.37e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 334       |\n",
      "|    ep_rew_mean        | 334       |\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 17000     |\n",
      "|    time_elapsed       | 151       |\n",
      "|    total_timesteps    | 85000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.425    |\n",
      "|    explained_variance | -43       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16999     |\n",
      "|    policy_loss        | -7.73e-05 |\n",
      "|    value_loss         | 9.34e-08  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 338      |\n",
      "|    ep_rew_mean        | 338      |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.348   |\n",
      "|    explained_variance | -0.925   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -0.00173 |\n",
      "|    value_loss         | 2.14e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 341      |\n",
      "|    ep_rew_mean        | 341      |\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.221   |\n",
      "|    explained_variance | -8.85    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -0.00875 |\n",
      "|    value_loss         | 0.000325 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 344       |\n",
      "|    ep_rew_mean        | 344       |\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 17300     |\n",
      "|    time_elapsed       | 153       |\n",
      "|    total_timesteps    | 86500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.365    |\n",
      "|    explained_variance | -11.4     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17299     |\n",
      "|    policy_loss        | -9.23e-05 |\n",
      "|    value_loss         | 1.39e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 346       |\n",
      "|    ep_rew_mean        | 346       |\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 17400     |\n",
      "|    time_elapsed       | 154       |\n",
      "|    total_timesteps    | 87000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.416    |\n",
      "|    explained_variance | -0.148    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17399     |\n",
      "|    policy_loss        | -0.000855 |\n",
      "|    value_loss         | 1.73e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 349       |\n",
      "|    ep_rew_mean        | 349       |\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 17500     |\n",
      "|    time_elapsed       | 155       |\n",
      "|    total_timesteps    | 87500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.325    |\n",
      "|    explained_variance | -14.7     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17499     |\n",
      "|    policy_loss        | -1.45e-05 |\n",
      "|    value_loss         | 2.83e-08  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 353      |\n",
      "|    ep_rew_mean        | 353      |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.429   |\n",
      "|    explained_variance | -4.52    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -6.7e-05 |\n",
      "|    value_loss         | 1.66e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 357      |\n",
      "|    ep_rew_mean        | 357      |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.148   |\n",
      "|    explained_variance | -408     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | 0.00156  |\n",
      "|    value_loss         | 3.69e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 360      |\n",
      "|    ep_rew_mean        | 360      |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.45    |\n",
      "|    explained_variance | -204     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | 0.000145 |\n",
      "|    value_loss         | 1.77e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 363      |\n",
      "|    ep_rew_mean        | 363      |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.583   |\n",
      "|    explained_variance | -7.16    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | 0.000826 |\n",
      "|    value_loss         | 2.5e-06  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 364      |\n",
      "|    ep_rew_mean        | 364      |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.487   |\n",
      "|    explained_variance | -4.54    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 0.00015  |\n",
      "|    value_loss         | 5.74e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 368      |\n",
      "|    ep_rew_mean        | 368      |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.322   |\n",
      "|    explained_variance | -5.12    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | 0.000174 |\n",
      "|    value_loss         | 9.9e-07  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 372      |\n",
      "|    ep_rew_mean        | 372      |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.341   |\n",
      "|    explained_variance | -0.367   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | 0.00332  |\n",
      "|    value_loss         | 6.08e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 376      |\n",
      "|    ep_rew_mean        | 376      |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.432   |\n",
      "|    explained_variance | -83.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 0.000485 |\n",
      "|    value_loss         | 3.86e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 382      |\n",
      "|    ep_rew_mean        | 382      |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.553   |\n",
      "|    explained_variance | -1.22    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | 0.00107  |\n",
      "|    value_loss         | 1.14e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 386      |\n",
      "|    ep_rew_mean        | 386      |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.442   |\n",
      "|    explained_variance | -0.644   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | 0.000194 |\n",
      "|    value_loss         | 1.43e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 391      |\n",
      "|    ep_rew_mean        | 391      |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.222   |\n",
      "|    explained_variance | -24.1    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | -0.00247 |\n",
      "|    value_loss         | 3.55e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 395       |\n",
      "|    ep_rew_mean        | 395       |\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 165       |\n",
      "|    total_timesteps    | 93500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.455    |\n",
      "|    explained_variance | -3.7      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | -0.000389 |\n",
      "|    value_loss         | 2.49e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 400      |\n",
      "|    ep_rew_mean        | 400      |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.287   |\n",
      "|    explained_variance | -11.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | 3.52e-05 |\n",
      "|    value_loss         | 4.96e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 405      |\n",
      "|    ep_rew_mean        | 405      |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.46    |\n",
      "|    explained_variance | -15.4    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | 0.000399 |\n",
      "|    value_loss         | 1.44e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 409      |\n",
      "|    ep_rew_mean        | 409      |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.262   |\n",
      "|    explained_variance | 0.58     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 8.23e-05 |\n",
      "|    value_loss         | 1.31e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 414       |\n",
      "|    ep_rew_mean        | 414       |\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 19100     |\n",
      "|    time_elapsed       | 169       |\n",
      "|    total_timesteps    | 95500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.29     |\n",
      "|    explained_variance | 0.834     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19099     |\n",
      "|    policy_loss        | -2.63e-05 |\n",
      "|    value_loss         | 9.34e-08  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 419      |\n",
      "|    ep_rew_mean        | 419      |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.514   |\n",
      "|    explained_variance | -22.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | 6.38e-05 |\n",
      "|    value_loss         | 2.51e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 424      |\n",
      "|    ep_rew_mean        | 424      |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.456   |\n",
      "|    explained_variance | 0.15     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 2.9e-05  |\n",
      "|    value_loss         | 1.22e-08 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 428      |\n",
      "|    ep_rew_mean        | 428      |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.347   |\n",
      "|    explained_variance | 0.324    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | 7.55e-05 |\n",
      "|    value_loss         | 1.36e-08 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 433      |\n",
      "|    ep_rew_mean        | 433      |\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.474   |\n",
      "|    explained_variance | -130     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 3.16e-05 |\n",
      "|    value_loss         | 8.73e-08 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 438      |\n",
      "|    ep_rew_mean        | 438      |\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.474   |\n",
      "|    explained_variance | -106     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | 8.45e-06 |\n",
      "|    value_loss         | 1.19e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 443       |\n",
      "|    ep_rew_mean        | 443       |\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 19700     |\n",
      "|    time_elapsed       | 174       |\n",
      "|    total_timesteps    | 98500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.372    |\n",
      "|    explained_variance | -1.43     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19699     |\n",
      "|    policy_loss        | -0.000199 |\n",
      "|    value_loss         | 3.45e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 447      |\n",
      "|    ep_rew_mean        | 447      |\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.404   |\n",
      "|    explained_variance | -408     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | 0.000116 |\n",
      "|    value_loss         | 1.39e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 452      |\n",
      "|    ep_rew_mean        | 452      |\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.476   |\n",
      "|    explained_variance | -31.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | 5.45e-05 |\n",
      "|    value_loss         | 3.83e-08 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 456      |\n",
      "|    ep_rew_mean        | 456      |\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.48    |\n",
      "|    explained_variance | -3.5     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | 1.98e-05 |\n",
      "|    value_loss         | 3.86e-08 |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train(environment=\"CartPole-v1\", total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9cd1d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\.venv\\Lib\\site-packages\\gymnasium\\wrappers\\rendering.py:296: UserWarning: \u001b[33mWARN: Overwriting existing videos at c:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\videos_CartPole_A2c folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward: 500.00\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d004b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Value Function: [-0.6 -0.2  0.4  1. ]\n",
      "Calculated Value of State 1 (V(s=1)): -0.0900\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Environment and Policy Definition ---\n",
    "\n",
    "# States: 0, 1, 2, 3 (Goal)\n",
    "num_states = 4\n",
    "\n",
    "# Actions: 0 for 'left', 1 for 'right'\n",
    "num_actions = 2\n",
    "\n",
    "# Discount factor\n",
    "gamma = 0.9\n",
    "\n",
    "# Let's assume we have the value function from a previous iteration\n",
    "# V(s=0)=-0.6, V(s=1)=-0.2, V(s=2)=0.4, V(s=3)=1 (Goal)\n",
    "# These are arbitrary but plausible values for demonstration.\n",
    "# The value of the terminal state is its reward.\n",
    "V = np.array([-0.6, -0.2, 0.4, 1.0])\n",
    "\n",
    "# Stochastic Policy, pi(action | state): 50% chance for each action\n",
    "# pi[state, action] = probability\n",
    "policy = np.full((num_states, num_actions), 0.5)\n",
    "\n",
    "# --- Bellman Equation Calculation for State 1 ---\n",
    "\n",
    "# The state we want to calculate the value for\n",
    "current_state = 1\n",
    "value_of_current_state = 0.0\n",
    "\n",
    "# Sum over all possible actions ('left', 'right')\n",
    "for action in [0, 1]:  # 0: left, 1: right\n",
    "    # Get the probability of taking this action under the policy\n",
    "    action_prob = policy[current_state, action]\n",
    "\n",
    "    # --- Now, calculate the expected value for taking this action ---\n",
    "    # This involves summing over all possible outcomes (next states)\n",
    "    # In our \"windy\" environment, intending to go 'right' has a 50% chance of\n",
    "    # actually going left and 50% chance of going right.\n",
    "\n",
    "    expected_value_for_action = 0.0\n",
    "\n",
    "    # Define the stochastic transitions for our windy gridworld\n",
    "    # P(next_state | current_state, action)\n",
    "    # In this specific example, the outcome is independent of the chosen action\n",
    "    transitions = {\n",
    "        'left': {'next_state': 0, 'prob': 0.5, 'reward': 0},\n",
    "        'right': {'next_state': 2, 'prob': 0.5, 'reward': 0}\n",
    "    }\n",
    "\n",
    "    # Sum over all possible next states\n",
    "    for outcome in transitions.values():\n",
    "        next_state = outcome['next_state']\n",
    "        transition_prob = outcome['prob']\n",
    "        reward = outcome['reward']\n",
    "\n",
    "        # Core of the Bellman equation: r + gamma * V(s')\n",
    "        q_value = reward + gamma * V[next_state]\n",
    "        expected_value_for_action += transition_prob * q_value\n",
    "\n",
    "    # Weight the expected value of the action by the probability of taking it\n",
    "    value_of_current_state += action_prob * expected_value_for_action\n",
    "\n",
    "print(f\"Current Value Function: {V}\")\n",
    "print(f\"Calculated Value of State {current_state} (V(s=1)): {value_of_current_state:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cea4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, VecVideoRecorder\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "import numpy as np\n",
    "#import ale_py\n",
    "#gym.register_envs(ale_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09c1fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(environment: gym.Env, total_timesteps: int):\n",
    "    \"\"\"Function to train an A2C agent on a specified environment for a given number of timesteps.\"\"\"\n",
    "    vec_env = make_atari_env(environment, n_envs=4, seed=0)\n",
    "    vec_env = VecFrameStack(vec_env, n_stack=4)\n",
    "    model = A2C(\"CnnPolicy\", vec_env, verbose=1)\n",
    "    model.learn(total_timesteps=total_timesteps)\n",
    "    model.save(\"Pong_A2C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "663ca8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 585      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.75    |\n",
      "|    explained_variance | 0.0472   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.0491   |\n",
      "|    value_loss         | 0.000964 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.36e+03  |\n",
      "|    ep_rew_mean        | -20.7     |\n",
      "| time/                 |           |\n",
      "|    fps                | 639       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.75     |\n",
      "|    explained_variance | -0.000508 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -0.224    |\n",
      "|    value_loss         | 0.134     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.65e+03 |\n",
      "|    ep_rew_mean        | -20.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 657      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.72    |\n",
      "|    explained_variance | -0.144   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.0929   |\n",
      "|    value_loss         | 0.00402  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.35e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 648      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.73    |\n",
      "|    explained_variance | 0.0971   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -0.275   |\n",
      "|    value_loss         | 0.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.29e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 629      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.75    |\n",
      "|    explained_variance | 0.00737  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -0.432   |\n",
      "|    value_loss         | 0.226    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.32e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 613      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.75    |\n",
      "|    explained_variance | 0.0651   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.0608   |\n",
      "|    value_loss         | 0.00161  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.27e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 606      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.74    |\n",
      "|    explained_variance | 0.196    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 0.0532   |\n",
      "|    value_loss         | 0.00118  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.25e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 599      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.77    |\n",
      "|    explained_variance | 0.066    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.0394   |\n",
      "|    value_loss         | 0.000607 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.36e+03 |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 591      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.75    |\n",
      "|    explained_variance | -3.22    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.0785   |\n",
      "|    value_loss         | 0.00409  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.36e+03 |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 584      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.75    |\n",
      "|    explained_variance | -0.0494  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.0134   |\n",
      "|    value_loss         | 0.00619  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.39e+03 |\n",
      "|    ep_rew_mean        | -20.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.7     |\n",
      "|    explained_variance | 0.955    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.0748   |\n",
      "|    value_loss         | 0.00791  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.4e+03  |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 580      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.61    |\n",
      "|    explained_variance | 0.671    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -0.217   |\n",
      "|    value_loss         | 0.0657   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.4e+03  |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 580      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.77    |\n",
      "|    explained_variance | -0.341   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.0348   |\n",
      "|    value_loss         | 0.000588 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.39e+03 |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 579      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.62    |\n",
      "|    explained_variance | -0.0487  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -0.042   |\n",
      "|    value_loss         | 0.0901   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.43e+03 |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 578      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.63    |\n",
      "|    explained_variance | 0.0902   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 0.0666   |\n",
      "|    value_loss         | 0.00208  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.42e+03 |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 577      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.75    |\n",
      "|    explained_variance | -0.00455 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -0.401   |\n",
      "|    value_loss         | 0.231    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.42e+03 |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 576      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.62    |\n",
      "|    explained_variance | -0.0372  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -0.186   |\n",
      "|    value_loss         | 0.174    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.42e+03 |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 573      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.68    |\n",
      "|    explained_variance | 0.0892   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -0.717   |\n",
      "|    value_loss         | 0.382    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.41e+03 |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 571      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.6     |\n",
      "|    explained_variance | 0.0468   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 0.0666   |\n",
      "|    value_loss         | 0.00207  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.4e+03  |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 569      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.77    |\n",
      "|    explained_variance | 0.148    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.0399   |\n",
      "|    value_loss         | 0.000593 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.4e+03  |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.51    |\n",
      "|    explained_variance | 0.316    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -0.108   |\n",
      "|    value_loss         | 0.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.42e+03 |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 555      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.64    |\n",
      "|    explained_variance | 0.656    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 0.12     |\n",
      "|    value_loss         | 0.0101   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.42e+03 |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 552      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.65    |\n",
      "|    explained_variance | 0.8      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -0.0204  |\n",
      "|    value_loss         | 0.00834  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.42e+03 |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 550      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.66    |\n",
      "|    explained_variance | -0.621   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -0.241   |\n",
      "|    value_loss         | 0.0406   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.41e+03 |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 547      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.76    |\n",
      "|    explained_variance | -5.07    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 0.128    |\n",
      "|    value_loss         | 0.00807  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.41e+03 |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 548      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.71    |\n",
      "|    explained_variance | 0.923    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 0.0279   |\n",
      "|    value_loss         | 0.00659  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.42e+03 |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 548      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.74    |\n",
      "|    explained_variance | 0.687    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -0.0719  |\n",
      "|    value_loss         | 0.0236   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.41e+03 |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 548      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.65    |\n",
      "|    explained_variance | 0.727    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 0.0292   |\n",
      "|    value_loss         | 0.00232  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.42e+03 |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 547      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.52    |\n",
      "|    explained_variance | -1.15    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 0.239    |\n",
      "|    value_loss         | 0.127    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.44e+03 |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 546      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.48    |\n",
      "|    explained_variance | 0.0916   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 0.318    |\n",
      "|    value_loss         | 0.127    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.43e+03 |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 545      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.34    |\n",
      "|    explained_variance | 0.774    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 0.116    |\n",
      "|    value_loss         | 0.0276   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.44e+03 |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 546      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.06    |\n",
      "|    explained_variance | -0.283   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -0.0194  |\n",
      "|    value_loss         | 0.318    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.44e+03 |\n",
      "|    ep_rew_mean        | -20.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 546      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.13    |\n",
      "|    explained_variance | 0.97     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -0.0137  |\n",
      "|    value_loss         | 0.00323  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.44e+03 |\n",
      "|    ep_rew_mean        | -20.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 547      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.55    |\n",
      "|    explained_variance | 0.844    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 0.0368   |\n",
      "|    value_loss         | 0.00359  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.44e+03 |\n",
      "|    ep_rew_mean        | -20.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 547      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.49    |\n",
      "|    explained_variance | 0.799    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -0.0557  |\n",
      "|    value_loss         | 0.0171   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.43e+03 |\n",
      "|    ep_rew_mean        | -20.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 547      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.35    |\n",
      "|    explained_variance | 0.568    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -0.105   |\n",
      "|    value_loss         | 0.0159   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.43e+03 |\n",
      "|    ep_rew_mean        | -20.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 547      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.31    |\n",
      "|    explained_variance | 0.806    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -0.0104  |\n",
      "|    value_loss         | 0.0031   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.43e+03 |\n",
      "|    ep_rew_mean        | -20.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 546      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.33    |\n",
      "|    explained_variance | 0.703    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -0.00921 |\n",
      "|    value_loss         | 0.0218   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.42e+03 |\n",
      "|    ep_rew_mean        | -20.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 546      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.5     |\n",
      "|    explained_variance | 0.784    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 0.182    |\n",
      "|    value_loss         | 0.0433   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.43e+03 |\n",
      "|    ep_rew_mean        | -20.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 546      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.59    |\n",
      "|    explained_variance | 0.874    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -0.0864  |\n",
      "|    value_loss         | 0.0178   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.42e+03 |\n",
      "|    ep_rew_mean        | -20.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 546      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.26    |\n",
      "|    explained_variance | 0.804    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -0.0127  |\n",
      "|    value_loss         | 0.0136   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.42e+03 |\n",
      "|    ep_rew_mean        | -20.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 546      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.43    |\n",
      "|    explained_variance | 0.949    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 0.00227  |\n",
      "|    value_loss         | 0.00238  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.42e+03 |\n",
      "|    ep_rew_mean        | -20.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 546      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.02    |\n",
      "|    explained_variance | 0.986    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 0.0515   |\n",
      "|    value_loss         | 0.00477  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.43e+03 |\n",
      "|    ep_rew_mean        | -20.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 546      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.09    |\n",
      "|    explained_variance | 0.509    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -0.137   |\n",
      "|    value_loss         | 0.0583   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.41e+03 |\n",
      "|    ep_rew_mean        | -20.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 547      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.3     |\n",
      "|    explained_variance | 0.877    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 0.0343   |\n",
      "|    value_loss         | 0.00882  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.41e+03 |\n",
      "|    ep_rew_mean        | -20.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 547      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.12    |\n",
      "|    explained_variance | 0.852    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -0.0344  |\n",
      "|    value_loss         | 0.00985  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.42e+03 |\n",
      "|    ep_rew_mean        | -20.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 547      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.46    |\n",
      "|    explained_variance | 0.259    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 0.0892   |\n",
      "|    value_loss         | 0.0177   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.42e+03 |\n",
      "|    ep_rew_mean        | -20.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 547      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.42    |\n",
      "|    explained_variance | 0.902    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -0.055   |\n",
      "|    value_loss         | 0.0101   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.43e+03  |\n",
      "|    ep_rew_mean        | -20.7     |\n",
      "| time/                 |           |\n",
      "|    fps                | 547       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 179       |\n",
      "|    total_timesteps    | 98000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.47     |\n",
      "|    explained_variance | 0.967     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | -0.000745 |\n",
      "|    value_loss         | 0.00477   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.43e+03 |\n",
      "|    ep_rew_mean        | -20.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 546      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.27    |\n",
      "|    explained_variance | -1.28    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -0.0688  |\n",
      "|    value_loss         | 0.0134   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.43e+03 |\n",
      "|    ep_rew_mean        | -20.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 546      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 102000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.52    |\n",
      "|    explained_variance | 0.184    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 0.0683   |\n",
      "|    value_loss         | 0.00331  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.42e+03 |\n",
      "|    ep_rew_mean        | -20.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 545      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 104000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.42    |\n",
      "|    explained_variance | 0.788    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 0.0248   |\n",
      "|    value_loss         | 0.0175   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.4e+03  |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 545      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 194      |\n",
      "|    total_timesteps    | 106000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | 0.25     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 0.206    |\n",
      "|    value_loss         | 0.0309   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.41e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 545      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 108000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.57    |\n",
      "|    explained_variance | 0.959    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -0.0118  |\n",
      "|    value_loss         | 0.00556  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.41e+03 |\n",
      "|    ep_rew_mean        | -20.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 544      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 110000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.44    |\n",
      "|    explained_variance | 0.809    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -0.00548 |\n",
      "|    value_loss         | 0.00724  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.41e+03 |\n",
      "|    ep_rew_mean        | -20.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 544      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 112000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.51    |\n",
      "|    explained_variance | 0.693    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -0.0899  |\n",
      "|    value_loss         | 0.0519   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.4e+03  |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 545      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 114000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.46    |\n",
      "|    explained_variance | 0.911    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 0.0381   |\n",
      "|    value_loss         | 0.00426  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.39e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 545      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 212      |\n",
      "|    total_timesteps    | 116000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | 0.828    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -0.0439  |\n",
      "|    value_loss         | 0.0188   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.4e+03  |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 546      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 216      |\n",
      "|    total_timesteps    | 118000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.41    |\n",
      "|    explained_variance | 0.962    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -0.0329  |\n",
      "|    value_loss         | 0.00268  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.4e+03  |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 546      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 120000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.45    |\n",
      "|    explained_variance | 0.573    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -0.208   |\n",
      "|    value_loss         | 0.0645   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.41e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 546      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 122000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.16    |\n",
      "|    explained_variance | -3.61    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 0.161    |\n",
      "|    value_loss         | 0.0372   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.4e+03  |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 546      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 124000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.806   |\n",
      "|    explained_variance | 0.742    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 0.0621   |\n",
      "|    value_loss         | 0.0265   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.39e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 546      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 126000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.22    |\n",
      "|    explained_variance | 0.707    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -0.0358  |\n",
      "|    value_loss         | 0.00528  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.39e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 546      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 234      |\n",
      "|    total_timesteps    | 128000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.05    |\n",
      "|    explained_variance | 0.851    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | -0.283   |\n",
      "|    value_loss         | 0.0671   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.4e+03  |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 545      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 238      |\n",
      "|    total_timesteps    | 130000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.998   |\n",
      "|    explained_variance | 0.784    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 0.0837   |\n",
      "|    value_loss         | 0.0177   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.4e+03  |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 544      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 132000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.47    |\n",
      "|    explained_variance | 0.83     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 0.0839   |\n",
      "|    value_loss         | 0.00721  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.4e+03  |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 544      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 246      |\n",
      "|    total_timesteps    | 134000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.1     |\n",
      "|    explained_variance | 0.785    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -0.00223 |\n",
      "|    value_loss         | 0.0351   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.41e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 543      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 250      |\n",
      "|    total_timesteps    | 136000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.3     |\n",
      "|    explained_variance | 0.946    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 0.0252   |\n",
      "|    value_loss         | 0.00699  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.41e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 542      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 254      |\n",
      "|    total_timesteps    | 138000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1       |\n",
      "|    explained_variance | 0.989    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 0.0178   |\n",
      "|    value_loss         | 0.000779 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.4e+03  |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 540      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 258      |\n",
      "|    total_timesteps    | 140000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.61    |\n",
      "|    explained_variance | 0.649    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | 0.0923   |\n",
      "|    value_loss         | 0.00595  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.4e+03  |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 539      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 263      |\n",
      "|    total_timesteps    | 142000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.26    |\n",
      "|    explained_variance | 0.343    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -0.0624  |\n",
      "|    value_loss         | 0.0437   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.4e+03  |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 537      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 267      |\n",
      "|    total_timesteps    | 144000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.76    |\n",
      "|    explained_variance | -0.00677 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -0.19    |\n",
      "|    value_loss         | 0.0964   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.4e+03  |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 535      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 272      |\n",
      "|    total_timesteps    | 146000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.6     |\n",
      "|    explained_variance | -0.648   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | 0.0578   |\n",
      "|    value_loss         | 0.00196  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.4e+03  |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 535      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 276      |\n",
      "|    total_timesteps    | 148000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.21    |\n",
      "|    explained_variance | 0.948    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -0.0513  |\n",
      "|    value_loss         | 0.0134   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.4e+03  |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 533      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 280      |\n",
      "|    total_timesteps    | 150000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.07    |\n",
      "|    explained_variance | 0.712    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -0.0783  |\n",
      "|    value_loss         | 0.0154   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.4e+03  |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 532      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 285      |\n",
      "|    total_timesteps    | 152000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.879   |\n",
      "|    explained_variance | 0.848    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -0.0277  |\n",
      "|    value_loss         | 0.0186   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.4e+03  |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 289      |\n",
      "|    total_timesteps    | 154000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.39    |\n",
      "|    explained_variance | 0.0154   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 0.227    |\n",
      "|    value_loss         | 0.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.4e+03  |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 293      |\n",
      "|    total_timesteps    | 156000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.292   |\n",
      "|    explained_variance | 0.99     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -0.00806 |\n",
      "|    value_loss         | 0.000551 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.4e+03  |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 298      |\n",
      "|    total_timesteps    | 158000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.508   |\n",
      "|    explained_variance | 0.903    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 0.0477   |\n",
      "|    value_loss         | 0.00923  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.39e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 528      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 302      |\n",
      "|    total_timesteps    | 160000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.941   |\n",
      "|    explained_variance | 0.977    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -0.032   |\n",
      "|    value_loss         | 0.0024   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.39e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 528      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 306      |\n",
      "|    total_timesteps    | 162000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.943   |\n",
      "|    explained_variance | 0.949    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -0.0108  |\n",
      "|    value_loss         | 0.00142  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.39e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 527      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 310      |\n",
      "|    total_timesteps    | 164000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.402   |\n",
      "|    explained_variance | 0.978    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 0.000243 |\n",
      "|    value_loss         | 0.00227  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.39e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 526      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 315      |\n",
      "|    total_timesteps    | 166000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.336   |\n",
      "|    explained_variance | 0.994    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 0.00291  |\n",
      "|    value_loss         | 0.000431 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.39e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 526      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 319      |\n",
      "|    total_timesteps    | 168000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.652   |\n",
      "|    explained_variance | 0.842    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 0.0268   |\n",
      "|    value_loss         | 0.0299   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.39e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 323      |\n",
      "|    total_timesteps    | 170000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.42    |\n",
      "|    explained_variance | 0.357    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 0.0501   |\n",
      "|    value_loss         | 0.00172  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.4e+03  |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 327      |\n",
      "|    total_timesteps    | 172000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.715   |\n",
      "|    explained_variance | 0.572    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -0.198   |\n",
      "|    value_loss         | 0.0388   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.41e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 331      |\n",
      "|    total_timesteps    | 174000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.951   |\n",
      "|    explained_variance | 0.467    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -0.332   |\n",
      "|    value_loss         | 0.115    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.41e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 523      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 335      |\n",
      "|    total_timesteps    | 176000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.02    |\n",
      "|    explained_variance | 0.969    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 0.0696   |\n",
      "|    value_loss         | 0.00744  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.41e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 523      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 340      |\n",
      "|    total_timesteps    | 178000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.34    |\n",
      "|    explained_variance | 0.362    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 0.0408   |\n",
      "|    value_loss         | 0.0109   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.42e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 522      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 344      |\n",
      "|    total_timesteps    | 180000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.16    |\n",
      "|    explained_variance | 0.964    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | -0.0401  |\n",
      "|    value_loss         | 0.00307  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.43e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 522      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 348      |\n",
      "|    total_timesteps    | 182000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.2     |\n",
      "|    explained_variance | 0.636    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | -0.0253  |\n",
      "|    value_loss         | 0.0358   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.43e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 521      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 352      |\n",
      "|    total_timesteps    | 184000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.05    |\n",
      "|    explained_variance | 0.511    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -0.0616  |\n",
      "|    value_loss         | 0.0563   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.45e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 521      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 356      |\n",
      "|    total_timesteps    | 186000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.16    |\n",
      "|    explained_variance | 0.933    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | 0.0759   |\n",
      "|    value_loss         | 0.0127   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.44e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 520      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 360      |\n",
      "|    total_timesteps    | 188000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.992   |\n",
      "|    explained_variance | 0.956    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 0.0166   |\n",
      "|    value_loss         | 0.00412  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.44e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 520      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 365      |\n",
      "|    total_timesteps    | 190000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.517   |\n",
      "|    explained_variance | 0.977    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | -0.0265  |\n",
      "|    value_loss         | 0.00584  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.45e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 520      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 369      |\n",
      "|    total_timesteps    | 192000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.777   |\n",
      "|    explained_variance | 0.961    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 0.0479   |\n",
      "|    value_loss         | 0.00538  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.45e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 373      |\n",
      "|    total_timesteps    | 194000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.29    |\n",
      "|    explained_variance | 0.488    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -0.192   |\n",
      "|    value_loss         | 0.0482   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.45e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 520      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 376      |\n",
      "|    total_timesteps    | 196000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.649   |\n",
      "|    explained_variance | 0.332    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 0.0598   |\n",
      "|    value_loss         | 0.164    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.45e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 520      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 380      |\n",
      "|    total_timesteps    | 198000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.817   |\n",
      "|    explained_variance | 0.987    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 0.0108   |\n",
      "|    value_loss         | 0.0012   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.46e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 520      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 384      |\n",
      "|    total_timesteps    | 200000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.15    |\n",
      "|    explained_variance | 0.312    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 0.143    |\n",
      "|    value_loss         | 0.051    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.46e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 521      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 387      |\n",
      "|    total_timesteps    | 202000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.07    |\n",
      "|    explained_variance | 0.939    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | 0.0517   |\n",
      "|    value_loss         | 0.00664  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.47e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 521      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 391      |\n",
      "|    total_timesteps    | 204000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.13    |\n",
      "|    explained_variance | 0.278    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 0.369    |\n",
      "|    value_loss         | 0.234    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.46e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 521      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 394      |\n",
      "|    total_timesteps    | 206000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.5     |\n",
      "|    explained_variance | 0.647    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | -0.0762  |\n",
      "|    value_loss         | 0.0183   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.46e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 521      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 398      |\n",
      "|    total_timesteps    | 208000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.34    |\n",
      "|    explained_variance | 0.818    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -0.198   |\n",
      "|    value_loss         | 0.0422   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.47e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 521      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 402      |\n",
      "|    total_timesteps    | 210000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.55    |\n",
      "|    explained_variance | 0.963    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | 0.0186   |\n",
      "|    value_loss         | 0.006    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.49e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 521      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 406      |\n",
      "|    total_timesteps    | 212000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.901   |\n",
      "|    explained_variance | 0.983    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | 0.0374   |\n",
      "|    value_loss         | 0.00388  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.48e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 522      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 409      |\n",
      "|    total_timesteps    | 214000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.14    |\n",
      "|    explained_variance | -2.06    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 0.0854   |\n",
      "|    value_loss         | 0.142    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.48e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 522      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 413      |\n",
      "|    total_timesteps    | 216000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.31    |\n",
      "|    explained_variance | 0.912    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -0.00962 |\n",
      "|    value_loss         | 0.0164   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.48e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 523      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 416      |\n",
      "|    total_timesteps    | 218000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.14    |\n",
      "|    explained_variance | 0.83     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | 0.00738  |\n",
      "|    value_loss         | 0.0158   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.5e+03  |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 523      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 420      |\n",
      "|    total_timesteps    | 220000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.11    |\n",
      "|    explained_variance | 0.856    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | -0.173   |\n",
      "|    value_loss         | 0.0258   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.5e+03  |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 523      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 424      |\n",
      "|    total_timesteps    | 222000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.01    |\n",
      "|    explained_variance | 0.874    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | 0.0357   |\n",
      "|    value_loss         | 0.0253   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.51e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 523      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 427      |\n",
      "|    total_timesteps    | 224000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.18    |\n",
      "|    explained_variance | 0.523    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | -0.183   |\n",
      "|    value_loss         | 0.0897   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.51e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 523      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 431      |\n",
      "|    total_timesteps    | 226000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.828   |\n",
      "|    explained_variance | 0.352    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -0.19    |\n",
      "|    value_loss         | 0.0489   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.52e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 523      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 435      |\n",
      "|    total_timesteps    | 228000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.838   |\n",
      "|    explained_variance | 0.914    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | 0.00569  |\n",
      "|    value_loss         | 0.00407  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.52e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 438      |\n",
      "|    total_timesteps    | 230000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.845   |\n",
      "|    explained_variance | 0.874    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | -0.0841  |\n",
      "|    value_loss         | 0.0128   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.51e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 442      |\n",
      "|    total_timesteps    | 232000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.07    |\n",
      "|    explained_variance | 0.789    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | -0.0706  |\n",
      "|    value_loss         | 0.0323   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.51e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 446      |\n",
      "|    total_timesteps    | 234000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.19    |\n",
      "|    explained_variance | 0.98     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 0.0872   |\n",
      "|    value_loss         | 0.00904  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.52e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 449      |\n",
      "|    total_timesteps    | 236000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.35    |\n",
      "|    explained_variance | 0.928    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -0.0628  |\n",
      "|    value_loss         | 0.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.52e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 453      |\n",
      "|    total_timesteps    | 238000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.24    |\n",
      "|    explained_variance | -0.582   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | 0.0404   |\n",
      "|    value_loss         | 0.0852   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.53e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 457      |\n",
      "|    total_timesteps    | 240000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.872   |\n",
      "|    explained_variance | 0.777    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | -0.0205  |\n",
      "|    value_loss         | 0.0154   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.53e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 461      |\n",
      "|    total_timesteps    | 242000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.61    |\n",
      "|    explained_variance | 0.225    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | 0.0444   |\n",
      "|    value_loss         | 0.00113  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.54e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 464      |\n",
      "|    total_timesteps    | 244000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.18    |\n",
      "|    explained_variance | 0.848    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 0.0318   |\n",
      "|    value_loss         | 0.0265   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.54e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 468      |\n",
      "|    total_timesteps    | 246000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.33    |\n",
      "|    explained_variance | 0.959    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 0.0243   |\n",
      "|    value_loss         | 0.00592  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.56e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 472      |\n",
      "|    total_timesteps    | 248000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.54    |\n",
      "|    explained_variance | 0.976    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | 0.0812   |\n",
      "|    value_loss         | 0.0123   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.56e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 476      |\n",
      "|    total_timesteps    | 250000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.28    |\n",
      "|    explained_variance | 0.282    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | -0.0575  |\n",
      "|    value_loss         | 0.024    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.56e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 480      |\n",
      "|    total_timesteps    | 252000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.41    |\n",
      "|    explained_variance | 0.726    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -0.0575  |\n",
      "|    value_loss         | 0.0418   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.57e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 483      |\n",
      "|    total_timesteps    | 254000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.24    |\n",
      "|    explained_variance | 0.982    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -0.0046  |\n",
      "|    value_loss         | 0.00434  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.58e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 487      |\n",
      "|    total_timesteps    | 256000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.22    |\n",
      "|    explained_variance | 0.589    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | 0.101    |\n",
      "|    value_loss         | 0.106    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.58e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 491      |\n",
      "|    total_timesteps    | 258000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.44    |\n",
      "|    explained_variance | 0.977    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | 0.0782   |\n",
      "|    value_loss         | 0.007    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.57e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 494      |\n",
      "|    total_timesteps    | 260000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.32    |\n",
      "|    explained_variance | 0.926    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -0.0536  |\n",
      "|    value_loss         | 0.0134   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.57e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 498      |\n",
      "|    total_timesteps    | 262000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.25    |\n",
      "|    explained_variance | 0.922    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -0.0602  |\n",
      "|    value_loss         | 0.01     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPongNoFrameskip-v4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m400000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(environment, total_timesteps)\u001b[39m\n\u001b[32m      4\u001b[39m vec_env = VecFrameStack(vec_env, n_stack=\u001b[32m4\u001b[39m)\n\u001b[32m      5\u001b[39m model = A2C(\u001b[33m\"\u001b[39m\u001b[33mCnnPolicy\u001b[39m\u001b[33m\"\u001b[39m, vec_env, verbose=\u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m model.save(\u001b[33m\"\u001b[39m\u001b[33mPong_A2C\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\.venv\\Lib\\site-packages\\stable_baselines3\\a2c\\a2c.py:201\u001b[39m, in \u001b[36mA2C.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlearn\u001b[39m(\n\u001b[32m    193\u001b[39m     \u001b[38;5;28mself\u001b[39m: SelfA2C,\n\u001b[32m    194\u001b[39m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    199\u001b[39m     progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    200\u001b[39m ) -> SelfA2C:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:337\u001b[39m, in \u001b[36mOnPolicyAlgorithm.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    334\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ep_info_buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    335\u001b[39m         \u001b[38;5;28mself\u001b[39m.dump_logs(iteration)\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m callback.on_training_end()\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\.venv\\Lib\\site-packages\\stable_baselines3\\a2c\\a2c.py:144\u001b[39m, in \u001b[36mA2C.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;28mself\u001b[39m._update_learning_rate(\u001b[38;5;28mself\u001b[39m.policy.optimizer)\n\u001b[32m    143\u001b[39m \u001b[38;5;66;03m# This will only loop once (get all data in one go)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrollout_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrollout_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mactions\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspaces\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDiscrete\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Convert discrete action from float to long\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\buffers.py:505\u001b[39m, in \u001b[36mRolloutBuffer.get\u001b[39m\u001b[34m(self, batch_size)\u001b[39m\n\u001b[32m    503\u001b[39m start_idx = \u001b[32m0\u001b[39m\n\u001b[32m    504\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m start_idx < \u001b[38;5;28mself\u001b[39m.buffer_size * \u001b[38;5;28mself\u001b[39m.n_envs:\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_idx\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_idx\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    506\u001b[39m     start_idx += batch_size\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\buffers.py:521\u001b[39m, in \u001b[36mRolloutBuffer._get_samples\u001b[39m\u001b[34m(self, batch_inds, env)\u001b[39m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_samples\u001b[39m(\n\u001b[32m    509\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    510\u001b[39m     batch_inds: np.ndarray,\n\u001b[32m    511\u001b[39m     env: Optional[VecNormalize] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    512\u001b[39m ) -> RolloutBufferSamples:\n\u001b[32m    513\u001b[39m     data = (\n\u001b[32m    514\u001b[39m         \u001b[38;5;28mself\u001b[39m.observations[batch_inds],\n\u001b[32m    515\u001b[39m         \u001b[38;5;28mself\u001b[39m.actions[batch_inds],\n\u001b[32m   (...)\u001b[39m\u001b[32m    519\u001b[39m         \u001b[38;5;28mself\u001b[39m.returns[batch_inds].flatten(),\n\u001b[32m    520\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m RolloutBufferSamples(*\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m.to_torch, data)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\buffers.py:139\u001b[39m, in \u001b[36mBaseBuffer.to_torch\u001b[39m\u001b[34m(self, array, copy)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[33;03mConvert a numpy array to a PyTorch tensor.\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[33;03mNote: it copies the data by default\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    136\u001b[39m \u001b[33;03m:return:\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m th.as_tensor(array, device=\u001b[38;5;28mself\u001b[39m.device)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train(environment=\"PongNoFrameskip-v4\", total_timesteps=400000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4db10dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_and_record_pong():\n",
    "    \"\"\"\n",
    "    Function to test a trained A2C agent on the Pong environment\n",
    "    and record a video of the gameplay.\n",
    "    \"\"\"\n",
    "    # Create the environment. It's recommended to use n_envs=1 for a clean video recording of one episode.\n",
    "    vec_env = make_atari_env(\"PongNoFrameskip-v4\", n_envs=1, seed=42)\n",
    "    vec_env = VecFrameStack(vec_env, n_stack=4)\n",
    "\n",
    "    # Define a function that triggers video recording.\n",
    "    # This will record the first episode (from step 0 to the end of the episode).\n",
    "    def video_trigger(step):\n",
    "        return step == 0\n",
    "\n",
    "    # Wrap the environment with the video recorder\n",
    "    vec_env = VecVideoRecorder(\n",
    "        vec_env,\n",
    "        video_folder=\"videos_Pong_a2c\",  # The folder to save the video in\n",
    "        record_video_trigger=video_trigger,\n",
    "        video_length=20000,  # A sufficiently long length to capture the whole episode\n",
    "        name_prefix=\"a2c-pong-agent\" # A prefix for the video file name\n",
    "    )\n",
    "\n",
    "    # Load the trained agent\n",
    "    model = A2C.load(\"Pong_A2C\")\n",
    "\n",
    "    # Reset the environment and get the initial observation\n",
    "    obs = vec_env.reset()\n",
    "\n",
    "    # Create an array to hold the rewards for each environment\n",
    "    rewards_per_env = np.zeros(vec_env.num_envs)\n",
    "    \n",
    "    # Create a flag to track when all environments are done\n",
    "    all_done = False\n",
    "    \n",
    "    while not all_done:\n",
    "        # Use the model to predict the action; deterministic=True for evaluation\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        \n",
    "        # Take a step in the environment\n",
    "        obs, reward, terminated, info = vec_env.step(action)\n",
    "        \n",
    "        # Add the reward to the corresponding environment's total\n",
    "        rewards_per_env += reward\n",
    "        \n",
    "        # Check if all parallel environments have finished\n",
    "        if np.all(terminated):\n",
    "            all_done = True\n",
    "\n",
    "    # Print the mean reward\n",
    "    print(f\"Mean reward: {np.mean(rewards_per_env):.2f}\")\n",
    "    \n",
    "    # Close the environment\n",
    "    vec_env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae3d67cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: -21.00\n",
      "MoviePy - Building video c:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\videos_Pong_a2c\\a2c-pong-agent-step-0-to-step-20000.mp4.\n",
      "MoviePy - Writing video c:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\videos_Pong_a2c\\a2c-pong-agent-step-0-to-step-20000.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready c:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\videos_Pong_a2c\\a2c-pong-agent-step-0-to-step-20000.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "test_and_record_pong()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ecf3951b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 539      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.75    |\n",
      "|    explained_variance | 0.0536   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.0535   |\n",
      "|    value_loss         | 0.00114  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.44e+03 |\n",
      "|    ep_rew_mean        | -20.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 567      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.73    |\n",
      "|    explained_variance | -0.00273 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.27    |\n",
      "|    value_loss         | 0.136    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.44e+03 |\n",
      "|    ep_rew_mean        | -20.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 579      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.62    |\n",
      "|    explained_variance | -0.1     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.0624   |\n",
      "|    value_loss         | 0.00202  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.31e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 584      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.6     |\n",
      "|    explained_variance | 0.0341   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -0.164   |\n",
      "|    value_loss         | 0.173    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.22e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 586      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.71    |\n",
      "|    explained_variance | -0.349   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.208    |\n",
      "|    value_loss         | 0.036    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.22e+03 |\n",
      "|    ep_rew_mean        | -20.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 587      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.64    |\n",
      "|    explained_variance | 0.348    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -0.322   |\n",
      "|    value_loss         | 0.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.26e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 590      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.17    |\n",
      "|    explained_variance | 0.505    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 0.0335   |\n",
      "|    value_loss         | 0.0688   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.23e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 593      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.49    |\n",
      "|    explained_variance | -1.97    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.138   |\n",
      "|    value_loss         | 0.0548   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.22e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 594      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.58    |\n",
      "|    explained_variance | 0.821    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -0.0503  |\n",
      "|    value_loss         | 0.015    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.19e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 594      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.52    |\n",
      "|    explained_variance | 0.933    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.0333   |\n",
      "|    value_loss         | 0.00724  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.18e+03 |\n",
      "|    ep_rew_mean        | -20.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 596      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.68    |\n",
      "|    explained_variance | 0.747    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -0.0248  |\n",
      "|    value_loss         | 0.0102   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.17e+03  |\n",
      "|    ep_rew_mean        | -20.9     |\n",
      "| time/                 |           |\n",
      "|    fps                | 597       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.13     |\n",
      "|    explained_variance | 0.971     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | -0.000111 |\n",
      "|    value_loss         | 0.00352   |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     19\u001b[39m     action, _states = model.predict(obs, deterministic=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     obs, rewards, dones, info = \u001b[43mvec_env\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     vec_env.render(\u001b[33m\"\u001b[39m\u001b[33mhuman\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:222\u001b[39m, in \u001b[36mVecEnv.step\u001b[39m\u001b[34m(self, actions)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    216\u001b[39m \u001b[33;03mStep the environments with the given action\u001b[39;00m\n\u001b[32m    217\u001b[39m \n\u001b[32m    218\u001b[39m \u001b[33;03m:param actions: the action\u001b[39;00m\n\u001b[32m    219\u001b[39m \u001b[33;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[32m    220\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    221\u001b[39m \u001b[38;5;28mself\u001b[39m.step_async(actions)\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\vec_frame_stack.py:39\u001b[39m, in \u001b[36mVecFrameStack.step_wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep_wait\u001b[39m(\n\u001b[32m     32\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     33\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m     \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]],\n\u001b[32m     38\u001b[39m ]:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     observations, rewards, dones, infos = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvenv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     observations, infos = \u001b[38;5;28mself\u001b[39m.stacked_obs.update(observations, dones, infos)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m observations, rewards, dones, infos\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:59\u001b[39m, in \u001b[36mDummyVecEnv.step_wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> VecEnvStepReturn:\n\u001b[32m     57\u001b[39m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_envs):\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m         obs, \u001b[38;5;28mself\u001b[39m.buf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m.buf_infos[env_idx] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[32m     60\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[32m     63\u001b[39m         \u001b[38;5;28mself\u001b[39m.buf_dones[env_idx] = terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\.venv\\Lib\\site-packages\\gymnasium\\core.py:327\u001b[39m, in \u001b[36mWrapper.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\n\u001b[32m    324\u001b[39m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[32m    325\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    326\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\.venv\\Lib\\site-packages\\gymnasium\\core.py:595\u001b[39m, in \u001b[36mRewardWrapper.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\n\u001b[32m    592\u001b[39m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[32m    593\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[ObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    594\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Modifies the :attr:`env` :meth:`step` reward using :meth:`self.reward`.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m595\u001b[39m     observation, reward, terminated, truncated, info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    596\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m observation, \u001b[38;5;28mself\u001b[39m.reward(reward), terminated, truncated, info\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\.venv\\Lib\\site-packages\\gymnasium\\core.py:560\u001b[39m, in \u001b[36mObservationWrapper.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    556\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\n\u001b[32m    557\u001b[39m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[32m    558\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    559\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Modifies the :attr:`env` after calling :meth:`step` using :meth:`self.observation` on the returned observations.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m     observation, reward, terminated, truncated, info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    561\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.observation(observation), reward, terminated, truncated, info\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\.venv\\Lib\\site-packages\\gymnasium\\core.py:327\u001b[39m, in \u001b[36mWrapper.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\n\u001b[32m    324\u001b[39m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[32m    325\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    326\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\atari_wrappers.py:112\u001b[39m, in \u001b[36mEpisodicLifeEnv.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: \u001b[38;5;28mint\u001b[39m) -> AtariStepReturn:\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     obs, reward, terminated, truncated, info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28mself\u001b[39m.was_real_done = terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n\u001b[32m    114\u001b[39m     \u001b[38;5;66;03m# check current lives, make loss of life terminal,\u001b[39;00m\n\u001b[32m    115\u001b[39m     \u001b[38;5;66;03m# then update lives to handle bonus lives\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\atari_wrappers.py:184\u001b[39m, in \u001b[36mMaxAndSkipEnv.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[38;5;28mself\u001b[39m._skip - \u001b[32m1\u001b[39m:\n\u001b[32m    183\u001b[39m     \u001b[38;5;28mself\u001b[39m._obs_buffer[\u001b[32m1\u001b[39m] = obs\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m total_reward += \u001b[38;5;28mfloat\u001b[39m(reward)\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3 import A2C\n",
    "\n",
    "import ale_py\n",
    "\n",
    "# There already exists an environment generator\n",
    "# that will make and wrap atari environments correctly.\n",
    "# Here we are also multi-worker training (n_envs=4 => 4 environments)\n",
    "vec_env = make_atari_env(\"PongNoFrameskip-v4\", n_envs=4, seed=0)\n",
    "# Frame-stacking with 4 frames\n",
    "vec_env = VecFrameStack(vec_env, n_stack=4)\n",
    "\n",
    "model = A2C(\"CnnPolicy\", vec_env, verbose=1)\n",
    "model.learn(total_timesteps=25_000)\n",
    "\n",
    "obs = vec_env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs, deterministic=False)\n",
    "    obs, rewards, dones, info = vec_env.step(action)\n",
    "    vec_env.render(\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64157b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value for state (0, 1): 10.0\n",
      "\n",
      "Optimal values after several iterations:\n",
      "V*((0, 0)): 9.00\n",
      "V*((0, 1)): 10.00\n",
      "V*((0, 2)): 0.00\n",
      "V*((1, 0)): 8.10\n",
      "V*((1, 1)): 9.00\n",
      "V*((1, 2)): 0.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bellman_optimality_update(state, mdp, V):\n",
    "    \"\"\"\n",
    "    Calculates the optimal value of a state using the Bellman optimality equation.\n",
    "\n",
    "    Args:\n",
    "        state: The current state.\n",
    "        mdp: A dictionary representing the Markov Decision Process with:\n",
    "             - mdp['T']: A dictionary for transition probabilities,\n",
    "                         mdp['T'][state][action] = [(prob, next_state), ...]\n",
    "             - mdp['R']: A dictionary for rewards,\n",
    "                         mdp['R'][state][action][next_state] = reward\n",
    "             - mdp['actions']: A list of all possible actions.\n",
    "             - mdp['gamma']: The discount factor.\n",
    "        V: A dictionary mapping states to their current value estimates.\n",
    "\n",
    "    Returns:\n",
    "        The updated optimal value for the given state.\n",
    "    \"\"\"\n",
    "    if state not in mdp['T']:  # Terminal state\n",
    "        return 0\n",
    "\n",
    "    action_values = []\n",
    "    for action in mdp['actions']:\n",
    "        expected_value = 0\n",
    "        if action in mdp['T'][state]:\n",
    "            for prob, next_state in mdp['T'][state][action]:\n",
    "                reward = mdp['R'].get(state, {}).get(action, {}).get(next_state, 0)\n",
    "                expected_value += prob * (reward + mdp['gamma'] * V.get(next_state, 0))\n",
    "        action_values.append(expected_value)\n",
    "\n",
    "    return np.max(action_values)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Example Usage: A simple grid world\n",
    "    # States are represented by coordinates (row, col)\n",
    "    # Actions are 'up', 'down', 'left', 'right'\n",
    "\n",
    "    mdp = {\n",
    "        'states': [(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2)],\n",
    "        'actions': ['up', 'down', 'left', 'right'],\n",
    "        'T': {\n",
    "            (0, 0): {'right': [(1.0, (0, 1))]},\n",
    "            (0, 1): {'left': [(1.0, (0, 0))], 'right': [(1.0, (0, 2))]},\n",
    "            (1, 0): {'up': [(1.0, (0, 0))], 'right': [(1.0, (1, 1))]},\n",
    "            (1, 1): {'left': [(1.0, (1, 0))], 'right': [(1.0, (1, 2))], 'up': [(1.0, (0, 1))]}\n",
    "        },\n",
    "        'R': {\n",
    "            (0, 1): {'right': {(0, 2): 10}}, # Reward for reaching the goal\n",
    "            (1, 1): {'right': {(1, 2): -10}} # Negative reward for hitting a penalty state\n",
    "        },\n",
    "        'gamma': 0.9\n",
    "    }\n",
    "\n",
    "    # Initial value estimates for all states\n",
    "    V = {state: 0 for state in mdp['states']}\n",
    "\n",
    "    # Calculate the optimal value for state (0, 1)\n",
    "    optimal_value_0_1 = bellman_optimality_update((0, 1), mdp, V)\n",
    "    print(f\"Optimal value for state (0, 1): {optimal_value_0_1}\")\n",
    "\n",
    "    # To find the true optimal values for all states, this update would be\n",
    "    # iterated until the values converge (Value Iteration).\n",
    "    for _ in range(100):\n",
    "        new_V = {}\n",
    "        for state in mdp['states']:\n",
    "            new_V[state] = bellman_optimality_update(state, mdp, V)\n",
    "        V = new_V\n",
    "\n",
    "    print(\"\\nOptimal values after several iterations:\")\n",
    "    for state, value in V.items():\n",
    "        print(f\"V*({state}): {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04f7f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "# Initialise the environment\n",
    "env = gym.make(\"BipedalWalker-v3\", render_mode=\"human\")\n",
    "\n",
    "# Reset the environment to generate the first observation\n",
    "observation, info = env.reset(seed=42)\n",
    "for _ in range(1000):\n",
    "    # this is where you would insert your policy\n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    # step (transition) through the environment with the action\n",
    "    # receiving the next observation, reward and if the episode has terminated or truncated\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # If the episode has ended then we can reset to start a new episode\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce4e171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a24a76c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(environment: gym.Env, total_timesteps: int):\n",
    "    \"\"\"Function to train an A2C agent on a specified environment for a given number of timesteps.\"\"\"\n",
    "    env = gym.make(environment,is_slippery=False, render_mode=\"rgb_array\")\n",
    "    model = DQN(\"MlpPolicy\", env, verbose=1)\n",
    "    model.learn(total_timesteps=total_timesteps)\n",
    "    model.save(\"frozenlake_dqn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a898c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 5.75     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.996    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 20486    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 23       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.38     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.989    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 11152    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 59       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.75     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.98     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 7686     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 105      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00295  |\n",
      "|    n_updates        | 1        |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.31     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.975    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 3334     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 133      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00239  |\n",
      "|    n_updates        | 8        |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.2      |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.965    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 2499     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 184      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00177  |\n",
      "|    n_updates        | 20       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.62     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.956    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 1785     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 231      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00114  |\n",
      "|    n_updates        | 32       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.82     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.953    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 1716     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 247      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000808 |\n",
      "|    n_updates        | 36       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.41     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.949    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 1697     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 269      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000725 |\n",
      "|    n_updates        | 42       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.97     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.945    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 1684     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 287      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000565 |\n",
      "|    n_updates        | 46       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.67     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.942    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 1619     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 307      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000482 |\n",
      "|    n_updates        | 51       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.61     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.936    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 1636     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 335      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000816 |\n",
      "|    n_updates        | 58       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.44     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.932    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 1604     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 357      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000624 |\n",
      "|    n_updates        | 64       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.25     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.928    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 1576     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 377      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000332 |\n",
      "|    n_updates        | 69       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6.95     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.926    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 1626     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 389      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000367 |\n",
      "|    n_updates        | 72       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.1      |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.919    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 1554     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 426      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000221 |\n",
      "|    n_updates        | 81       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.56     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.908    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 1487     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 484      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000116 |\n",
      "|    n_updates        | 95       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.34     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.905    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 1445     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 499      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000123 |\n",
      "|    n_updates        | 99       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.49     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.898    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 1447     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 539      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.54e-05 |\n",
      "|    n_updates        | 109      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.5      |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.892    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 1418     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 570      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000259 |\n",
      "|    n_updates        | 117      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.33     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.889    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 1424     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 586      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.91e-05 |\n",
      "|    n_updates        | 121      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.37     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.882    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 1462     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 619      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00015  |\n",
      "|    n_updates        | 129      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.33     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.877    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 1457     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 645      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000146 |\n",
      "|    n_updates        | 136      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.24     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.873    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 1452     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 666      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00011  |\n",
      "|    n_updates        | 141      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.19     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.869    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 1466     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 690      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.11e-05 |\n",
      "|    n_updates        | 147      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.15     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.864    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 1457     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 715      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.51e-05 |\n",
      "|    n_updates        | 153      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.31     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.857    |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 1449     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 754      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.53e-05 |\n",
      "|    n_updates        | 163      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.25     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.851    |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 1450     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 784      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000119 |\n",
      "|    n_updates        | 170      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.22     |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.843    |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 1436     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 827      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000115 |\n",
      "|    n_updates        | 181      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.24     |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.837    |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 1426     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 857      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.89e-05 |\n",
      "|    n_updates        | 189      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.08     |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.831    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 1432     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 892      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.7e-05  |\n",
      "|    n_updates        | 197      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.12     |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.821    |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 1425     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 943      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.22e-05 |\n",
      "|    n_updates        | 210      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.13     |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.818    |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 1429     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 960      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.91e-05 |\n",
      "|    n_updates        | 214      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.21     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.812    |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 1422     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 990      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.54e-05 |\n",
      "|    n_updates        | 222      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.32     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.806    |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 1420     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1019     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0151   |\n",
      "|    n_updates        | 229      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.48     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.8      |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 1418     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1055     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.19e-05 |\n",
      "|    n_updates        | 238      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.58     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.792    |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 1413     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1093     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.66e-05 |\n",
      "|    n_updates        | 248      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.74     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.785    |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 1433     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1131     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 257      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.94     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.778    |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 1411     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1171     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.22e-05 |\n",
      "|    n_updates        | 267      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.28     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.769    |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 1398     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1217     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.07e-06 |\n",
      "|    n_updates        | 279      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.12     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.765    |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 1399     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1238     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.93e-05 |\n",
      "|    n_updates        | 284      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.8      |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.76     |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 1398     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1264     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.1e-05  |\n",
      "|    n_updates        | 290      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.26     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.748    |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 1384     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1325     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.53e-05 |\n",
      "|    n_updates        | 306      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.34     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.739    |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 1377     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1373     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.55e-05 |\n",
      "|    n_updates        | 318      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.47     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.731    |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 1355     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1417     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.39e-06 |\n",
      "|    n_updates        | 329      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.67     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.724    |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 1354     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1453     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.48e-05 |\n",
      "|    n_updates        | 338      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.8      |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.715    |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 1345     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1499     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 349      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.93     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.708    |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 1343     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1538     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.38e-05 |\n",
      "|    n_updates        | 359      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.17     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.699    |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 1352     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1583     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2e-05    |\n",
      "|    n_updates        | 370      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.29     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.692    |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 1342     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1619     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.1e-05  |\n",
      "|    n_updates        | 379      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.5      |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.684    |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 1328     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1665     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.97e-06 |\n",
      "|    n_updates        | 391      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.4      |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.678    |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 1333     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1694     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.81e-05 |\n",
      "|    n_updates        | 398      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.36     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.673    |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 1333     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1720     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.76e-05 |\n",
      "|    n_updates        | 404      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.41     |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.664    |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 1322     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1768     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.3e-05  |\n",
      "|    n_updates        | 416      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.59     |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.655    |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 1323     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1816     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.15e-06 |\n",
      "|    n_updates        | 428      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.57     |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.649    |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 1315     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1849     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.62e-06 |\n",
      "|    n_updates        | 437      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.45     |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.641    |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 1314     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1888     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.77e-06 |\n",
      "|    n_updates        | 446      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.6      |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.635    |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 1317     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1920     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.03e-05 |\n",
      "|    n_updates        | 454      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.96     |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.623    |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 1309     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1986     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.85e-06 |\n",
      "|    n_updates        | 471      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.4     |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.609    |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 1295     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2056     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.6e-06  |\n",
      "|    n_updates        | 488      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.3     |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.603    |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 1288     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2090     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.09e-06 |\n",
      "|    n_updates        | 497      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.3     |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.597    |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 1285     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2123     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.93e-06 |\n",
      "|    n_updates        | 505      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.4     |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.588    |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 1277     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2167     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.57e-06 |\n",
      "|    n_updates        | 516      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.6     |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.576    |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 1268     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2233     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.26e-06 |\n",
      "|    n_updates        | 533      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.2     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.555    |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 1262     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2340     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.95e-06 |\n",
      "|    n_updates        | 559      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.5     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.546    |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 1254     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2388     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.26e-06 |\n",
      "|    n_updates        | 571      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.2     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.528    |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 1250     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2483     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.44e-06 |\n",
      "|    n_updates        | 595      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.4     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.512    |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 1247     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 2566     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.77e-06 |\n",
      "|    n_updates        | 616      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.6     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.5      |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 1241     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 2632     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.15e-06 |\n",
      "|    n_updates        | 632      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.476    |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 1232     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 2758     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.29e-06 |\n",
      "|    n_updates        | 664      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.462    |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 1225     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 2833     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.38e-06 |\n",
      "|    n_updates        | 683      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.457    |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 1223     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 2859     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.25e-06 |\n",
      "|    n_updates        | 689      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.6     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.431    |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 1219     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 2995     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.2e-06  |\n",
      "|    n_updates        | 723      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.6     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.422    |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 1216     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 3040     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.18e-06 |\n",
      "|    n_updates        | 734      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.6     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.415    |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 1214     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 3080     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.18e-06 |\n",
      "|    n_updates        | 744      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.7     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.405    |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 1210     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 3130     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.1e-06  |\n",
      "|    n_updates        | 757      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.8     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.397    |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 1203     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 3173     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.82e-06 |\n",
      "|    n_updates        | 768      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.7     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.375    |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 1186     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 3288     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 796      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.9     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.362    |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 1176     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 3360     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.7e-06  |\n",
      "|    n_updates        | 814      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.2     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.346    |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 1167     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 3441     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.84e-06 |\n",
      "|    n_updates        | 835      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.9     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.327    |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 1159     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 3542     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.8e-06  |\n",
      "|    n_updates        | 860      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.9     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.301    |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 1147     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 3681     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.99e-06 |\n",
      "|    n_updates        | 895      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.7     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.28     |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 1139     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 3788     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.87e-06 |\n",
      "|    n_updates        | 921      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.8     |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.246    |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 1127     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 3969     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.54e-06 |\n",
      "|    n_updates        | 967      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.208    |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 1109     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 4168     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.06e-06 |\n",
      "|    n_updates        | 1016     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.181    |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 1099     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 4313     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.15e-06 |\n",
      "|    n_updates        | 1053     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.6     |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.128    |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 1078     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 4588     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.57e-08 |\n",
      "|    n_updates        | 1121     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 26.7     |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.081    |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 1066     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 4837     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.59e-07 |\n",
      "|    n_updates        | 1184     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 29.1     |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 1048     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 5139     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.7e-07  |\n",
      "|    n_updates        | 1259     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 32       |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 1044     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 5539     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.03e-06 |\n",
      "|    n_updates        | 1359     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.5     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 1036     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 5939     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3e-07    |\n",
      "|    n_updates        | 1459     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.6     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 1028     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 6339     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.19e-06 |\n",
      "|    n_updates        | 1559     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.7     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 1018     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 6739     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.35e-07 |\n",
      "|    n_updates        | 1659     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 45.1     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 1012     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 7139     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.62e-08 |\n",
      "|    n_updates        | 1759     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.8     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 1006     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 7539     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.66e-07 |\n",
      "|    n_updates        | 1859     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 51.1     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 1003     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 7939     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.34e-10 |\n",
      "|    n_updates        | 1959     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.8     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 1000     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 8339     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.01e-07 |\n",
      "|    n_updates        | 2059     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 1002     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 8739     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.56e-10 |\n",
      "|    n_updates        | 2159     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 1002     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 9134     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.58e-08 |\n",
      "|    n_updates        | 2258     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.5     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 998      |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 9534     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.64e-08 |\n",
      "|    n_updates        | 2358     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68       |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 995      |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 9934     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.83e-10 |\n",
      "|    n_updates        | 2458     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.2     |\n",
      "|    ep_rew_mean      | 0.02     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 993      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 10094    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.73e-06 |\n",
      "|    n_updates        | 2498     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.3     |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 993      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 10118    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.32e-06 |\n",
      "|    n_updates        | 2504     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.8     |\n",
      "|    ep_rew_mean      | 0.1      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 992      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 10142    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.54e-06 |\n",
      "|    n_updates        | 2510     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.2     |\n",
      "|    ep_rew_mean      | 0.14     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 991      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 10166    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00851  |\n",
      "|    n_updates        | 2516     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.5     |\n",
      "|    ep_rew_mean      | 0.15     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 990      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 10289    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.05e-06 |\n",
      "|    n_updates        | 2547     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.1     |\n",
      "|    ep_rew_mean      | 0.17     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 987      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 10387    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.95e-06 |\n",
      "|    n_updates        | 2571     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.3     |\n",
      "|    ep_rew_mean      | 0.21     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 986      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 10414    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00841  |\n",
      "|    n_updates        | 2578     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.6     |\n",
      "|    ep_rew_mean      | 0.24     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 986      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 10533    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.36e-06 |\n",
      "|    n_updates        | 2608     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 0.26     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 987      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 10553    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.36e-05 |\n",
      "|    n_updates        | 2613     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 0.26     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 986      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 10565    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00688  |\n",
      "|    n_updates        | 2616     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 0.26     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 987      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 10577    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.75e-06 |\n",
      "|    n_updates        | 2619     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 0.26     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 987      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 10589    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00673  |\n",
      "|    n_updates        | 2622     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 0.26     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 988      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 10674    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.61e-06 |\n",
      "|    n_updates        | 2643     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.5     |\n",
      "|    ep_rew_mean      | 0.26     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 987      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 10891    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.05e-05 |\n",
      "|    n_updates        | 2697     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 51.9     |\n",
      "|    ep_rew_mean      | 0.26     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 987      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 11124    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.73e-06 |\n",
      "|    n_updates        | 2755     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50.1     |\n",
      "|    ep_rew_mean      | 0.26     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 988      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 11351    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00407  |\n",
      "|    n_updates        | 2812     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.3     |\n",
      "|    ep_rew_mean      | 0.27     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 985      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 11573    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00341  |\n",
      "|    n_updates        | 2868     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44.5     |\n",
      "|    ep_rew_mean      | 0.27     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 984      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 11585    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.72e-07 |\n",
      "|    n_updates        | 2871     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.5     |\n",
      "|    ep_rew_mean      | 0.27     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 984      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 11694    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.69e-06 |\n",
      "|    n_updates        | 2898     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.7     |\n",
      "|    ep_rew_mean      | 0.27     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 984      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 11706    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.73e-06 |\n",
      "|    n_updates        | 2901     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.4     |\n",
      "|    ep_rew_mean      | 0.28     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 984      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 11874    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.25e-06 |\n",
      "|    n_updates        | 2943     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 31.5     |\n",
      "|    ep_rew_mean      | 0.28     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 984      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 11886    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.95e-06 |\n",
      "|    n_updates        | 2946     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 27.6     |\n",
      "|    ep_rew_mean      | 0.28     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 984      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 11898    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.43e-06 |\n",
      "|    n_updates        | 2949     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 0.28     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 983      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 11912    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.64e-07 |\n",
      "|    n_updates        | 2952     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.6     |\n",
      "|    ep_rew_mean      | 0.29     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 981      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 12199    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.11e-07 |\n",
      "|    n_updates        | 3024     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 0.28     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 979      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 12438    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00154  |\n",
      "|    n_updates        | 3084     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 26       |\n",
      "|    ep_rew_mean      | 0.24     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 977      |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 12717    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000169 |\n",
      "|    n_updates        | 3154     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 27.9     |\n",
      "|    ep_rew_mean      | 0.22     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 975      |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 12928    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.73e-07 |\n",
      "|    n_updates        | 3206     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 29.6     |\n",
      "|    ep_rew_mean      | 0.21     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 516      |\n",
      "|    fps              | 973      |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 13129    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.88e-07 |\n",
      "|    n_updates        | 3257     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30.8     |\n",
      "|    ep_rew_mean      | 0.21     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 972      |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 13369    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000516 |\n",
      "|    n_updates        | 3317     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 31.7     |\n",
      "|    ep_rew_mean      | 0.21     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 524      |\n",
      "|    fps              | 971      |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 13559    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.89e-07 |\n",
      "|    n_updates        | 3364     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.2     |\n",
      "|    ep_rew_mean      | 0.18     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 528      |\n",
      "|    fps              | 970      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 13832    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.37e-07 |\n",
      "|    n_updates        | 3432     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.4     |\n",
      "|    ep_rew_mean      | 0.17     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 532      |\n",
      "|    fps              | 971      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 13970    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.31e-07 |\n",
      "|    n_updates        | 3467     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.1     |\n",
      "|    ep_rew_mean      | 0.15     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 536      |\n",
      "|    fps              | 971      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 14166    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.66e-08 |\n",
      "|    n_updates        | 3516     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37       |\n",
      "|    ep_rew_mean      | 0.16     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 970      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 14269    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.06e-07 |\n",
      "|    n_updates        | 3542     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.7     |\n",
      "|    ep_rew_mean      | 0.16     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 544      |\n",
      "|    fps              | 970      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 14544    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.53e-08 |\n",
      "|    n_updates        | 3610     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.6     |\n",
      "|    ep_rew_mean      | 0.16     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 548      |\n",
      "|    fps              | 969      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 14749    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.76e-08 |\n",
      "|    n_updates        | 3662     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.2     |\n",
      "|    ep_rew_mean      | 0.17     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 552      |\n",
      "|    fps              | 968      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 14895    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.71e-06 |\n",
      "|    n_updates        | 3698     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.3     |\n",
      "|    ep_rew_mean      | 0.18     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 556      |\n",
      "|    fps              | 968      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 15023    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.19e-06 |\n",
      "|    n_updates        | 3730     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.7     |\n",
      "|    ep_rew_mean      | 0.18     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 15294    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.76e-08 |\n",
      "|    n_updates        | 3798     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.1     |\n",
      "|    ep_rew_mean      | 0.18     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 564      |\n",
      "|    fps              | 961      |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 15563    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.26e-08 |\n",
      "|    n_updates        | 3865     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41       |\n",
      "|    ep_rew_mean      | 0.19     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 568      |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 15672    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.9e-08  |\n",
      "|    n_updates        | 3892     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.4     |\n",
      "|    ep_rew_mean      | 0.19     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 572      |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 15925    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.2e-07  |\n",
      "|    n_updates        | 3956     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 45.9     |\n",
      "|    ep_rew_mean      | 0.2      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 576      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 16280    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.04e-08 |\n",
      "|    n_updates        | 4044     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.7     |\n",
      "|    ep_rew_mean      | 0.2      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 16572    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.43e-08 |\n",
      "|    n_updates        | 4117     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50.2     |\n",
      "|    ep_rew_mean      | 0.19     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 584      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 16892    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.82e-08 |\n",
      "|    n_updates        | 4197     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.7     |\n",
      "|    ep_rew_mean      | 0.19     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 588      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 17159    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.88e-07 |\n",
      "|    n_updates        | 4264     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.8     |\n",
      "|    ep_rew_mean      | 0.19     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 592      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 17477    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.89e-09 |\n",
      "|    n_updates        | 4344     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 0.2      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 596      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 17774    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.7e-08  |\n",
      "|    n_updates        | 4418     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 0.2      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 18091    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6e-09    |\n",
      "|    n_updates        | 4497     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 0.22     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 604      |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 18259    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.27e-09 |\n",
      "|    n_updates        | 4539     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 0.22     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 608      |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 18450    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.87e-08 |\n",
      "|    n_updates        | 4587     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 0.2      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 612      |\n",
      "|    fps              | 954      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 18763    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.52e-09 |\n",
      "|    n_updates        | 4665     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 0.18     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 616      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 18921    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.62e-10 |\n",
      "|    n_updates        | 4705     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 0.18     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 19192    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.8e-10  |\n",
      "|    n_updates        | 4772     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 0.16     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 624      |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 19388    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.28e-08 |\n",
      "|    n_updates        | 4821     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 0.15     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 628      |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 19500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.93e-09 |\n",
      "|    n_updates        | 4849     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 0.13     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 632      |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 19807    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.19e-09 |\n",
      "|    n_updates        | 4926     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 0.14     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 636      |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 20037    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00131  |\n",
      "|    n_updates        | 4984     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 0.13     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 20050    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.93e-05 |\n",
      "|    n_updates        | 4987     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.2     |\n",
      "|    ep_rew_mean      | 0.13     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 644      |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 20062    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.12e-05 |\n",
      "|    n_updates        | 4990     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.3     |\n",
      "|    ep_rew_mean      | 0.13     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 648      |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 20075    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.54e-05 |\n",
      "|    n_updates        | 4993     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 51.9     |\n",
      "|    ep_rew_mean      | 0.12     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 652      |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 20088    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.19e-05 |\n",
      "|    n_updates        | 4996     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50.8     |\n",
      "|    ep_rew_mean      | 0.11     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 656      |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 20100    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.57e-05 |\n",
      "|    n_updates        | 4999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.2     |\n",
      "|    ep_rew_mean      | 0.11     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 20112    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000477 |\n",
      "|    n_updates        | 5002     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 45.7     |\n",
      "|    ep_rew_mean      | 0.11     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 664      |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20129    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.48e-05 |\n",
      "|    n_updates        | 5007     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44.7     |\n",
      "|    ep_rew_mean      | 0.09     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 668      |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20141    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.17e-06 |\n",
      "|    n_updates        | 5010     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.3     |\n",
      "|    ep_rew_mean      | 0.09     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 672      |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20155    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.8e-06  |\n",
      "|    n_updates        | 5013     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.9     |\n",
      "|    ep_rew_mean      | 0.08     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 676      |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20171    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0065   |\n",
      "|    n_updates        | 5017     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.1     |\n",
      "|    ep_rew_mean      | 0.08     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20179    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.95e-07 |\n",
      "|    n_updates        | 5019     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 33.1     |\n",
      "|    ep_rew_mean      | 0.11     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 684      |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20199    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.82e-06 |\n",
      "|    n_updates        | 5024     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30.5     |\n",
      "|    ep_rew_mean      | 0.12     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 688      |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20211    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.06e-05 |\n",
      "|    n_updates        | 5027     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 27.4     |\n",
      "|    ep_rew_mean      | 0.12     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 692      |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20219    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.16e-05 |\n",
      "|    n_updates        | 5029     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.6     |\n",
      "|    ep_rew_mean      | 0.11     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 696      |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20230    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.61e-06 |\n",
      "|    n_updates        | 5032     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 0.1      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20242    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.14e-05 |\n",
      "|    n_updates        | 5035     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.9     |\n",
      "|    ep_rew_mean      | 0.07     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 704      |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20254    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.01e-05 |\n",
      "|    n_updates        | 5038     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.2     |\n",
      "|    ep_rew_mean      | 0.07     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 708      |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20266    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.47e-06 |\n",
      "|    n_updates        | 5041     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.2     |\n",
      "|    ep_rew_mean      | 0.07     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 712      |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20278    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.14e-06 |\n",
      "|    n_updates        | 5044     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 716      |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20287    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.47e-06 |\n",
      "|    n_updates        | 5046     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11       |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20295    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.27e-06 |\n",
      "|    n_updates        | 5048     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.15     |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 724      |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20303    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.87e-06 |\n",
      "|    n_updates        | 5050     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.11     |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 728      |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20311    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.25e-06 |\n",
      "|    n_updates        | 5052     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 5.13     |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 732      |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20320    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.76e-05 |\n",
      "|    n_updates        | 5054     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.91     |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 736      |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20328    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.28e-05 |\n",
      "|    n_updates        | 5056     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.86     |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 740      |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20336    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000292 |\n",
      "|    n_updates        | 5058     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.82     |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 744      |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20344    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.2e-06  |\n",
      "|    n_updates        | 5060     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.77     |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 748      |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20352    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.87e-07 |\n",
      "|    n_updates        | 5062     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.73     |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 752      |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20361    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0046   |\n",
      "|    n_updates        | 5065     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.69     |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 756      |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20369    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.83e-07 |\n",
      "|    n_updates        | 5067     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.65     |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 760      |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20377    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.14e-05 |\n",
      "|    n_updates        | 5069     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.56     |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 764      |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20385    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.33e-05 |\n",
      "|    n_updates        | 5071     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.52     |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 768      |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20393    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.8e-05  |\n",
      "|    n_updates        | 5073     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.46     |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 772      |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20401    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.58e-05 |\n",
      "|    n_updates        | 5075     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.38     |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 776      |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20409    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.37e-06 |\n",
      "|    n_updates        | 5077     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.38     |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 780      |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20417    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.63e-05 |\n",
      "|    n_updates        | 5079     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.26     |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 784      |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20425    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00414  |\n",
      "|    n_updates        | 5081     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.25     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 788      |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20436    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00432  |\n",
      "|    n_updates        | 5083     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.25     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 792      |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20444    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.41e-05 |\n",
      "|    n_updates        | 5085     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.22     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 796      |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20452    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.58e-05 |\n",
      "|    n_updates        | 5087     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20460    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.28e-06 |\n",
      "|    n_updates        | 5089     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 804      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20468    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.89e-06 |\n",
      "|    n_updates        | 5091     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 808      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20477    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.35e-07 |\n",
      "|    n_updates        | 5094     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 812      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20485    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.04e-05 |\n",
      "|    n_updates        | 5096     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 816      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20493    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.28e-05 |\n",
      "|    n_updates        | 5098     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 820      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20501    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.59e-07 |\n",
      "|    n_updates        | 5100     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 824      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20510    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.35e-06 |\n",
      "|    n_updates        | 5102     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 828      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20518    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00485  |\n",
      "|    n_updates        | 5104     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 832      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20526    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000161 |\n",
      "|    n_updates        | 5106     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 836      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20536    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.8e-05  |\n",
      "|    n_updates        | 5108     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 840      |\n",
      "|    fps              | 954      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20544    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.87e-06 |\n",
      "|    n_updates        | 5110     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 844      |\n",
      "|    fps              | 954      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20552    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.98e-05 |\n",
      "|    n_updates        | 5112     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 848      |\n",
      "|    fps              | 954      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20560    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000111 |\n",
      "|    n_updates        | 5114     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 852      |\n",
      "|    fps              | 954      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20568    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00312  |\n",
      "|    n_updates        | 5116     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.07     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 856      |\n",
      "|    fps              | 954      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20576    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.64e-06 |\n",
      "|    n_updates        | 5118     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.48     |\n",
      "|    ep_rew_mean      | 0.01     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 860      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20625    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.73e-05 |\n",
      "|    n_updates        | 5131     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.63     |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 864      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20648    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.98e-05 |\n",
      "|    n_updates        | 5136     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.67     |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 868      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20660    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.14e-05 |\n",
      "|    n_updates        | 5139     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.67     |\n",
      "|    ep_rew_mean      | 0.05     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 872      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20668    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00252  |\n",
      "|    n_updates        | 5141     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.71     |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 876      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20680    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.53e-06 |\n",
      "|    n_updates        | 5144     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.71     |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 880      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20688    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.68e-06 |\n",
      "|    n_updates        | 5146     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.71     |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 884      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20696    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.02e-06 |\n",
      "|    n_updates        | 5148     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.68     |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 888      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20704    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.12e-05 |\n",
      "|    n_updates        | 5150     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.68     |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 892      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20712    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.26e-05 |\n",
      "|    n_updates        | 5152     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.68     |\n",
      "|    ep_rew_mean      | 0.06     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 896      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20720    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0075   |\n",
      "|    n_updates        | 5154     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.77     |\n",
      "|    ep_rew_mean      | 0.08     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 900      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20737    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.12e-05 |\n",
      "|    n_updates        | 5159     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.93     |\n",
      "|    ep_rew_mean      | 0.12     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 904      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20761    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.05e-05 |\n",
      "|    n_updates        | 5165     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.08     |\n",
      "|    ep_rew_mean      | 0.16     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 908      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20785    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.8e-05  |\n",
      "|    n_updates        | 5171     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.24     |\n",
      "|    ep_rew_mean      | 0.2      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 912      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20809    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.98e-05 |\n",
      "|    n_updates        | 5177     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.4      |\n",
      "|    ep_rew_mean      | 0.24     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 916      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20833    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.37e-05 |\n",
      "|    n_updates        | 5183     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.6      |\n",
      "|    ep_rew_mean      | 0.28     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 920      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20861    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00165  |\n",
      "|    n_updates        | 5190     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.68     |\n",
      "|    ep_rew_mean      | 0.3      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 924      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 20978    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.83e-05 |\n",
      "|    n_updates        | 5219     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 5.11     |\n",
      "|    ep_rew_mean      | 0.34     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 928      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 21029    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.19e-05 |\n",
      "|    n_updates        | 5232     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6.37     |\n",
      "|    ep_rew_mean      | 0.37     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 932      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 21163    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00561  |\n",
      "|    n_updates        | 5265     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6.47     |\n",
      "|    ep_rew_mean      | 0.39     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 936      |\n",
      "|    fps              | 954      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 21183    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000147 |\n",
      "|    n_updates        | 5270     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6.63     |\n",
      "|    ep_rew_mean      | 0.43     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 940      |\n",
      "|    fps              | 954      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 21207    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.79e-05 |\n",
      "|    n_updates        | 5276     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6.78     |\n",
      "|    ep_rew_mean      | 0.46     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 944      |\n",
      "|    fps              | 954      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 21230    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000423 |\n",
      "|    n_updates        | 5282     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6.94     |\n",
      "|    ep_rew_mean      | 0.5      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 948      |\n",
      "|    fps              | 954      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 21254    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000386 |\n",
      "|    n_updates        | 5288     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.12     |\n",
      "|    ep_rew_mean      | 0.54     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 952      |\n",
      "|    fps              | 954      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 21280    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.79e-05 |\n",
      "|    n_updates        | 5294     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.28     |\n",
      "|    ep_rew_mean      | 0.58     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 956      |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 21304    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000331 |\n",
      "|    n_updates        | 5300     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.03     |\n",
      "|    ep_rew_mean      | 0.61     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 960      |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 21328    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.3e-06  |\n",
      "|    n_updates        | 5306     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.08     |\n",
      "|    ep_rew_mean      | 0.61     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 964      |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 21356    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.78e-05 |\n",
      "|    n_updates        | 5313     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.53     |\n",
      "|    ep_rew_mean      | 0.62     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 968      |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 21413    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.07e-05 |\n",
      "|    n_updates        | 5328     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.63     |\n",
      "|    ep_rew_mean      | 0.64     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 972      |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 21431    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.16e-06 |\n",
      "|    n_updates        | 5332     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.91     |\n",
      "|    ep_rew_mean      | 0.67     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 976      |\n",
      "|    fps              | 952      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 21471    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.87e-05 |\n",
      "|    n_updates        | 5342     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.07     |\n",
      "|    ep_rew_mean      | 0.71     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 980      |\n",
      "|    fps              | 952      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 21495    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.56e-05 |\n",
      "|    n_updates        | 5348     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.29     |\n",
      "|    ep_rew_mean      | 0.75     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 984      |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 21525    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.66e-06 |\n",
      "|    n_updates        | 5356     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.61     |\n",
      "|    ep_rew_mean      | 0.78     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 988      |\n",
      "|    fps              | 952      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 21565    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000167 |\n",
      "|    n_updates        | 5366     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.6      |\n",
      "|    ep_rew_mean      | 0.81     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 992      |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 21672    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.62e-06 |\n",
      "|    n_updates        | 5392     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.3     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 996      |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 21746    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.98e-05 |\n",
      "|    n_updates        | 5411     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.4     |\n",
      "|    ep_rew_mean      | 0.86     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1000     |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 21773    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.92e-06 |\n",
      "|    n_updates        | 5418     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.3     |\n",
      "|    ep_rew_mean      | 0.85     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1004     |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 21795    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.32e-06 |\n",
      "|    n_updates        | 5423     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.3     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1008     |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 21815    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.24e-06 |\n",
      "|    n_updates        | 5428     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.3     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1012     |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 21839    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.85e-06 |\n",
      "|    n_updates        | 5434     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.8     |\n",
      "|    ep_rew_mean      | 0.83     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1016     |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 21918    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.32e-06 |\n",
      "|    n_updates        | 5454     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.9     |\n",
      "|    ep_rew_mean      | 0.79     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1020     |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 22051    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.36e-06 |\n",
      "|    n_updates        | 5487     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 0.78     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1024     |\n",
      "|    fps              | 952      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 22296    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.86e-05 |\n",
      "|    n_updates        | 5548     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 0.77     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1028     |\n",
      "|    fps              | 952      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 22359    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.28e-05 |\n",
      "|    n_updates        | 5564     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 0.75     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1032     |\n",
      "|    fps              | 952      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 22499    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.47e-06 |\n",
      "|    n_updates        | 5599     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14       |\n",
      "|    ep_rew_mean      | 0.73     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1036     |\n",
      "|    fps              | 952      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 22579    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.81e-06 |\n",
      "|    n_updates        | 5619     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.4     |\n",
      "|    ep_rew_mean      | 0.73     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1040     |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 22650    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.03e-07 |\n",
      "|    n_updates        | 5637     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.5     |\n",
      "|    ep_rew_mean      | 0.74     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1044     |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 22676    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.84e-07 |\n",
      "|    n_updates        | 5643     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.7     |\n",
      "|    ep_rew_mean      | 0.73     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1048     |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 22721    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.62e-07 |\n",
      "|    n_updates        | 5655     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.5     |\n",
      "|    ep_rew_mean      | 0.7      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1052     |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 22831    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.51e-06 |\n",
      "|    n_updates        | 5682     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.6     |\n",
      "|    ep_rew_mean      | 0.67     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1056     |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 22961    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.27e-07 |\n",
      "|    n_updates        | 5715     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | 0.63     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1060     |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 23185    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.54e-06 |\n",
      "|    n_updates        | 5771     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | 0.61     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1064     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 23365    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.76e-06 |\n",
      "|    n_updates        | 5816     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.8     |\n",
      "|    ep_rew_mean      | 0.63     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1068     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 23389    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.72e-06 |\n",
      "|    n_updates        | 5822     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 0.63     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1072     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 23591    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.88e-07 |\n",
      "|    n_updates        | 5872     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23       |\n",
      "|    ep_rew_mean      | 0.62     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1076     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 23771    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00168  |\n",
      "|    n_updates        | 5917     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 0.62     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1080     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 23839    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.12e-07 |\n",
      "|    n_updates        | 5934     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.5     |\n",
      "|    ep_rew_mean      | 0.61     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1084     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 23979    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.06e-07 |\n",
      "|    n_updates        | 5969     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.8     |\n",
      "|    ep_rew_mean      | 0.6      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1088     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 24147    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000645 |\n",
      "|    n_updates        | 6011     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25       |\n",
      "|    ep_rew_mean      | 0.6      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1092     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 24176    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000877 |\n",
      "|    n_updates        | 6018     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.6     |\n",
      "|    ep_rew_mean      | 0.61     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1096     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 24205    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.17e-06 |\n",
      "|    n_updates        | 6026     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.5     |\n",
      "|    ep_rew_mean      | 0.6      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1100     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 24323    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.46e-06 |\n",
      "|    n_updates        | 6055     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 26.5     |\n",
      "|    ep_rew_mean      | 0.58     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1104     |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 24443    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.39e-06 |\n",
      "|    n_updates        | 6085     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 26.9     |\n",
      "|    ep_rew_mean      | 0.57     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1108     |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 24510    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.4e-06  |\n",
      "|    n_updates        | 6102     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 29.2     |\n",
      "|    ep_rew_mean      | 0.53     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1112     |\n",
      "|    fps              | 952      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 24760    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.97e-07 |\n",
      "|    n_updates        | 6164     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 29.6     |\n",
      "|    ep_rew_mean      | 0.51     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1116     |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 24882    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.46e-05 |\n",
      "|    n_updates        | 6195     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 29.8     |\n",
      "|    ep_rew_mean      | 0.54     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1120     |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 25032    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.27e-08 |\n",
      "|    n_updates        | 6232     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 28.9     |\n",
      "|    ep_rew_mean      | 0.54     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1124     |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 25182    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.96e-07 |\n",
      "|    n_updates        | 6270     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30.5     |\n",
      "|    ep_rew_mean      | 0.51     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1128     |\n",
      "|    fps              | 954      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 25407    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.12e-07 |\n",
      "|    n_updates        | 6326     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 29.9     |\n",
      "|    ep_rew_mean      | 0.5      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1132     |\n",
      "|    fps              | 954      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 25484    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.37e-06 |\n",
      "|    n_updates        | 6345     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30.6     |\n",
      "|    ep_rew_mean      | 0.52     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1136     |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 25638    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.81e-07 |\n",
      "|    n_updates        | 6384     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30.2     |\n",
      "|    ep_rew_mean      | 0.51     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1140     |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 25672    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.13e-07 |\n",
      "|    n_updates        | 6392     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 31.5     |\n",
      "|    ep_rew_mean      | 0.49     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1144     |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 25829    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.99e-05 |\n",
      "|    n_updates        | 6432     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 31.8     |\n",
      "|    ep_rew_mean      | 0.48     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1148     |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 25901    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.86e-08 |\n",
      "|    n_updates        | 6450     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 31.1     |\n",
      "|    ep_rew_mean      | 0.5      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1152     |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 25941    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.94e-06 |\n",
      "|    n_updates        | 6460     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30.8     |\n",
      "|    ep_rew_mean      | 0.53     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1156     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 26039    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000433 |\n",
      "|    n_updates        | 6484     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 29.7     |\n",
      "|    ep_rew_mean      | 0.57     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1160     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 26158    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.68e-06 |\n",
      "|    n_updates        | 6514     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 28.3     |\n",
      "|    ep_rew_mean      | 0.6      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1164     |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 26196    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.18e-06 |\n",
      "|    n_updates        | 6523     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 28.3     |\n",
      "|    ep_rew_mean      | 0.6      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1168     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 26220    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.03e-06 |\n",
      "|    n_updates        | 6529     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 26.8     |\n",
      "|    ep_rew_mean      | 0.6      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1172     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 26272    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.87e-07 |\n",
      "|    n_updates        | 6542     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.5     |\n",
      "|    ep_rew_mean      | 0.61     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1176     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 26323    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.17e-08 |\n",
      "|    n_updates        | 6555     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 26.1     |\n",
      "|    ep_rew_mean      | 0.59     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1180     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 26453    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.2e-07  |\n",
      "|    n_updates        | 6588     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.1     |\n",
      "|    ep_rew_mean      | 0.59     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1184     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 26489    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.27e-07 |\n",
      "|    n_updates        | 6597     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.1     |\n",
      "|    ep_rew_mean      | 0.61     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1188     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 26561    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.13e-07 |\n",
      "|    n_updates        | 6615     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.7     |\n",
      "|    ep_rew_mean      | 0.59     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1192     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 26744    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.55e-07 |\n",
      "|    n_updates        | 6660     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 26.7     |\n",
      "|    ep_rew_mean      | 0.58     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1196     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 26877    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.87e-06 |\n",
      "|    n_updates        | 6694     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.8     |\n",
      "|    ep_rew_mean      | 0.59     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1200     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 26902    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.17e-06 |\n",
      "|    n_updates        | 6700     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.1     |\n",
      "|    ep_rew_mean      | 0.61     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1204     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 26953    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.24e-08 |\n",
      "|    n_updates        | 6713     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 26       |\n",
      "|    ep_rew_mean      | 0.62     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1208     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 27110    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.83e-07 |\n",
      "|    n_updates        | 6752     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 0.66     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1212     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 27135    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.64e-07 |\n",
      "|    n_updates        | 6758     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.2     |\n",
      "|    ep_rew_mean      | 0.67     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1216     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 27207    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.23e-06 |\n",
      "|    n_updates        | 6776     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 0.68     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1220     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 27231    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.41e-07 |\n",
      "|    n_updates        | 6782     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 0.7      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1224     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 27265    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.52e-05 |\n",
      "|    n_updates        | 6791     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | 0.73     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1228     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 27413    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.59e-06 |\n",
      "|    n_updates        | 6828     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | 0.75     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1232     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 27553    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.81e-06 |\n",
      "|    n_updates        | 6863     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | 0.76     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1236     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 27651    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.68e-07 |\n",
      "|    n_updates        | 6887     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.2     |\n",
      "|    ep_rew_mean      | 0.76     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1240     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 27693    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.59e-06 |\n",
      "|    n_updates        | 6898     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 0.76     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1244     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 27948    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.9e-05  |\n",
      "|    n_updates        | 6961     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | 0.77     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1248     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 27970    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.23e-07 |\n",
      "|    n_updates        | 6967     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.3     |\n",
      "|    ep_rew_mean      | 0.77     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1252     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 28074    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.93e-07 |\n",
      "|    n_updates        | 6993     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 0.76     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1256     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 28199    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.01e-07 |\n",
      "|    n_updates        | 7024     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 0.76     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1260     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 28234    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.41e-08 |\n",
      "|    n_updates        | 7033     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | 0.75     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1264     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 28290    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.54e-08 |\n",
      "|    n_updates        | 7047     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 0.72     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1268     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 28334    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.29e-07 |\n",
      "|    n_updates        | 7058     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 0.72     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1272     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 28495    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.23e-06 |\n",
      "|    n_updates        | 7098     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 0.72     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1276     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 28538    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.09e-07 |\n",
      "|    n_updates        | 7109     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 0.74     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1280     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 28591    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.97e-07 |\n",
      "|    n_updates        | 7122     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 0.74     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1284     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 28711    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.63e-07 |\n",
      "|    n_updates        | 7152     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 0.73     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1288     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 28747    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.01e-07 |\n",
      "|    n_updates        | 7161     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.6     |\n",
      "|    ep_rew_mean      | 0.75     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1292     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 28803    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.16e-08 |\n",
      "|    n_updates        | 7175     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.5     |\n",
      "|    ep_rew_mean      | 0.75     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1296     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 28925    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000174 |\n",
      "|    n_updates        | 7206     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | 0.75     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1300     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 28973    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.89e-08 |\n",
      "|    n_updates        | 7218     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 0.75     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1304     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 29159    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.66e-07 |\n",
      "|    n_updates        | 7264     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 0.75     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1308     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 29265    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.46e-07 |\n",
      "|    n_updates        | 7291     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 0.75     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1312     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 29290    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.42e-07 |\n",
      "|    n_updates        | 7297     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 0.75     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1316     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 29389    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.53e-08 |\n",
      "|    n_updates        | 7322     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 0.75     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1320     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 29418    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.94e-07 |\n",
      "|    n_updates        | 7329     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.1     |\n",
      "|    ep_rew_mean      | 0.74     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1324     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 29574    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.26e-07 |\n",
      "|    n_updates        | 7368     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 0.73     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1328     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 29756    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.79e-07 |\n",
      "|    n_updates        | 7413     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.6     |\n",
      "|    ep_rew_mean      | 0.75     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1332     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 29813    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.26e-06 |\n",
      "|    n_updates        | 7428     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.7     |\n",
      "|    ep_rew_mean      | 0.73     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1336     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30017    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.75e-05 |\n",
      "|    n_updates        | 7479     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 0.7      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1340     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30034    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00771  |\n",
      "|    n_updates        | 7483     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21       |\n",
      "|    ep_rew_mean      | 0.68     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1344     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30046    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000105 |\n",
      "|    n_updates        | 7486     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | 0.65     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1348     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30060    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000477 |\n",
      "|    n_updates        | 7489     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20       |\n",
      "|    ep_rew_mean      | 0.62     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1352     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30072    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000732 |\n",
      "|    n_updates        | 7492     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.9     |\n",
      "|    ep_rew_mean      | 0.59     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1356     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30084    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00499  |\n",
      "|    n_updates        | 7495     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | 0.55     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1360     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30096    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00123  |\n",
      "|    n_updates        | 7498     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.2     |\n",
      "|    ep_rew_mean      | 0.52     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1364     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30108    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00164  |\n",
      "|    n_updates        | 7501     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.9     |\n",
      "|    ep_rew_mean      | 0.51     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1368     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30124    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000393 |\n",
      "|    n_updates        | 7505     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.4     |\n",
      "|    ep_rew_mean      | 0.49     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1372     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30136    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.29e-05 |\n",
      "|    n_updates        | 7508     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.2     |\n",
      "|    ep_rew_mean      | 0.48     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1376     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30157    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000329 |\n",
      "|    n_updates        | 7514     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.9     |\n",
      "|    ep_rew_mean      | 0.48     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1380     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30181    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000147 |\n",
      "|    n_updates        | 7520     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15       |\n",
      "|    ep_rew_mean      | 0.49     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1384     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30207    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00613  |\n",
      "|    n_updates        | 7526     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.8     |\n",
      "|    ep_rew_mean      | 0.5      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1388     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30231    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00487  |\n",
      "|    n_updates        | 7532     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.5     |\n",
      "|    ep_rew_mean      | 0.51     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1392     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30257    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000154 |\n",
      "|    n_updates        | 7539     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 0.51     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1396     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30282    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0019   |\n",
      "|    n_updates        | 7545     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 0.51     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1400     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30309    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0016   |\n",
      "|    n_updates        | 7552     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.8     |\n",
      "|    ep_rew_mean      | 0.52     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1404     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30334    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00151  |\n",
      "|    n_updates        | 7558     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.9     |\n",
      "|    ep_rew_mean      | 0.51     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1408     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30353    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000251 |\n",
      "|    n_updates        | 7563     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.9     |\n",
      "|    ep_rew_mean      | 0.51     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1412     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30379    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000128 |\n",
      "|    n_updates        | 7569     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 0.53     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1416     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30403    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00541  |\n",
      "|    n_updates        | 7575     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 0.53     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1420     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30427    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000349 |\n",
      "|    n_updates        | 7581     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.78     |\n",
      "|    ep_rew_mean      | 0.55     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1424     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30452    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00011  |\n",
      "|    n_updates        | 7587     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.78     |\n",
      "|    ep_rew_mean      | 0.57     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1428     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30534    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000301 |\n",
      "|    n_updates        | 7608     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.45     |\n",
      "|    ep_rew_mean      | 0.57     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1432     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30558    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.66e-05 |\n",
      "|    n_updates        | 7614     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 5.62     |\n",
      "|    ep_rew_mean      | 0.59     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1436     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 30579    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00066  |\n",
      "|    n_updates        | 7619     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.62     |\n",
      "|    ep_rew_mean      | 0.61     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1440     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 30896    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.39e-05 |\n",
      "|    n_updates        | 7698     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.6     |\n",
      "|    ep_rew_mean      | 0.63     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1444     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 31104    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.3e-05  |\n",
      "|    n_updates        | 7750     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 0.63     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1448     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 31336    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.71e-05 |\n",
      "|    n_updates        | 7808     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 0.67     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1452     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 31405    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.81e-05 |\n",
      "|    n_updates        | 7826     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 0.71     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1456     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 31447    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000401 |\n",
      "|    n_updates        | 7836     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.8     |\n",
      "|    ep_rew_mean      | 0.73     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1460     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 31575    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.03e-05 |\n",
      "|    n_updates        | 7868     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.8     |\n",
      "|    ep_rew_mean      | 0.77     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1464     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 31683    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.27e-06 |\n",
      "|    n_updates        | 7895     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.8     |\n",
      "|    ep_rew_mean      | 0.81     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1468     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 31709    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00551  |\n",
      "|    n_updates        | 7902     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.9     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1472     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 31731    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.47e-06 |\n",
      "|    n_updates        | 7907     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.7     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1476     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 31830    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.69e-06 |\n",
      "|    n_updates        | 7932     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.4     |\n",
      "|    ep_rew_mean      | 0.83     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1480     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 31918    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.73e-06 |\n",
      "|    n_updates        | 7954     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | 0.82     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1484     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 31969    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.57e-06 |\n",
      "|    n_updates        | 7967     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | 0.81     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1488     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 31996    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000314 |\n",
      "|    n_updates        | 7973     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | 0.8      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1492     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 32020    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.58e-06 |\n",
      "|    n_updates        | 7979     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.7     |\n",
      "|    ep_rew_mean      | 0.8      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1496     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 32049    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.76e-06 |\n",
      "|    n_updates        | 7987     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | 0.76     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1500     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 32165    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000273 |\n",
      "|    n_updates        | 8016     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | 0.76     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1504     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 32197    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.63e-06 |\n",
      "|    n_updates        | 8024     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.7     |\n",
      "|    ep_rew_mean      | 0.78     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1508     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 32221    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.14e-06 |\n",
      "|    n_updates        | 8030     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | 0.77     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1512     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 32449    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000343 |\n",
      "|    n_updates        | 8087     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | 0.77     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1516     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 32475    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.34e-06 |\n",
      "|    n_updates        | 8093     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 0.77     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1520     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 32567    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.9e-06  |\n",
      "|    n_updates        | 8116     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 0.75     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1524     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 32670    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.45e-06 |\n",
      "|    n_updates        | 8142     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 0.75     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1528     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 32750    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00194  |\n",
      "|    n_updates        | 8162     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 0.75     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1532     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 32774    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.7e-06  |\n",
      "|    n_updates        | 8168     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 0.76     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1536     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 32814    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.48e-06 |\n",
      "|    n_updates        | 8178     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.8     |\n",
      "|    ep_rew_mean      | 0.78     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1540     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 32877    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.45e-07 |\n",
      "|    n_updates        | 8194     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18       |\n",
      "|    ep_rew_mean      | 0.8      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1544     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 32901    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.16e-06 |\n",
      "|    n_updates        | 8200     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.4     |\n",
      "|    ep_rew_mean      | 0.83     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1548     |\n",
      "|    fps              | 961      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 32976    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000121 |\n",
      "|    n_updates        | 8218     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.4     |\n",
      "|    ep_rew_mean      | 0.82     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1552     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 33143    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00334  |\n",
      "|    n_updates        | 8260     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.4     |\n",
      "|    ep_rew_mean      | 0.8      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1556     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 33485    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.27e-06 |\n",
      "|    n_updates        | 8346     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.2     |\n",
      "|    ep_rew_mean      | 0.81     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1560     |\n",
      "|    fps              | 961      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 33591    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.44e-06 |\n",
      "|    n_updates        | 8372     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.9     |\n",
      "|    ep_rew_mean      | 0.8      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1564     |\n",
      "|    fps              | 961      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 33672    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.67e-06 |\n",
      "|    n_updates        | 8392     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.4     |\n",
      "|    ep_rew_mean      | 0.79     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1568     |\n",
      "|    fps              | 961      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 33746    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.12e-05 |\n",
      "|    n_updates        | 8411     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 0.79     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1572     |\n",
      "|    fps              | 961      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 33839    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00111  |\n",
      "|    n_updates        | 8434     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.5     |\n",
      "|    ep_rew_mean      | 0.8      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1576     |\n",
      "|    fps              | 961      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 33881    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.43e-05 |\n",
      "|    n_updates        | 8445     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.9     |\n",
      "|    ep_rew_mean      | 0.8      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1580     |\n",
      "|    fps              | 961      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 33905    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.5e-05  |\n",
      "|    n_updates        | 8451     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.6     |\n",
      "|    ep_rew_mean      | 0.81     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1584     |\n",
      "|    fps              | 962      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 33931    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.28e-06 |\n",
      "|    n_updates        | 8457     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | 0.82     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1588     |\n",
      "|    fps              | 962      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 34029    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0001   |\n",
      "|    n_updates        | 8482     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | 0.82     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1592     |\n",
      "|    fps              | 962      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 34049    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.03e-06 |\n",
      "|    n_updates        | 8487     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | 0.82     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1596     |\n",
      "|    fps              | 962      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 34121    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00233  |\n",
      "|    n_updates        | 8505     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 0.85     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1600     |\n",
      "|    fps              | 962      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 34249    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00118  |\n",
      "|    n_updates        | 8537     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1604     |\n",
      "|    fps              | 962      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 34269    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00069  |\n",
      "|    n_updates        | 8542     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1608     |\n",
      "|    fps              | 962      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 34309    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.16e-05 |\n",
      "|    n_updates        | 8552     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.3     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1612     |\n",
      "|    fps              | 962      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 34380    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.75e-07 |\n",
      "|    n_updates        | 8569     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.7     |\n",
      "|    ep_rew_mean      | 0.83     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1616     |\n",
      "|    fps              | 962      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 34449    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.12e-06 |\n",
      "|    n_updates        | 8587     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.2     |\n",
      "|    ep_rew_mean      | 0.83     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1620     |\n",
      "|    fps              | 962      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 34491    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.75e-05 |\n",
      "|    n_updates        | 8597     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.7     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1624     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 34537    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.83e-06 |\n",
      "|    n_updates        | 8609     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20       |\n",
      "|    ep_rew_mean      | 0.83     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1628     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 34752    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.63e-05 |\n",
      "|    n_updates        | 8662     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 0.81     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1632     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 34933    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000948 |\n",
      "|    n_updates        | 8708     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 0.79     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1636     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 34967    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.1e-06  |\n",
      "|    n_updates        | 8716     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 0.79     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1640     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 34994    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000646 |\n",
      "|    n_updates        | 8723     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 0.78     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1644     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 35134    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.62e-06 |\n",
      "|    n_updates        | 8758     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 0.79     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1648     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 35158    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.12e-07 |\n",
      "|    n_updates        | 8764     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.4     |\n",
      "|    ep_rew_mean      | 0.8      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1652     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 35182    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.35e-05 |\n",
      "|    n_updates        | 8770     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18       |\n",
      "|    ep_rew_mean      | 0.81     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1656     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 35285    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.12e-05 |\n",
      "|    n_updates        | 8796     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | 0.81     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1660     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 35347    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000114 |\n",
      "|    n_updates        | 8811     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17       |\n",
      "|    ep_rew_mean      | 0.81     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1664     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 35371    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00321  |\n",
      "|    n_updates        | 8817     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17       |\n",
      "|    ep_rew_mean      | 0.79     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1668     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 35449    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.57e-06 |\n",
      "|    n_updates        | 8837     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.4     |\n",
      "|    ep_rew_mean      | 0.8      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1672     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 35475    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.54e-06 |\n",
      "|    n_updates        | 8843     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.4     |\n",
      "|    ep_rew_mean      | 0.79     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1676     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 35521    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.64e-05 |\n",
      "|    n_updates        | 8855     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.7     |\n",
      "|    ep_rew_mean      | 0.8      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1680     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 35575    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.38e-07 |\n",
      "|    n_updates        | 8868     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.7     |\n",
      "|    ep_rew_mean      | 0.8      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1684     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 35600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.92e-07 |\n",
      "|    n_updates        | 8874     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.1     |\n",
      "|    ep_rew_mean      | 0.78     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1688     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 35642    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.94e-06 |\n",
      "|    n_updates        | 8885     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.1     |\n",
      "|    ep_rew_mean      | 0.79     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1692     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 35857    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.27e-06 |\n",
      "|    n_updates        | 8939     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | 0.8      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1696     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 35883    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.33e-06 |\n",
      "|    n_updates        | 8945     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.6     |\n",
      "|    ep_rew_mean      | 0.8      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1700     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 35912    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00263  |\n",
      "|    n_updates        | 8952     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.2     |\n",
      "|    ep_rew_mean      | 0.81     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1704     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 35985    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.56e-07 |\n",
      "|    n_updates        | 8971     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17       |\n",
      "|    ep_rew_mean      | 0.8      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1708     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 36007    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.21e-07 |\n",
      "|    n_updates        | 8976     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.9     |\n",
      "|    ep_rew_mean      | 0.81     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1712     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 36069    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.7e-07  |\n",
      "|    n_updates        | 8992     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.5     |\n",
      "|    ep_rew_mean      | 0.82     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1716     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 36097    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.23e-05 |\n",
      "|    n_updates        | 8999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.4     |\n",
      "|    ep_rew_mean      | 0.81     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1720     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 36136    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.52e-05 |\n",
      "|    n_updates        | 9008     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.6     |\n",
      "|    ep_rew_mean      | 0.82     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1724     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 36192    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.46e-06 |\n",
      "|    n_updates        | 9022     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.6     |\n",
      "|    ep_rew_mean      | 0.81     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1728     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 36314    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.71e-06 |\n",
      "|    n_updates        | 9053     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.4     |\n",
      "|    ep_rew_mean      | 0.82     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1732     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 36377    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.38e-06 |\n",
      "|    n_updates        | 9069     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.4     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1736     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 36403    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2e-06    |\n",
      "|    n_updates        | 9075     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.6     |\n",
      "|    ep_rew_mean      | 0.83     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1740     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 36451    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.97e-07 |\n",
      "|    n_updates        | 9087     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14       |\n",
      "|    ep_rew_mean      | 0.83     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1744     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 36537    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.52e-07 |\n",
      "|    n_updates        | 9109     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14       |\n",
      "|    ep_rew_mean      | 0.82     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1748     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 36557    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 9114     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14       |\n",
      "|    ep_rew_mean      | 0.82     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1752     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 36584    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0001   |\n",
      "|    n_updates        | 9120     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 0.83     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1756     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 36608    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.32e-07 |\n",
      "|    n_updates        | 9126     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.3     |\n",
      "|    ep_rew_mean      | 0.81     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1760     |\n",
      "|    fps              | 966      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 36781    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.03e-07 |\n",
      "|    n_updates        | 9170     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.4     |\n",
      "|    ep_rew_mean      | 0.82     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1764     |\n",
      "|    fps              | 966      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 36807    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.43e-06 |\n",
      "|    n_updates        | 9176     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1768     |\n",
      "|    fps              | 966      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 36833    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.08e-06 |\n",
      "|    n_updates        | 9183     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 0.83     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1772     |\n",
      "|    fps              | 966      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 36855    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.69e-06 |\n",
      "|    n_updates        | 9188     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.1     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1776     |\n",
      "|    fps              | 966      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 36933    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.38e-07 |\n",
      "|    n_updates        | 9208     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1780     |\n",
      "|    fps              | 966      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 36959    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.64e-07 |\n",
      "|    n_updates        | 9214     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1784     |\n",
      "|    fps              | 966      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 36985    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.83e-07 |\n",
      "|    n_updates        | 9221     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 0.86     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1788     |\n",
      "|    fps              | 966      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 37011    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.42e-07 |\n",
      "|    n_updates        | 9227     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.3     |\n",
      "|    ep_rew_mean      | 0.86     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1792     |\n",
      "|    fps              | 966      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 37087    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000941 |\n",
      "|    n_updates        | 9246     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 0.86     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1796     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 37241    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3e-06    |\n",
      "|    n_updates        | 9285     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.4     |\n",
      "|    ep_rew_mean      | 0.87     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1800     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 37357    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.81e-06 |\n",
      "|    n_updates        | 9314     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14       |\n",
      "|    ep_rew_mean      | 0.87     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1804     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 37383    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.47e-06 |\n",
      "|    n_updates        | 9320     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.1     |\n",
      "|    ep_rew_mean      | 0.86     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1808     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 37416    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.44e-06 |\n",
      "|    n_updates        | 9328     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 0.86     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1812     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 37445    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.41e-07 |\n",
      "|    n_updates        | 9336     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14       |\n",
      "|    ep_rew_mean      | 0.86     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1816     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 37501    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.71e-07 |\n",
      "|    n_updates        | 9350     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.9     |\n",
      "|    ep_rew_mean      | 0.86     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1820     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 37523    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.16e-07 |\n",
      "|    n_updates        | 9355     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.2     |\n",
      "|    ep_rew_mean      | 0.85     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1824     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 37614    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.89e-07 |\n",
      "|    n_updates        | 9378     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 0.86     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1828     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 37638    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.53e-06 |\n",
      "|    n_updates        | 9384     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 0.85     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1832     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 37740    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.09e-07 |\n",
      "|    n_updates        | 9409     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1836     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 37773    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.2e-05  |\n",
      "|    n_updates        | 9418     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14       |\n",
      "|    ep_rew_mean      | 0.83     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1840     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 37855    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.75e-07 |\n",
      "|    n_updates        | 9438     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1844     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 37879    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000352 |\n",
      "|    n_updates        | 9444     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.2     |\n",
      "|    ep_rew_mean      | 0.83     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1848     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 37973    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.07e-07 |\n",
      "|    n_updates        | 9468     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.9     |\n",
      "|    ep_rew_mean      | 0.83     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1852     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 38070    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.11e-07 |\n",
      "|    n_updates        | 9492     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.9     |\n",
      "|    ep_rew_mean      | 0.83     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1856     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 38094    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0003   |\n",
      "|    n_updates        | 9498     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14       |\n",
      "|    ep_rew_mean      | 0.86     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1860     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 38177    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.55e-08 |\n",
      "|    n_updates        | 9519     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14       |\n",
      "|    ep_rew_mean      | 0.86     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1864     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 38205    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00311  |\n",
      "|    n_updates        | 9526     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.3     |\n",
      "|    ep_rew_mean      | 0.87     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1868     |\n",
      "|    fps              | 966      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 38267    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 9541     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.9     |\n",
      "|    ep_rew_mean      | 0.88     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1872     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 38345    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.8e-07  |\n",
      "|    n_updates        | 9561     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.9     |\n",
      "|    ep_rew_mean      | 0.88     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1876     |\n",
      "|    fps              | 966      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 38524    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 9605     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.9     |\n",
      "|    ep_rew_mean      | 0.88     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1880     |\n",
      "|    fps              | 966      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 38548    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.4e-05  |\n",
      "|    n_updates        | 9611     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.3     |\n",
      "|    ep_rew_mean      | 0.87     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1884     |\n",
      "|    fps              | 966      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 38616    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.11e-06 |\n",
      "|    n_updates        | 9628     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.5     |\n",
      "|    ep_rew_mean      | 0.87     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1888     |\n",
      "|    fps              | 966      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 38661    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.11e-06 |\n",
      "|    n_updates        | 9640     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16       |\n",
      "|    ep_rew_mean      | 0.86     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1892     |\n",
      "|    fps              | 966      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 38686    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.24e-07 |\n",
      "|    n_updates        | 9646     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.2     |\n",
      "|    ep_rew_mean      | 0.85     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1896     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 38757    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.4e-06  |\n",
      "|    n_updates        | 9664     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.3     |\n",
      "|    ep_rew_mean      | 0.85     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1900     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 38784    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.35e-06 |\n",
      "|    n_updates        | 9670     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.9     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1904     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 38877    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.18e-06 |\n",
      "|    n_updates        | 9694     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15       |\n",
      "|    ep_rew_mean      | 0.85     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1908     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 38915    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.1e-07  |\n",
      "|    n_updates        | 9703     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.8     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1912     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 39025    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.59e-06 |\n",
      "|    n_updates        | 9731     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.5     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1916     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 39049    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.81e-07 |\n",
      "|    n_updates        | 9737     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.7     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1920     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 39095    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6e-07    |\n",
      "|    n_updates        | 9748     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.6     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1924     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 39170    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.52e-07 |\n",
      "|    n_updates        | 9767     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.9     |\n",
      "|    ep_rew_mean      | 0.85     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1928     |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 39233    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.11e-06 |\n",
      "|    n_updates        | 9783     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.2     |\n",
      "|    ep_rew_mean      | 0.87     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1932     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 39262    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.96e-06 |\n",
      "|    n_updates        | 9790     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.8     |\n",
      "|    ep_rew_mean      | 0.87     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1936     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 39356    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.68e-07 |\n",
      "|    n_updates        | 9813     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.2     |\n",
      "|    ep_rew_mean      | 0.88     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1940     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 39380    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 9819     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.6     |\n",
      "|    ep_rew_mean      | 0.88     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1944     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 39435    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.9e-07  |\n",
      "|    n_updates        | 9833     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.9     |\n",
      "|    ep_rew_mean      | 0.9      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1948     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 39459    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.51e-07 |\n",
      "|    n_updates        | 9839     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.5     |\n",
      "|    ep_rew_mean      | 0.89     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1952     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 39520    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.1e-07  |\n",
      "|    n_updates        | 9854     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.9     |\n",
      "|    ep_rew_mean      | 0.89     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1956     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 39585    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.84e-07 |\n",
      "|    n_updates        | 9871     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.3     |\n",
      "|    ep_rew_mean      | 0.89     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1960     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 39609    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.11e-07 |\n",
      "|    n_updates        | 9877     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.5     |\n",
      "|    ep_rew_mean      | 0.89     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1964     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 39659    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.02e-07 |\n",
      "|    n_updates        | 9889     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.8     |\n",
      "|    ep_rew_mean      | 0.88     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1968     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 39742    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.25e-06 |\n",
      "|    n_updates        | 9910     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.3     |\n",
      "|    ep_rew_mean      | 0.87     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1972     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 39775    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000318 |\n",
      "|    n_updates        | 9918     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13       |\n",
      "|    ep_rew_mean      | 0.86     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1976     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 39821    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.61e-07 |\n",
      "|    n_updates        | 9930     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 0.86     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1980     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 39898    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.63e-07 |\n",
      "|    n_updates        | 9949     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 0.87     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1984     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 39954    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.31e-07 |\n",
      "|    n_updates        | 9963     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 0.87     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1988     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 40011    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 9977     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.5     |\n",
      "|    ep_rew_mean      | 0.87     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1992     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 40133    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00387  |\n",
      "|    n_updates        | 10008    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.4     |\n",
      "|    ep_rew_mean      | 0.87     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1996     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 40397    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00395  |\n",
      "|    n_updates        | 10074    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.4     |\n",
      "|    ep_rew_mean      | 0.87     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2000     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 40421    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000273 |\n",
      "|    n_updates        | 10080    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.7     |\n",
      "|    ep_rew_mean      | 0.88     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2004     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 40445    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00173  |\n",
      "|    n_updates        | 10086    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.5     |\n",
      "|    ep_rew_mean      | 0.89     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2008     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 40469    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000367 |\n",
      "|    n_updates        | 10092    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.7     |\n",
      "|    ep_rew_mean      | 0.9      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2012     |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 40493    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000176 |\n",
      "|    n_updates        | 10098    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.7     |\n",
      "|    ep_rew_mean      | 0.9      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2016     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 40517    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00594  |\n",
      "|    n_updates        | 10104    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.3     |\n",
      "|    ep_rew_mean      | 0.9      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2020     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 40625    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000186 |\n",
      "|    n_updates        | 10131    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.8     |\n",
      "|    ep_rew_mean      | 0.91     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2024     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 40649    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000379 |\n",
      "|    n_updates        | 10137    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.4     |\n",
      "|    ep_rew_mean      | 0.91     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2028     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 40673    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000889 |\n",
      "|    n_updates        | 10143    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.4     |\n",
      "|    ep_rew_mean      | 0.91     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2032     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 40700    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.43e-05 |\n",
      "|    n_updates        | 10149    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.9     |\n",
      "|    ep_rew_mean      | 0.92     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2036     |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 40743    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000263 |\n",
      "|    n_updates        | 10160    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.9     |\n",
      "|    ep_rew_mean      | 0.93     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2040     |\n",
      "|    fps              | 962      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 40769    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00611  |\n",
      "|    n_updates        | 10167    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 0.93     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2044     |\n",
      "|    fps              | 962      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 40793    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.74e-05 |\n",
      "|    n_updates        | 10173    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 0.92     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2048     |\n",
      "|    fps              | 962      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 40815    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00163  |\n",
      "|    n_updates        | 10178    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 0.92     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2052     |\n",
      "|    fps              | 962      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 40838    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.3e-05  |\n",
      "|    n_updates        | 10184    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 0.92     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2056     |\n",
      "|    fps              | 962      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 40862    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000453 |\n",
      "|    n_updates        | 10190    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 0.91     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2060     |\n",
      "|    fps              | 962      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 40888    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00675  |\n",
      "|    n_updates        | 10196    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.6     |\n",
      "|    ep_rew_mean      | 0.9      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2064     |\n",
      "|    fps              | 962      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 40914    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00028  |\n",
      "|    n_updates        | 10203    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12       |\n",
      "|    ep_rew_mean      | 0.91     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2068     |\n",
      "|    fps              | 962      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 40940    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 10209    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.9     |\n",
      "|    ep_rew_mean      | 0.92     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2072     |\n",
      "|    fps              | 961      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 40964    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000282 |\n",
      "|    n_updates        | 10215    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.7     |\n",
      "|    ep_rew_mean      | 0.93     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2076     |\n",
      "|    fps              | 961      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 40988    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.25e-05 |\n",
      "|    n_updates        | 10221    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.1     |\n",
      "|    ep_rew_mean      | 0.93     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2080     |\n",
      "|    fps              | 961      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 41012    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000108 |\n",
      "|    n_updates        | 10227    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.8     |\n",
      "|    ep_rew_mean      | 0.93     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2084     |\n",
      "|    fps              | 961      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 41036    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.64e-05 |\n",
      "|    n_updates        | 10233    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.5     |\n",
      "|    ep_rew_mean      | 0.93     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2088     |\n",
      "|    fps              | 961      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 41060    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.51e-05 |\n",
      "|    n_updates        | 10239    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.51     |\n",
      "|    ep_rew_mean      | 0.94     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2092     |\n",
      "|    fps              | 961      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 41084    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.15e-05 |\n",
      "|    n_updates        | 10245    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.11     |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2096     |\n",
      "|    fps              | 961      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 41108    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000145 |\n",
      "|    n_updates        | 10251    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.11     |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2100     |\n",
      "|    fps              | 961      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 41132    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.19e-05 |\n",
      "|    n_updates        | 10257    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.15     |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2104     |\n",
      "|    fps              | 961      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 41160    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000725 |\n",
      "|    n_updates        | 10264    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.17     |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2108     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 41186    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.45e-05 |\n",
      "|    n_updates        | 10271    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.17     |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2112     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 41210    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.01e-05 |\n",
      "|    n_updates        | 10277    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.17     |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2116     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 41234    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.17e-05 |\n",
      "|    n_updates        | 10283    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6.35     |\n",
      "|    ep_rew_mean      | 0.96     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2120     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 41260    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.01e-05 |\n",
      "|    n_updates        | 10289    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6.35     |\n",
      "|    ep_rew_mean      | 0.96     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2124     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 41284    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.76e-05 |\n",
      "|    n_updates        | 10295    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6.37     |\n",
      "|    ep_rew_mean      | 0.96     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2128     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 41310    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.9e-05  |\n",
      "|    n_updates        | 10302    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6.34     |\n",
      "|    ep_rew_mean      | 0.96     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2132     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 41334    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00118  |\n",
      "|    n_updates        | 10308    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6.18     |\n",
      "|    ep_rew_mean      | 0.96     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2136     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 41361    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.93e-05 |\n",
      "|    n_updates        | 10315    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6.57     |\n",
      "|    ep_rew_mean      | 0.96     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2140     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 41426    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.27e-05 |\n",
      "|    n_updates        | 10331    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6.61     |\n",
      "|    ep_rew_mean      | 0.96     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2144     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 41454    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000359 |\n",
      "|    n_updates        | 10338    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6.65     |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2148     |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 41480    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000336 |\n",
      "|    n_updates        | 10344    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6.67     |\n",
      "|    ep_rew_mean      | 0.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2152     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 41505    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.76e-05 |\n",
      "|    n_updates        | 10351    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6.68     |\n",
      "|    ep_rew_mean      | 0.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2156     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 41530    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.6e-05  |\n",
      "|    n_updates        | 10357    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6.66     |\n",
      "|    ep_rew_mean      | 0.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2160     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 41554    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000261 |\n",
      "|    n_updates        | 10363    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6.64     |\n",
      "|    ep_rew_mean      | 1        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2164     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 41578    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.59e-05 |\n",
      "|    n_updates        | 10369    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6.62     |\n",
      "|    ep_rew_mean      | 1        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2168     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 41602    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00063  |\n",
      "|    n_updates        | 10375    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6.63     |\n",
      "|    ep_rew_mean      | 1        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2172     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 41627    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00573  |\n",
      "|    n_updates        | 10381    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.16     |\n",
      "|    ep_rew_mean      | 1        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2176     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 41704    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.59e-05 |\n",
      "|    n_updates        | 10400    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.18     |\n",
      "|    ep_rew_mean      | 1        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2180     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 41730    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.58e-06 |\n",
      "|    n_updates        | 10407    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.19     |\n",
      "|    ep_rew_mean      | 1        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2184     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 41755    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000181 |\n",
      "|    n_updates        | 10413    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.19     |\n",
      "|    ep_rew_mean      | 1        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2188     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 41779    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.91e-05 |\n",
      "|    n_updates        | 10419    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.19     |\n",
      "|    ep_rew_mean      | 1        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2192     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 41803    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000375 |\n",
      "|    n_updates        | 10425    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.17     |\n",
      "|    ep_rew_mean      | 0.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2196     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 41825    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.16e-05 |\n",
      "|    n_updates        | 10431    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.25     |\n",
      "|    ep_rew_mean      | 0.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2200     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 41857    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.27e-06 |\n",
      "|    n_updates        | 10439    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.51     |\n",
      "|    ep_rew_mean      | 0.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2204     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 41911    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000166 |\n",
      "|    n_updates        | 10452    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.49     |\n",
      "|    ep_rew_mean      | 0.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2208     |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 41935    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000104 |\n",
      "|    n_updates        | 10458    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.49     |\n",
      "|    ep_rew_mean      | 0.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2212     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 41959    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000112 |\n",
      "|    n_updates        | 10464    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.49     |\n",
      "|    ep_rew_mean      | 0.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2216     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 41983    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000148 |\n",
      "|    n_updates        | 10470    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.47     |\n",
      "|    ep_rew_mean      | 0.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2220     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 42007    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.36e-06 |\n",
      "|    n_updates        | 10476    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.47     |\n",
      "|    ep_rew_mean      | 0.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2224     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 42031    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000124 |\n",
      "|    n_updates        | 10482    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.47     |\n",
      "|    ep_rew_mean      | 0.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2228     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 42057    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.36e-05 |\n",
      "|    n_updates        | 10489    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.49     |\n",
      "|    ep_rew_mean      | 0.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2232     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 42083    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.98e-05 |\n",
      "|    n_updates        | 10495    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.85     |\n",
      "|    ep_rew_mean      | 0.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2236     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 42146    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.79e-06 |\n",
      "|    n_updates        | 10511    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.66     |\n",
      "|    ep_rew_mean      | 0.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2240     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42192    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.07e-05 |\n",
      "|    n_updates        | 10522    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.84     |\n",
      "|    ep_rew_mean      | 0.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2244     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42238    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00028  |\n",
      "|    n_updates        | 10534    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.09     |\n",
      "|    ep_rew_mean      | 0.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2248     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42289    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.09e-05 |\n",
      "|    n_updates        | 10547    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.89     |\n",
      "|    ep_rew_mean      | 0.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2252     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42394    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.07e-06 |\n",
      "|    n_updates        | 10573    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.9      |\n",
      "|    ep_rew_mean      | 0.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2256     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42420    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000144 |\n",
      "|    n_updates        | 10579    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.89     |\n",
      "|    ep_rew_mean      | 0.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2260     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42443    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000119 |\n",
      "|    n_updates        | 10585    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.85     |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2264     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42463    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.11e-05 |\n",
      "|    n_updates        | 10590    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.87     |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2268     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42489    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.2e-05  |\n",
      "|    n_updates        | 10597    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.9      |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2272     |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42517    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.78e-06 |\n",
      "|    n_updates        | 10604    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.8      |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2276     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42584    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.18e-06 |\n",
      "|    n_updates        | 10620    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.86     |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2280     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42616    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.15e-06 |\n",
      "|    n_updates        | 10628    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.85     |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2284     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42640    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.31e-05 |\n",
      "|    n_updates        | 10634    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.85     |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2288     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42664    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.38e-05 |\n",
      "|    n_updates        | 10640    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.87     |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2292     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42690    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.8e-05  |\n",
      "|    n_updates        | 10647    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.89     |\n",
      "|    ep_rew_mean      | 0.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2296     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42714    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.95e-06 |\n",
      "|    n_updates        | 10653    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.82     |\n",
      "|    ep_rew_mean      | 0.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2300     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42739    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.77e-07 |\n",
      "|    n_updates        | 10659    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.54     |\n",
      "|    ep_rew_mean      | 0.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2304     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42765    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.96e-06 |\n",
      "|    n_updates        | 10666    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.54     |\n",
      "|    ep_rew_mean      | 0.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2308     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42789    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.17e-06 |\n",
      "|    n_updates        | 10672    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.56     |\n",
      "|    ep_rew_mean      | 0.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2312     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42815    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000107 |\n",
      "|    n_updates        | 10678    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.57     |\n",
      "|    ep_rew_mean      | 0.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2316     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42840    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000107 |\n",
      "|    n_updates        | 10684    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.55     |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2320     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42862    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.34e-05 |\n",
      "|    n_updates        | 10690    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.55     |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2324     |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42886    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.28e-05 |\n",
      "|    n_updates        | 10696    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.87     |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2328     |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42944    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.33e-06 |\n",
      "|    n_updates        | 10710    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.89     |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2332     |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42972    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.37e-06 |\n",
      "|    n_updates        | 10717    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.52     |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2336     |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 42998    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.96e-06 |\n",
      "|    n_updates        | 10724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.33     |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2340     |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 43025    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.67e-06 |\n",
      "|    n_updates        | 10731    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.77     |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2344     |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 43115    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.61e-06 |\n",
      "|    n_updates        | 10753    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.51     |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2348     |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 43140    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.35e-05 |\n",
      "|    n_updates        | 10759    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.42     |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2352     |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 43236    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.9e-06  |\n",
      "|    n_updates        | 10783    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.48     |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2356     |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 43268    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.32e-06 |\n",
      "|    n_updates        | 10791    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.6      |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2360     |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 43303    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.5e-06  |\n",
      "|    n_updates        | 10800    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.73     |\n",
      "|    ep_rew_mean      | 0.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2364     |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 43336    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.93e-05 |\n",
      "|    n_updates        | 10808    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.73     |\n",
      "|    ep_rew_mean      | 0.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2368     |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 43362    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.36e-06 |\n",
      "|    n_updates        | 10815    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.62     |\n",
      "|    ep_rew_mean      | 0.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2372     |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 43479    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.57e-06 |\n",
      "|    n_updates        | 10844    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.58     |\n",
      "|    ep_rew_mean      | 0.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2376     |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 43542    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.42e-06 |\n",
      "|    n_updates        | 10860    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.5      |\n",
      "|    ep_rew_mean      | 0.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2380     |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 43566    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000141 |\n",
      "|    n_updates        | 10866    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.5      |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2384     |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 43590    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.19e-06 |\n",
      "|    n_updates        | 10872    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.5      |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2388     |\n",
      "|    fps              | 954      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 43614    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.5e-05  |\n",
      "|    n_updates        | 10878    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.46     |\n",
      "|    ep_rew_mean      | 0.96     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2392     |\n",
      "|    fps              | 954      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 43636    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.05e-06 |\n",
      "|    n_updates        | 10883    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.98     |\n",
      "|    ep_rew_mean      | 0.96     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2396     |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 43712    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.57e-05 |\n",
      "|    n_updates        | 10902    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.4     |\n",
      "|    ep_rew_mean      | 0.96     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2400     |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 43778    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.12e-05 |\n",
      "|    n_updates        | 10919    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.4     |\n",
      "|    ep_rew_mean      | 0.96     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2404     |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 43804    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.23e-05 |\n",
      "|    n_updates        | 10925    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.4     |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2408     |\n",
      "|    fps              | 954      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 43826    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.13e-06 |\n",
      "|    n_updates        | 10931    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.3     |\n",
      "|    ep_rew_mean      | 0.94     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2412     |\n",
      "|    fps              | 954      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 43849    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.29e-05 |\n",
      "|    n_updates        | 10937    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.7     |\n",
      "|    ep_rew_mean      | 0.94     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2416     |\n",
      "|    fps              | 954      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 43912    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.46e-06 |\n",
      "|    n_updates        | 10952    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.7     |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2420     |\n",
      "|    fps              | 954      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 43936    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.2e-05  |\n",
      "|    n_updates        | 10958    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.7     |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2424     |\n",
      "|    fps              | 954      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 43960    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.32e-05 |\n",
      "|    n_updates        | 10964    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.4     |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2428     |\n",
      "|    fps              | 954      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 43986    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.41e-06 |\n",
      "|    n_updates        | 10971    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.4     |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2432     |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 44010    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.49e-06 |\n",
      "|    n_updates        | 10977    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.4     |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2436     |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 44036    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.98e-06 |\n",
      "|    n_updates        | 10983    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.3     |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2440     |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 44060    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.81e-06 |\n",
      "|    n_updates        | 10989    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.75     |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2444     |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 44090    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.97e-07 |\n",
      "|    n_updates        | 10997    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.76     |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2448     |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 44116    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.66e-07 |\n",
      "|    n_updates        | 11003    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.04     |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2452     |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 44140    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000122 |\n",
      "|    n_updates        | 11009    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.62     |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2456     |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 44230    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.45e-07 |\n",
      "|    n_updates        | 11032    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.53     |\n",
      "|    ep_rew_mean      | 0.96     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2460     |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 44256    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.66e-06 |\n",
      "|    n_updates        | 11038    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.46     |\n",
      "|    ep_rew_mean      | 0.96     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2464     |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 44282    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.59e-07 |\n",
      "|    n_updates        | 11045    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.46     |\n",
      "|    ep_rew_mean      | 0.96     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2468     |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 44308    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.65e-06 |\n",
      "|    n_updates        | 11051    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 8.55     |\n",
      "|    ep_rew_mean      | 0.96     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2472     |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 44334    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.69e-07 |\n",
      "|    n_updates        | 11058    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.14     |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2476     |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 44456    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.71e-06 |\n",
      "|    n_updates        | 11088    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.25     |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2480     |\n",
      "|    fps              | 952      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 44491    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.31e-06 |\n",
      "|    n_updates        | 11097    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.8      |\n",
      "|    ep_rew_mean      | 0.96     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2484     |\n",
      "|    fps              | 952      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 44570    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.84e-06 |\n",
      "|    n_updates        | 11117    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.79     |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2488     |\n",
      "|    fps              | 952      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 44593    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.22e-06 |\n",
      "|    n_updates        | 11123    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.81     |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2492     |\n",
      "|    fps              | 952      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 44617    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.63e-06 |\n",
      "|    n_updates        | 11129    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.7     |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2496     |\n",
      "|    fps              | 952      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 44785    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.65e-05 |\n",
      "|    n_updates        | 11171    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.6     |\n",
      "|    ep_rew_mean      | 0.94     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2500     |\n",
      "|    fps              | 952      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 44838    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.74e-06 |\n",
      "|    n_updates        | 11184    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.6     |\n",
      "|    ep_rew_mean      | 0.94     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2504     |\n",
      "|    fps              | 952      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 44863    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.53e-06 |\n",
      "|    n_updates        | 11190    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.6     |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2508     |\n",
      "|    fps              | 952      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 44889    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.02e-05 |\n",
      "|    n_updates        | 11197    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.6     |\n",
      "|    ep_rew_mean      | 0.94     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2512     |\n",
      "|    fps              | 952      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 44909    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.97e-06 |\n",
      "|    n_updates        | 11202    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 0.94     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2516     |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 44935    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.45e-06 |\n",
      "|    n_updates        | 11208    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 0.93     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2520     |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 44958    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.41e-07 |\n",
      "|    n_updates        | 11214    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 0.93     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2524     |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 44985    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.7e-05  |\n",
      "|    n_updates        | 11221    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.7     |\n",
      "|    ep_rew_mean      | 0.93     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2528     |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 45054    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.15e-06 |\n",
      "|    n_updates        | 11238    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 0.89     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2532     |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 45395    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.19e-07 |\n",
      "|    n_updates        | 11323    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.1     |\n",
      "|    ep_rew_mean      | 0.86     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2536     |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 45743    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.03e-06 |\n",
      "|    n_updates        | 11410    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | 0.85     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2540     |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 45974    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.59e-06 |\n",
      "|    n_updates        | 11468    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.5     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2544     |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 46041    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.22e-07 |\n",
      "|    n_updates        | 11485    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.5     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2548     |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 46067    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.72e-07 |\n",
      "|    n_updates        | 11491    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.5     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2552     |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 46091    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.67e-06 |\n",
      "|    n_updates        | 11497    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.6     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2556     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 46195    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.83e-06 |\n",
      "|    n_updates        | 11523    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.6     |\n",
      "|    ep_rew_mean      | 0.83     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2560     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 46219    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000942 |\n",
      "|    n_updates        | 11529    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | 0.83     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2564     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 46288    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.99e-06 |\n",
      "|    n_updates        | 11546    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | 0.83     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2568     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 46313    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.68e-06 |\n",
      "|    n_updates        | 11553    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | 0.83     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2572     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 46366    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.89e-07 |\n",
      "|    n_updates        | 11566    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20       |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2576     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 46457    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.02e-06 |\n",
      "|    n_updates        | 11589    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.9     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2580     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 46484    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.59e-06 |\n",
      "|    n_updates        | 11595    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.8     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2584     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 46550    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.67e-06 |\n",
      "|    n_updates        | 11612    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.8     |\n",
      "|    ep_rew_mean      | 0.85     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2588     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 46574    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.95e-06 |\n",
      "|    n_updates        | 11618    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | 0.85     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2592     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 46645    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.21e-06 |\n",
      "|    n_updates        | 11636    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.9     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2596     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 46672    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.31e-07 |\n",
      "|    n_updates        | 11642    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | 0.85     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2600     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 46696    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.11e-07 |\n",
      "|    n_updates        | 11648    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2604     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 46718    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.78e-07 |\n",
      "|    n_updates        | 11654    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.5     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2608     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 46742    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.32e-07 |\n",
      "|    n_updates        | 11660    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.2     |\n",
      "|    ep_rew_mean      | 0.85     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2612     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 46828    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.29e-06 |\n",
      "|    n_updates        | 11681    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.2     |\n",
      "|    ep_rew_mean      | 0.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2616     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 46853    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.58e-05 |\n",
      "|    n_updates        | 11688    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.2     |\n",
      "|    ep_rew_mean      | 0.85     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2620     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 46877    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.95e-07 |\n",
      "|    n_updates        | 11694    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.3     |\n",
      "|    ep_rew_mean      | 0.85     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2624     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 46918    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.33e-06 |\n",
      "|    n_updates        | 11704    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.9     |\n",
      "|    ep_rew_mean      | 0.85     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2628     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 46944    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.94e-06 |\n",
      "|    n_updates        | 11710    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.7     |\n",
      "|    ep_rew_mean      | 0.88     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2632     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 46964    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.02e-06 |\n",
      "|    n_updates        | 11715    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.6     |\n",
      "|    ep_rew_mean      | 0.9      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2636     |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 47006    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.43e-06 |\n",
      "|    n_updates        | 11726    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.9     |\n",
      "|    ep_rew_mean      | 0.9      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2640     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 47164    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.59e-06 |\n",
      "|    n_updates        | 11765    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.5     |\n",
      "|    ep_rew_mean      | 0.9      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2644     |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 47188    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.3e-05  |\n",
      "|    n_updates        | 11771    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.5     |\n",
      "|    ep_rew_mean      | 0.9      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2648     |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 47214    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.58e-07 |\n",
      "|    n_updates        | 11778    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.2     |\n",
      "|    ep_rew_mean      | 0.9      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2652     |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 47310    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.59e-06 |\n",
      "|    n_updates        | 11802    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.4     |\n",
      "|    ep_rew_mean      | 0.9      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2656     |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 47334    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.97e-06 |\n",
      "|    n_updates        | 11808    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.8     |\n",
      "|    ep_rew_mean      | 0.91     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2660     |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 47396    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.42e-06 |\n",
      "|    n_updates        | 11823    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.3     |\n",
      "|    ep_rew_mean      | 0.91     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2664     |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 47423    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.2e-06  |\n",
      "|    n_updates        | 11830    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.3     |\n",
      "|    ep_rew_mean      | 0.91     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2668     |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 47448    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.56e-06 |\n",
      "|    n_updates        | 11836    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.2     |\n",
      "|    ep_rew_mean      | 0.91     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2672     |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 47483    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.02e-05 |\n",
      "|    n_updates        | 11845    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.7     |\n",
      "|    ep_rew_mean      | 0.91     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2676     |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 47526    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.51e-07 |\n",
      "|    n_updates        | 11856    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.7     |\n",
      "|    ep_rew_mean      | 0.91     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2680     |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 47550    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.34e-06 |\n",
      "|    n_updates        | 11862    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.9     |\n",
      "|    ep_rew_mean      | 0.91     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2684     |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 47640    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00414  |\n",
      "|    n_updates        | 11884    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.9     |\n",
      "|    ep_rew_mean      | 0.91     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2688     |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 47664    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.83e-06 |\n",
      "|    n_updates        | 11890    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.4     |\n",
      "|    ep_rew_mean      | 0.92     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2692     |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 47689    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.35e-05 |\n",
      "|    n_updates        | 11897    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.4     |\n",
      "|    ep_rew_mean      | 0.93     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2696     |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 47713    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.5e-06  |\n",
      "|    n_updates        | 11903    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.3     |\n",
      "|    ep_rew_mean      | 0.93     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2700     |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 47830    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.69e-06 |\n",
      "|    n_updates        | 11932    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.4     |\n",
      "|    ep_rew_mean      | 0.94     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2704     |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 47856    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.23e-06 |\n",
      "|    n_updates        | 11938    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.8     |\n",
      "|    ep_rew_mean      | 0.94     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2708     |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 47922    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.3e-06  |\n",
      "|    n_updates        | 11955    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.3     |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2712     |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 47956    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.12e-05 |\n",
      "|    n_updates        | 11963    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.4     |\n",
      "|    ep_rew_mean      | 0.96     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2716     |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 48098    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.73e-07 |\n",
      "|    n_updates        | 11999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.9     |\n",
      "|    ep_rew_mean      | 0.96     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2720     |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 48172    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000436 |\n",
      "|    n_updates        | 12017    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 0.96     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2724     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 48257    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.5e-06  |\n",
      "|    n_updates        | 12039    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 0.96     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2728     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 48281    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.69e-06 |\n",
      "|    n_updates        | 12045    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 0.96     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2732     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 48340    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.03e-06 |\n",
      "|    n_updates        | 12059    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2736     |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 48368    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000305 |\n",
      "|    n_updates        | 12066    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.3     |\n",
      "|    ep_rew_mean      | 0.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2740     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 48394    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.81e-07 |\n",
      "|    n_updates        | 12073    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.6     |\n",
      "|    ep_rew_mean      | 0.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2744     |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 48451    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.17e-06 |\n",
      "|    n_updates        | 12087    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.7     |\n",
      "|    ep_rew_mean      | 0.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2748     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 48486    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.2e-06  |\n",
      "|    n_updates        | 12096    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.1     |\n",
      "|    ep_rew_mean      | 0.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2752     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 48516    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.74e-06 |\n",
      "|    n_updates        | 12103    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.1     |\n",
      "|    ep_rew_mean      | 0.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2756     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 48540    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.31e-06 |\n",
      "|    n_updates        | 12109    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.1     |\n",
      "|    ep_rew_mean      | 0.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2760     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 48604    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.34e-07 |\n",
      "|    n_updates        | 12125    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.1     |\n",
      "|    ep_rew_mean      | 0.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2764     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 48633    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.02e-06 |\n",
      "|    n_updates        | 12133    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.6     |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2768     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 48710    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.43e-07 |\n",
      "|    n_updates        | 12152    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.5     |\n",
      "|    ep_rew_mean      | 0.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2772     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 48736    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.2e-06  |\n",
      "|    n_updates        | 12158    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14       |\n",
      "|    ep_rew_mean      | 0.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2776     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 48922    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.57e-07 |\n",
      "|    n_updates        | 12205    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.4     |\n",
      "|    ep_rew_mean      | 0.94     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2780     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 48986    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.59e-07 |\n",
      "|    n_updates        | 12221    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 0.94     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2784     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 49010    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00106  |\n",
      "|    n_updates        | 12227    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 0.93     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2788     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 49034    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.66e-06 |\n",
      "|    n_updates        | 12233    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 0.92     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2792     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 49058    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.93e-06 |\n",
      "|    n_updates        | 12239    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 0.92     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2796     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 49082    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.87e-06 |\n",
      "|    n_updates        | 12245    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 0.92     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2800     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 49106    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.14e-06 |\n",
      "|    n_updates        | 12251    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 0.92     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2804     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 49232    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.21e-05 |\n",
      "|    n_updates        | 12282    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 0.92     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2808     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 49256    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.27e-07 |\n",
      "|    n_updates        | 12288    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 0.91     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2812     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 49327    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.61e-07 |\n",
      "|    n_updates        | 12306    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.7     |\n",
      "|    ep_rew_mean      | 0.91     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2816     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 49364    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.06e-07 |\n",
      "|    n_updates        | 12315    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.2     |\n",
      "|    ep_rew_mean      | 0.91     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2820     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 49388    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.58e-08 |\n",
      "|    n_updates        | 12321    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.2     |\n",
      "|    ep_rew_mean      | 0.91     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2824     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 49478    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000608 |\n",
      "|    n_updates        | 12344    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.2     |\n",
      "|    ep_rew_mean      | 0.9      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2828     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 49500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.88e-06 |\n",
      "|    n_updates        | 12349    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 0.9      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2832     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 49620    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.35e-06 |\n",
      "|    n_updates        | 12379    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.8     |\n",
      "|    ep_rew_mean      | 0.87     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2836     |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 49850    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.62e-08 |\n",
      "|    n_updates        | 12437    |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "train(\"FrozenLake-v1\", total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba85a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dqn_and_record_video(model_path: str, env_name: str = \"FrozenLake-v1\", video_length: int = 500):\n",
    "    \"\"\"\n",
    "    Tests a trained DQN agent on a specified environment for one episode\n",
    "    and records a video of the episode.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): The path to the trained DQN model.\n",
    "        env_name (str): The name of the environment to test on.\n",
    "        video_length (int): The maximum number of timesteps to record for the video.\n",
    "    \"\"\"\n",
    "    # Create the environment for testing\n",
    "    eval_env = gym.make(env_name,is_slippery=False, render_mode=\"rgb_array\")\n",
    "    \n",
    "    # Wrap the environment for video recording\n",
    "    # DummyVecEnv is used here because VecVideoRecorder expects a vectorized environment\n",
    "    eval_env = DummyVecEnv([lambda: eval_env]) \n",
    "    \n",
    "    video_folder = \"videos_FrozenLake_dqn\"\n",
    "    video_recorder = VecVideoRecorder(\n",
    "        eval_env, video_folder, \n",
    "        record_video_trigger=lambda x: x == 0,\n",
    "        video_length=video_length,\n",
    "        name_prefix=f\"dqn-frozenlake-test\"\n",
    "    )\n",
    "\n",
    "    # Load the trained model\n",
    "    model = DQN.load(model_path, env=video_recorder)\n",
    "\n",
    "    print(\"Starting video recording...\")\n",
    "    obs = video_recorder.reset()\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = video_recorder.step(action)\n",
    "        episode_reward += reward[0]\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    video_recorder.close()\n",
    "    print(f\"Video recorded to: {video_folder}\")\n",
    "    print(f\"Episode Reward: {episode_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f30f5d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting video recording...\n",
      "MoviePy - Building video c:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\videos_FrozenLake_dqn\\dqn-frozenlake-test-step-0-to-step-500.mp4.\n",
      "MoviePy - Writing video c:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\videos_FrozenLake_dqn\\dqn-frozenlake-test-step-0-to-step-500.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready c:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\videos_FrozenLake_dqn\\dqn-frozenlake-test-step-0-to-step-500.mp4\n",
      "Video recorded to: videos_FrozenLake_dqn\n",
      "Episode Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "test_dqn_and_record_video(model_path=\"frozenlake_dqn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3828a9ef",
   "metadata": {},
   "source": [
    "## DQN on CartPole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c3750ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if GPU is to be used\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else\n",
    "    \"mps\" if torch.backends.mps.is_available() else\n",
    "    \"cpu\"\n",
    ")\n",
    "\n",
    "\n",
    "# To ensure reproducibility during training, you can fix the random seeds\n",
    "# by uncommenting the lines below. This makes the results consistent across\n",
    "# runs, which is helpful for debugging or comparing different approaches.\n",
    "#\n",
    "# That said, allowing randomness can be beneficial in practice, as it lets\n",
    "# the model explore different training trajectories.\n",
    "\n",
    "\n",
    "# seed = 42\n",
    "# random.seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "# env.reset(seed=seed)\n",
    "# env.action_space.seed(seed)\n",
    "# env.observation_space.seed(seed)\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1b2f236",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cfa2470",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = nn.Linear(128, n_actions)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd5136dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
    "# GAMMA is the discount factor as mentioned in the previous section\n",
    "# EPS_START is the starting value of epsilon\n",
    "# EPS_END is the final value of epsilon\n",
    "# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
    "# TAU is the update rate of the target network\n",
    "# LR is the learning rate of the ``AdamW`` optimizer\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.01\n",
    "EPS_DECAY = 2500\n",
    "TAU = 0.005\n",
    "LR = 3e-4\n",
    "\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "# Get the number of state observations\n",
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "policy_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return the largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1).indices.view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations(show_result=False):\n",
    "    plt.figure(1)\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    if show_result:\n",
    "        plt.title('Result')\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2031bed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1).values\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # In-place gradient clipping\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39a90cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if torch.cuda.is_available() or torch.backends.mps.is_available():\n",
    "    num_episodes = 600\n",
    "else:\n",
    "    num_episodes = 50\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and get its state\n",
    "    state, info = env.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    for t in count():\n",
    "        action = select_action(state)\n",
    "        observation, reward, terminated, truncated, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "\n",
    "        # Soft update of the target network's weights\n",
    "        # θ′ ← τ θ + (1 −τ )θ′\n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_state_dict = policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        target_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "\n",
    "print('Complete')\n",
    "plot_durations(show_result=True)\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42f73da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 finished with reward: 500.0\n",
      "Episode 2 finished with reward: 500.0\n",
      "Episode 3 finished with reward: 500.0\n",
      "Episode 4 finished with reward: 500.0\n",
      "Episode 5 finished with reward: 500.0\n",
      "\n",
      "Average reward over 5 test episodes: 500.0\n"
     ]
    }
   ],
   "source": [
    "num_test_episodes = 5 # How many episodes to run for testing\n",
    "total_rewards = []\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "env = RecordVideo(\n",
    "    env,\n",
    "    video_folder=\"videos_cartpole-dqn_agent\",    # Folder to save videos\n",
    "    name_prefix=\"eval\",               # Prefix for video filenames\n",
    "    episode_trigger=lambda x: True    # Record every episode\n",
    ")\n",
    "\n",
    "for episode in range(num_test_episodes):\n",
    "    obs, info = env.reset()\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    truncated = False\n",
    "\n",
    "    while not done and not truncated:\n",
    "        # Convert observation to a PyTorch tensor\n",
    "        obs_tensor = torch.tensor(obs, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        # Get Q-values from the model\n",
    "        with torch.no_grad(): # No need to calculate gradients during testing\n",
    "            q_values = policy_net(obs_tensor.to(device))\n",
    "\n",
    "        # Select the action with the highest Q-value (greedy action)\n",
    "        action = torch.argmax(q_values).item()\n",
    "\n",
    "        # Take the action in the environment\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        episode_reward += reward\n",
    "\n",
    "        env.render() # This will display the environment\n",
    "\n",
    "    total_rewards.append(episode_reward)\n",
    "    print(f\"Episode {episode + 1} finished with reward: {episode_reward}\")\n",
    "\n",
    "env.close()\n",
    "\n",
    "# Calculate average reward\n",
    "average_reward = sum(total_rewards) / num_test_episodes\n",
    "print(f\"\\nAverage reward over {num_test_episodes} test episodes: {average_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0e1e26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\.venv\\Lib\\site-packages\\gymnasium\\envs\\registration.py:512: DeprecationWarning: \u001b[33mWARN: The environment InvertedPendulum-v4 is out of date. You should consider upgrading to version `v5`.\u001b[0m\n",
      "  logger.deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 finished with a total reward of: 3.00\n",
      "Episode 2 finished with a total reward of: 6.00\n",
      "Episode 3 finished with a total reward of: 6.00\n",
      "Episode 4 finished with a total reward of: 7.00\n",
      "Episode 5 finished with a total reward of: 8.00\n",
      "Episode 6 finished with a total reward of: 3.00\n",
      "Episode 7 finished with a total reward of: 3.00\n",
      "Episode 8 finished with a total reward of: 5.00\n",
      "Episode 9 finished with a total reward of: 6.00\n",
      "Episode 10 finished with a total reward of: 4.00\n",
      "Episode 11 finished with a total reward of: 5.00\n",
      "Episode 12 finished with a total reward of: 5.00\n",
      "Episode 13 finished with a total reward of: 4.00\n",
      "Episode 14 finished with a total reward of: 4.00\n",
      "Episode 15 finished with a total reward of: 5.00\n",
      "Episode 16 finished with a total reward of: 6.00\n",
      "Episode 17 finished with a total reward of: 9.00\n",
      "Episode 18 finished with a total reward of: 6.00\n",
      "Episode 19 finished with a total reward of: 12.00\n",
      "Episode 20 finished with a total reward of: 6.00\n",
      "Episode 21 finished with a total reward of: 4.00\n",
      "Episode 22 finished with a total reward of: 12.00\n",
      "Episode 23 finished with a total reward of: 3.00\n",
      "Episode 24 finished with a total reward of: 4.00\n",
      "Episode 25 finished with a total reward of: 5.00\n",
      "Episode 26 finished with a total reward of: 4.00\n",
      "Episode 27 finished with a total reward of: 4.00\n",
      "Episode 28 finished with a total reward of: 6.00\n",
      "Episode 29 finished with a total reward of: 3.00\n",
      "Episode 30 finished with a total reward of: 11.00\n",
      "Episode 31 finished with a total reward of: 29.00\n",
      "Episode 32 finished with a total reward of: 4.00\n",
      "Episode 33 finished with a total reward of: 4.00\n",
      "Episode 34 finished with a total reward of: 8.00\n",
      "Episode 35 finished with a total reward of: 6.00\n",
      "Episode 36 finished with a total reward of: 3.00\n",
      "Episode 37 finished with a total reward of: 6.00\n",
      "Episode 38 finished with a total reward of: 5.00\n",
      "Episode 39 finished with a total reward of: 5.00\n",
      "Episode 40 finished with a total reward of: 6.00\n",
      "Episode 41 finished with a total reward of: 8.00\n",
      "Episode 42 finished with a total reward of: 12.00\n",
      "Episode 43 finished with a total reward of: 5.00\n",
      "Episode 44 finished with a total reward of: 6.00\n",
      "Episode 45 finished with a total reward of: 6.00\n",
      "Episode 46 finished with a total reward of: 8.00\n",
      "Episode 47 finished with a total reward of: 11.00\n",
      "Episode 48 finished with a total reward of: 6.00\n",
      "Episode 49 finished with a total reward of: 8.00\n",
      "Episode 50 finished with a total reward of: 3.00\n",
      "Episode 51 finished with a total reward of: 7.00\n",
      "Episode 52 finished with a total reward of: 3.00\n",
      "Episode 53 finished with a total reward of: 3.00\n",
      "Episode 54 finished with a total reward of: 4.00\n",
      "Episode 55 finished with a total reward of: 7.00\n",
      "Episode 56 finished with a total reward of: 4.00\n",
      "Episode 57 finished with a total reward of: 7.00\n",
      "Episode 58 finished with a total reward of: 3.00\n",
      "Episode 59 finished with a total reward of: 12.00\n",
      "Episode 60 finished with a total reward of: 3.00\n",
      "Episode 61 finished with a total reward of: 9.00\n",
      "Episode 62 finished with a total reward of: 10.00\n",
      "Episode 63 finished with a total reward of: 6.00\n",
      "Episode 64 finished with a total reward of: 8.00\n",
      "Episode 65 finished with a total reward of: 4.00\n",
      "Episode 66 finished with a total reward of: 10.00\n",
      "Episode 67 finished with a total reward of: 10.00\n",
      "Episode 68 finished with a total reward of: 8.00\n",
      "Episode 69 finished with a total reward of: 5.00\n",
      "Episode 70 finished with a total reward of: 4.00\n",
      "Episode 71 finished with a total reward of: 7.00\n",
      "Episode 72 finished with a total reward of: 5.00\n",
      "Episode 73 finished with a total reward of: 11.00\n",
      "Episode 74 finished with a total reward of: 11.00\n",
      "Episode 75 finished with a total reward of: 4.00\n",
      "Episode 76 finished with a total reward of: 8.00\n",
      "Episode 77 finished with a total reward of: 5.00\n",
      "Episode 78 finished with a total reward of: 8.00\n",
      "Episode 79 finished with a total reward of: 6.00\n",
      "Episode 80 finished with a total reward of: 5.00\n",
      "Episode 81 finished with a total reward of: 4.00\n",
      "Episode 82 finished with a total reward of: 4.00\n",
      "Episode 83 finished with a total reward of: 9.00\n",
      "Episode 84 finished with a total reward of: 7.00\n",
      "Episode 85 finished with a total reward of: 3.00\n",
      "Episode 86 finished with a total reward of: 6.00\n",
      "Episode 87 finished with a total reward of: 6.00\n",
      "Episode 88 finished with a total reward of: 4.00\n",
      "Episode 89 finished with a total reward of: 4.00\n",
      "Episode 90 finished with a total reward of: 5.00\n",
      "Episode 91 finished with a total reward of: 13.00\n",
      "Episode 92 finished with a total reward of: 10.00\n",
      "Episode 93 finished with a total reward of: 16.00\n",
      "Episode 94 finished with a total reward of: 4.00\n",
      "Episode 95 finished with a total reward of: 6.00\n",
      "Episode 96 finished with a total reward of: 8.00\n",
      "Episode 97 finished with a total reward of: 3.00\n",
      "Episode 98 finished with a total reward of: 5.00\n",
      "Episode 99 finished with a total reward of: 6.00\n",
      "Episode 100 finished with a total reward of: 6.00\n",
      "Episode 101 finished with a total reward of: 3.00\n",
      "Episode 102 finished with a total reward of: 5.00\n",
      "Episode 103 finished with a total reward of: 5.00\n",
      "Episode 104 finished with a total reward of: 4.00\n",
      "Episode 105 finished with a total reward of: 10.00\n",
      "Episode 106 finished with a total reward of: 4.00\n",
      "Episode 107 finished with a total reward of: 4.00\n",
      "Episode 108 finished with a total reward of: 19.00\n",
      "Episode 109 finished with a total reward of: 4.00\n",
      "Episode 110 finished with a total reward of: 6.00\n",
      "Episode 111 finished with a total reward of: 6.00\n",
      "Episode 112 finished with a total reward of: 6.00\n",
      "Episode 113 finished with a total reward of: 4.00\n",
      "Episode 114 finished with a total reward of: 3.00\n",
      "Episode 115 finished with a total reward of: 13.00\n",
      "Episode 116 finished with a total reward of: 6.00\n",
      "Episode 117 finished with a total reward of: 4.00\n",
      "Episode 118 finished with a total reward of: 13.00\n",
      "Episode 119 finished with a total reward of: 13.00\n",
      "Episode 120 finished with a total reward of: 3.00\n",
      "Episode 121 finished with a total reward of: 5.00\n",
      "Episode 122 finished with a total reward of: 3.00\n",
      "Episode 123 finished with a total reward of: 6.00\n",
      "Episode 124 finished with a total reward of: 12.00\n",
      "Episode 125 finished with a total reward of: 14.00\n",
      "Episode 126 finished with a total reward of: 3.00\n",
      "Episode 127 finished with a total reward of: 5.00\n",
      "Episode 128 finished with a total reward of: 3.00\n",
      "Episode 129 finished with a total reward of: 4.00\n",
      "Episode 130 finished with a total reward of: 7.00\n",
      "Episode 131 finished with a total reward of: 3.00\n",
      "Episode 132 finished with a total reward of: 4.00\n",
      "Episode 133 finished with a total reward of: 6.00\n",
      "Episode 134 finished with a total reward of: 3.00\n",
      "Episode 135 finished with a total reward of: 8.00\n",
      "Episode 136 finished with a total reward of: 3.00\n",
      "Episode 137 finished with a total reward of: 5.00\n",
      "Episode 138 finished with a total reward of: 4.00\n",
      "Episode 139 finished with a total reward of: 3.00\n",
      "Episode 140 finished with a total reward of: 4.00\n",
      "Episode 141 finished with a total reward of: 5.00\n",
      "Episode 142 finished with a total reward of: 12.00\n",
      "Episode 143 finished with a total reward of: 7.00\n",
      "Episode 144 finished with a total reward of: 3.00\n",
      "Episode 145 finished with a total reward of: 3.00\n",
      "Episode 146 finished with a total reward of: 3.00\n",
      "Episode 147 finished with a total reward of: 3.00\n",
      "Episode 148 finished with a total reward of: 4.00\n",
      "Episode 149 finished with a total reward of: 7.00\n",
      "Episode 150 finished with a total reward of: 4.00\n",
      "Episode 151 finished with a total reward of: 4.00\n",
      "Episode 152 finished with a total reward of: 5.00\n",
      "Episode 153 finished with a total reward of: 4.00\n",
      "Episode 154 finished with a total reward of: 15.00\n",
      "Episode 155 finished with a total reward of: 4.00\n",
      "Episode 156 finished with a total reward of: 5.00\n",
      "Episode 157 finished with a total reward of: 8.00\n",
      "Episode 158 finished with a total reward of: 6.00\n",
      "Episode 159 finished with a total reward of: 14.00\n",
      "Episode 160 finished with a total reward of: 3.00\n",
      "Episode 161 finished with a total reward of: 6.00\n",
      "Episode 162 finished with a total reward of: 4.00\n",
      "Episode 163 finished with a total reward of: 3.00\n",
      "Episode 164 finished with a total reward of: 4.00\n",
      "Episode 165 finished with a total reward of: 4.00\n",
      "Episode 166 finished with a total reward of: 10.00\n",
      "Episode 167 finished with a total reward of: 3.00\n",
      "Episode 168 finished with a total reward of: 4.00\n",
      "Episode 169 finished with a total reward of: 3.00\n",
      "Episode 170 finished with a total reward of: 3.00\n",
      "Episode 171 finished with a total reward of: 6.00\n",
      "Episode 172 finished with a total reward of: 9.00\n",
      "Episode 173 finished with a total reward of: 3.00\n",
      "Episode 174 finished with a total reward of: 16.00\n",
      "Episode 175 finished with a total reward of: 5.00\n",
      "Episode 176 finished with a total reward of: 11.00\n",
      "Episode 177 finished with a total reward of: 4.00\n",
      "Episode 178 finished with a total reward of: 4.00\n",
      "Episode 179 finished with a total reward of: 6.00\n",
      "Episode 180 finished with a total reward of: 5.00\n",
      "Episode 181 finished with a total reward of: 5.00\n",
      "Episode 182 finished with a total reward of: 6.00\n",
      "Episode 183 finished with a total reward of: 7.00\n",
      "Episode 184 finished with a total reward of: 9.00\n",
      "Episode 185 finished with a total reward of: 4.00\n",
      "Episode 186 finished with a total reward of: 13.00\n",
      "Episode 187 finished with a total reward of: 5.00\n",
      "Episode 188 finished with a total reward of: 18.00\n",
      "Episode 189 finished with a total reward of: 4.00\n",
      "Episode 190 finished with a total reward of: 5.00\n",
      "Episode 191 finished with a total reward of: 13.00\n",
      "Episode 192 finished with a total reward of: 5.00\n",
      "Episode 193 finished with a total reward of: 4.00\n",
      "Episode 194 finished with a total reward of: 10.00\n",
      "Episode 195 finished with a total reward of: 18.00\n",
      "Episode 196 finished with a total reward of: 11.00\n",
      "Episode 197 finished with a total reward of: 3.00\n",
      "Episode 198 finished with a total reward of: 6.00\n",
      "Episode 199 finished with a total reward of: 6.00\n",
      "Episode 200 finished with a total reward of: 4.00\n",
      "Episode 201 finished with a total reward of: 3.00\n",
      "Episode 202 finished with a total reward of: 5.00\n",
      "Episode 203 finished with a total reward of: 6.00\n",
      "Episode 204 finished with a total reward of: 15.00\n",
      "Episode 205 finished with a total reward of: 3.00\n",
      "Episode 206 finished with a total reward of: 4.00\n",
      "Episode 207 finished with a total reward of: 7.00\n",
      "Episode 208 finished with a total reward of: 3.00\n",
      "Episode 209 finished with a total reward of: 6.00\n",
      "Episode 210 finished with a total reward of: 5.00\n",
      "Episode 211 finished with a total reward of: 3.00\n",
      "Episode 212 finished with a total reward of: 5.00\n",
      "Episode 213 finished with a total reward of: 5.00\n",
      "Episode 214 finished with a total reward of: 11.00\n",
      "Episode 215 finished with a total reward of: 6.00\n",
      "Episode 216 finished with a total reward of: 8.00\n",
      "Episode 217 finished with a total reward of: 4.00\n",
      "Episode 218 finished with a total reward of: 9.00\n",
      "Episode 219 finished with a total reward of: 8.00\n",
      "Episode 220 finished with a total reward of: 10.00\n",
      "Episode 221 finished with a total reward of: 3.00\n",
      "Episode 222 finished with a total reward of: 3.00\n",
      "Episode 223 finished with a total reward of: 5.00\n",
      "Episode 224 finished with a total reward of: 11.00\n",
      "Episode 225 finished with a total reward of: 4.00\n",
      "Episode 226 finished with a total reward of: 4.00\n",
      "Episode 227 finished with a total reward of: 7.00\n",
      "Episode 228 finished with a total reward of: 4.00\n",
      "Episode 229 finished with a total reward of: 6.00\n",
      "Episode 230 finished with a total reward of: 5.00\n",
      "Episode 231 finished with a total reward of: 4.00\n",
      "Episode 232 finished with a total reward of: 3.00\n",
      "Episode 233 finished with a total reward of: 3.00\n",
      "Episode 234 finished with a total reward of: 3.00\n",
      "Episode 235 finished with a total reward of: 9.00\n",
      "Episode 236 finished with a total reward of: 3.00\n",
      "Episode 237 finished with a total reward of: 3.00\n",
      "Episode 238 finished with a total reward of: 7.00\n",
      "Episode 239 finished with a total reward of: 5.00\n",
      "Episode 240 finished with a total reward of: 5.00\n",
      "Episode 241 finished with a total reward of: 18.00\n",
      "Episode 242 finished with a total reward of: 4.00\n",
      "Episode 243 finished with a total reward of: 3.00\n",
      "Episode 244 finished with a total reward of: 6.00\n",
      "Episode 245 finished with a total reward of: 4.00\n",
      "Episode 246 finished with a total reward of: 15.00\n",
      "Episode 247 finished with a total reward of: 3.00\n",
      "Episode 248 finished with a total reward of: 3.00\n",
      "Episode 249 finished with a total reward of: 6.00\n",
      "Episode 250 finished with a total reward of: 3.00\n",
      "Episode 251 finished with a total reward of: 3.00\n",
      "Episode 252 finished with a total reward of: 8.00\n",
      "Episode 253 finished with a total reward of: 4.00\n",
      "Episode 254 finished with a total reward of: 5.00\n",
      "Episode 255 finished with a total reward of: 12.00\n",
      "Episode 256 finished with a total reward of: 4.00\n",
      "Episode 257 finished with a total reward of: 5.00\n",
      "Episode 258 finished with a total reward of: 13.00\n",
      "Episode 259 finished with a total reward of: 6.00\n",
      "Episode 260 finished with a total reward of: 3.00\n",
      "Episode 261 finished with a total reward of: 4.00\n",
      "Episode 262 finished with a total reward of: 6.00\n",
      "Episode 263 finished with a total reward of: 8.00\n",
      "Episode 264 finished with a total reward of: 9.00\n",
      "Episode 265 finished with a total reward of: 4.00\n",
      "Episode 266 finished with a total reward of: 7.00\n",
      "Episode 267 finished with a total reward of: 6.00\n",
      "Episode 268 finished with a total reward of: 9.00\n",
      "Episode 269 finished with a total reward of: 4.00\n",
      "Episode 270 finished with a total reward of: 3.00\n",
      "Episode 271 finished with a total reward of: 6.00\n",
      "Episode 272 finished with a total reward of: 3.00\n",
      "Episode 273 finished with a total reward of: 10.00\n",
      "Episode 274 finished with a total reward of: 4.00\n",
      "Episode 275 finished with a total reward of: 6.00\n",
      "Episode 276 finished with a total reward of: 3.00\n",
      "Episode 277 finished with a total reward of: 5.00\n",
      "Episode 278 finished with a total reward of: 3.00\n",
      "Episode 279 finished with a total reward of: 11.00\n",
      "Episode 280 finished with a total reward of: 3.00\n",
      "Episode 281 finished with a total reward of: 9.00\n",
      "Episode 282 finished with a total reward of: 12.00\n",
      "Episode 283 finished with a total reward of: 3.00\n",
      "Episode 284 finished with a total reward of: 3.00\n",
      "Episode 285 finished with a total reward of: 3.00\n",
      "Episode 286 finished with a total reward of: 3.00\n",
      "Episode 287 finished with a total reward of: 3.00\n",
      "Episode 288 finished with a total reward of: 8.00\n",
      "Episode 289 finished with a total reward of: 7.00\n",
      "Episode 290 finished with a total reward of: 8.00\n",
      "Episode 291 finished with a total reward of: 3.00\n",
      "Episode 292 finished with a total reward of: 4.00\n",
      "Episode 293 finished with a total reward of: 3.00\n",
      "Episode 294 finished with a total reward of: 3.00\n",
      "Episode 295 finished with a total reward of: 3.00\n",
      "Episode 296 finished with a total reward of: 13.00\n",
      "Episode 297 finished with a total reward of: 4.00\n",
      "Episode 298 finished with a total reward of: 5.00\n",
      "Episode 299 finished with a total reward of: 3.00\n",
      "Episode 300 finished with a total reward of: 3.00\n",
      "Episode 301 finished with a total reward of: 4.00\n",
      "Episode 302 finished with a total reward of: 5.00\n",
      "Episode 303 finished with a total reward of: 13.00\n",
      "Episode 304 finished with a total reward of: 4.00\n",
      "Episode 305 finished with a total reward of: 7.00\n",
      "Episode 306 finished with a total reward of: 7.00\n",
      "Episode 307 finished with a total reward of: 4.00\n",
      "Episode 308 finished with a total reward of: 3.00\n",
      "Episode 309 finished with a total reward of: 3.00\n",
      "Episode 310 finished with a total reward of: 4.00\n",
      "Episode 311 finished with a total reward of: 8.00\n",
      "Episode 312 finished with a total reward of: 3.00\n",
      "Episode 313 finished with a total reward of: 5.00\n",
      "Episode 314 finished with a total reward of: 4.00\n",
      "Episode 315 finished with a total reward of: 6.00\n",
      "Episode 316 finished with a total reward of: 3.00\n",
      "Episode 317 finished with a total reward of: 4.00\n",
      "Episode 318 finished with a total reward of: 6.00\n",
      "Episode 319 finished with a total reward of: 4.00\n",
      "Episode 320 finished with a total reward of: 5.00\n",
      "Episode 321 finished with a total reward of: 5.00\n",
      "Episode 322 finished with a total reward of: 6.00\n",
      "Episode 323 finished with a total reward of: 7.00\n",
      "Episode 324 finished with a total reward of: 6.00\n",
      "Episode 325 finished with a total reward of: 5.00\n",
      "Episode 326 finished with a total reward of: 3.00\n",
      "Episode 327 finished with a total reward of: 3.00\n",
      "Episode 328 finished with a total reward of: 11.00\n",
      "Episode 329 finished with a total reward of: 3.00\n",
      "Episode 330 finished with a total reward of: 5.00\n",
      "Episode 331 finished with a total reward of: 3.00\n",
      "\n",
      "Video recording complete. Check the 'videos_IPendulum' directory.\n"
     ]
    }
   ],
   "source": [
    "# A random agent on the InvertedPendulam environment\n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "# Create the InvertedPendulam environment with the render_mode set to \"rgb_array\" for video recording\n",
    "env = gym.make(\"InvertedPendulum-v4\", render_mode=\"rgb_array\")\n",
    "\n",
    "# Wrap the environment with the RecordVideo wrapper to save the video\n",
    "# The video will be saved in a \"videos_IPendulum\" directory\n",
    "env = RecordVideo(env, video_folder=\"videos_IPendulum\")\n",
    "\n",
    "# Reset the environment to get the initial observation\n",
    "observation, info = env.reset()\n",
    "\n",
    "# Initialize total reward for the episode and episode counter\n",
    "total_reward = 0\n",
    "episode_count = 1\n",
    "\n",
    "# Run the simulation for a total of 2000 steps\n",
    "for i in range(2000):\n",
    "    # The render method is called by the RecordVideo wrapper, so you don't need to call it manually.\n",
    "    # Taking a random action from the environment's action space\n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    # Take a step in the environment with the random action\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # Add the reward from the step to the total reward for the current episode\n",
    "    total_reward += reward\n",
    "\n",
    "    # If the episode is terminated or truncated,\n",
    "    # print the total reward for the episode and reset the environment to start a new one.\n",
    "    if terminated or truncated:\n",
    "        print(f\"Episode {episode_count} finished with a total reward of: {total_reward:.2f}\")\n",
    "        observation, info = env.reset()\n",
    "        # Reset the total reward for the next episode\n",
    "        total_reward = 0\n",
    "        episode_count += 1\n",
    "\n",
    "# Close the environment to clean up resources\n",
    "env.close()\n",
    "\n",
    "print(\"\\nVideo recording complete. Check the 'videos_IPendulum' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01afe79",
   "metadata": {},
   "source": [
    "## Crossentropy on the FrozenLake environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79188a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from dataclasses import dataclass\n",
    "import typing as tt\n",
    "import random\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "import os \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791144e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 100\n",
    "PERCENTILE = 30\n",
    "GAMMA = 0.9\n",
    "MODEL_PATH = \"frozenlake_crossentropy.pth\" \n",
    "VIDEO_TEST_FOLDER = \"videos_flake_crossentropy\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2390da4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteOneHotWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env: gym.Env):\n",
    "        super(DiscreteOneHotWrapper, self).__init__(env)\n",
    "        assert isinstance(env.observation_space,gym.spaces.Discrete)\n",
    "        shape = (env.observation_space.n, )\n",
    "        self.observation_space = gym.spaces.Box(0.0, 1.0, shape, dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        res = np.copy(self.observation_space.low)\n",
    "        res[observation] = 1.0\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd36c8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, obs_size: int, hidden_size: int,\n",
    "                 n_actions: int):\n",
    "        super(Net, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c96a9ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EpisodeStep:\n",
    "    observation: np.ndarray\n",
    "    action: int\n",
    "\n",
    "@dataclass\n",
    "class Episode:\n",
    "    reward: float\n",
    "    steps: tt.List[EpisodeStep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3661223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_batches(env: gym.Env, net: Net, batch_size: int) -> \\\n",
    "        tt.Generator[tt.List[Episode], None, None]:\n",
    "    batch = []\n",
    "    episode_reward = 0.0\n",
    "    episode_steps = []\n",
    "    obs, info = env.reset() \n",
    "    sm = nn.Softmax(dim=1)\n",
    "    while True:\n",
    "        obs_v = torch.tensor(obs, dtype=torch.float32)\n",
    "        act_probs_v = sm(net(obs_v.unsqueeze(0)))\n",
    "        act_probs = act_probs_v.data.numpy()[0]\n",
    "        action = np.random.choice(len(act_probs), p=act_probs)\n",
    "        next_obs, reward, is_done, is_trunc, _ = env.step(action)\n",
    "        episode_reward += float(reward)\n",
    "        step = EpisodeStep(observation=obs, action=action)\n",
    "        episode_steps.append(step)\n",
    "        if is_done or is_trunc:\n",
    "            e = Episode(reward=episode_reward, steps=episode_steps)\n",
    "            batch.append(e)\n",
    "            episode_reward = 0.0\n",
    "            episode_steps = []\n",
    "            next_obs, _ = env.reset() \n",
    "            if len(batch) == batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "        obs = next_obs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bf497af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_batch(batch: tt.List[Episode], percentile: float) -> tt.Tuple[tt.List[Episode], tt.List[np.ndarray],tt.List[int], float]:\n",
    "    reward_fun = lambda s: s.reward * (GAMMA ** len(s.steps))\n",
    "    disc_rewards = list(map(reward_fun, batch))\n",
    "    reward_bound = np.percentile(disc_rewards, percentile)\n",
    "\n",
    "    train_obs: tt.List[np.ndarray] = []\n",
    "    train_act: tt.List[int] = []\n",
    "    elite_batch: tt.List[Episode] = []\n",
    "\n",
    "    for example, discounted_reward in zip(batch, disc_rewards):\n",
    "        if discounted_reward > reward_bound:\n",
    "            train_obs.extend(map(lambda step: step.observation,example.steps))\n",
    "            train_act.extend(map(lambda step: step.action,example.steps))\n",
    "            elite_batch.append(example)\n",
    "\n",
    "    return elite_batch, train_obs, train_act, reward_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ace452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_and_record(model: Net, env_name: str, num_test_episodes: int = 5, video_folder: str = VIDEO_TEST_FOLDER):\n",
    "    print(f\"\\nTesting model for {num_test_episodes} episodes...\")\n",
    "    os.makedirs(video_folder, exist_ok=True)\n",
    "\n",
    "    test_env = gym.make(env_name, is_slippery=False, render_mode=\"rgb_array\")\n",
    "    test_env = DiscreteOneHotWrapper(test_env)\n",
    "    test_env = gym.wrappers.RecordVideo(\n",
    "        test_env,\n",
    "        video_folder=video_folder,\n",
    "        episode_trigger=lambda episode_id: True,\n",
    "        name_prefix=\"test_episode\" \n",
    "    )\n",
    "\n",
    "    model.eval() \n",
    "    sm = nn.Softmax(dim=1)\n",
    "    total_rewards = []\n",
    "\n",
    "    for i in range(num_test_episodes):\n",
    "        obs, _ = test_env.reset() \n",
    "        episode_reward = 0.0\n",
    "        done = False\n",
    "        truncated = False\n",
    "        while not done and not truncated:\n",
    "            obs_v = torch.tensor(obs, dtype=torch.float32).unsqueeze(0)\n",
    "            act_probs_v = sm(model(obs_v))\n",
    "            action = torch.argmax(act_probs_v).item() # Choose action with highest probability\n",
    "            obs, reward, done, truncated, _ = test_env.step(action)\n",
    "            episode_reward += reward\n",
    "        total_rewards.append(episode_reward)\n",
    "        print(f\"Test Episode {i+1}: Reward = {episode_reward}\")\n",
    "\n",
    "    test_env.close()\n",
    "    mean_reward = np.mean(total_rewards)\n",
    "    print(f\"Mean test reward over {num_test_episodes} episodes: {mean_reward:.3f}\")\n",
    "    return mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d063fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "0: loss=1.298, rw_mean=0.010, rw_bound=0.000, batch=1\n",
      "1: loss=1.311, rw_mean=0.010, rw_bound=0.000, batch=2\n",
      "2: loss=1.316, rw_mean=0.020, rw_bound=0.000, batch=4\n",
      "3: loss=1.318, rw_mean=0.020, rw_bound=0.000, batch=6\n",
      "4: loss=1.317, rw_mean=0.010, rw_bound=0.000, batch=7\n",
      "5: loss=1.311, rw_mean=0.000, rw_bound=0.000, batch=7\n",
      "6: loss=1.307, rw_mean=0.010, rw_bound=0.000, batch=8\n",
      "7: loss=1.308, rw_mean=0.060, rw_bound=0.000, batch=14\n",
      "8: loss=1.307, rw_mean=0.010, rw_bound=0.000, batch=15\n",
      "9: loss=1.302, rw_mean=0.030, rw_bound=0.000, batch=18\n",
      "10: loss=1.296, rw_mean=0.050, rw_bound=0.000, batch=23\n",
      "11: loss=1.289, rw_mean=0.010, rw_bound=0.000, batch=24\n",
      "12: loss=1.287, rw_mean=0.010, rw_bound=0.000, batch=25\n",
      "13: loss=1.279, rw_mean=0.010, rw_bound=0.000, batch=26\n",
      "14: loss=1.276, rw_mean=0.030, rw_bound=0.000, batch=29\n",
      "15: loss=1.269, rw_mean=0.050, rw_bound=0.000, batch=34\n",
      "16: loss=1.265, rw_mean=0.020, rw_bound=0.000, batch=36\n",
      "17: loss=1.259, rw_mean=0.030, rw_bound=0.000, batch=39\n",
      "18: loss=1.252, rw_mean=0.080, rw_bound=0.000, batch=47\n",
      "19: loss=1.254, rw_mean=0.100, rw_bound=0.000, batch=57\n",
      "20: loss=1.247, rw_mean=0.050, rw_bound=0.000, batch=62\n",
      "21: loss=1.243, rw_mean=0.020, rw_bound=0.000, batch=64\n",
      "22: loss=1.235, rw_mean=0.060, rw_bound=0.000, batch=70\n",
      "23: loss=1.233, rw_mean=0.070, rw_bound=0.000, batch=77\n",
      "24: loss=1.231, rw_mean=0.050, rw_bound=0.000, batch=82\n",
      "25: loss=1.231, rw_mean=0.090, rw_bound=0.000, batch=91\n",
      "26: loss=1.225, rw_mean=0.060, rw_bound=0.000, batch=97\n",
      "27: loss=1.223, rw_mean=0.070, rw_bound=0.000, batch=104\n",
      "28: loss=1.220, rw_mean=0.040, rw_bound=0.000, batch=108\n",
      "29: loss=1.219, rw_mean=0.080, rw_bound=0.000, batch=116\n",
      "30: loss=1.216, rw_mean=0.080, rw_bound=0.000, batch=124\n",
      "31: loss=1.211, rw_mean=0.040, rw_bound=0.000, batch=128\n",
      "32: loss=1.207, rw_mean=0.090, rw_bound=0.000, batch=137\n",
      "33: loss=1.200, rw_mean=0.100, rw_bound=0.000, batch=147\n",
      "34: loss=1.195, rw_mean=0.080, rw_bound=0.000, batch=155\n",
      "35: loss=1.189, rw_mean=0.070, rw_bound=0.000, batch=162\n",
      "36: loss=1.182, rw_mean=0.070, rw_bound=0.000, batch=169\n",
      "37: loss=1.177, rw_mean=0.100, rw_bound=0.000, batch=179\n",
      "38: loss=1.170, rw_mean=0.100, rw_bound=0.000, batch=189\n",
      "39: loss=1.169, rw_mean=0.070, rw_bound=0.000, batch=196\n",
      "40: loss=1.166, rw_mean=0.050, rw_bound=0.000, batch=201\n",
      "41: loss=1.142, rw_mean=0.150, rw_bound=0.122, batch=208\n",
      "42: loss=1.136, rw_mean=0.100, rw_bound=0.152, batch=215\n",
      "43: loss=1.113, rw_mean=0.150, rw_bound=0.206, batch=215\n",
      "44: loss=1.093, rw_mean=0.100, rw_bound=0.229, batch=209\n",
      "45: loss=1.086, rw_mean=0.110, rw_bound=0.239, batch=216\n",
      "46: loss=1.067, rw_mean=0.080, rw_bound=0.254, batch=204\n",
      "47: loss=1.062, rw_mean=0.080, rw_bound=0.000, batch=212\n",
      "48: loss=1.056, rw_mean=0.080, rw_bound=0.206, batch=217\n",
      "49: loss=1.027, rw_mean=0.150, rw_bound=0.282, batch=206\n",
      "50: loss=1.023, rw_mean=0.120, rw_bound=0.298, batch=214\n",
      "51: loss=1.000, rw_mean=0.120, rw_bound=0.314, batch=199\n",
      "52: loss=0.991, rw_mean=0.190, rw_bound=0.328, batch=209\n",
      "53: loss=0.948, rw_mean=0.190, rw_bound=0.349, batch=184\n",
      "54: loss=0.956, rw_mean=0.140, rw_bound=0.000, batch=198\n",
      "55: loss=0.936, rw_mean=0.180, rw_bound=0.286, batch=208\n",
      "56: loss=0.894, rw_mean=0.230, rw_bound=0.387, batch=175\n",
      "57: loss=0.900, rw_mean=0.140, rw_bound=0.000, batch=189\n",
      "58: loss=0.881, rw_mean=0.320, rw_bound=0.349, batch=201\n",
      "59: loss=0.866, rw_mean=0.170, rw_bound=0.387, batch=204\n",
      "60: loss=0.789, rw_mean=0.260, rw_bound=0.430, batch=136\n",
      "61: loss=0.818, rw_mean=0.240, rw_bound=0.000, batch=160\n",
      "62: loss=0.830, rw_mean=0.230, rw_bound=0.156, batch=182\n",
      "63: loss=0.835, rw_mean=0.110, rw_bound=0.000, batch=193\n",
      "64: loss=0.821, rw_mean=0.170, rw_bound=0.244, batch=205\n",
      "65: loss=0.788, rw_mean=0.210, rw_bound=0.314, batch=212\n",
      "66: loss=0.744, rw_mean=0.270, rw_bound=0.387, batch=206\n",
      "67: loss=0.720, rw_mean=0.290, rw_bound=0.430, batch=199\n",
      "68: loss=0.640, rw_mean=0.340, rw_bound=0.478, batch=121\n",
      "69: loss=0.695, rw_mean=0.240, rw_bound=0.000, batch=145\n",
      "70: loss=0.673, rw_mean=0.300, rw_bound=0.282, batch=168\n",
      "71: loss=0.671, rw_mean=0.300, rw_bound=0.349, batch=185\n",
      "72: loss=0.643, rw_mean=0.330, rw_bound=0.387, batch=197\n",
      "73: loss=0.610, rw_mean=0.270, rw_bound=0.430, batch=197\n",
      "74: loss=0.572, rw_mean=0.250, rw_bound=0.478, batch=173\n",
      "75: loss=0.559, rw_mean=0.420, rw_bound=0.478, batch=189\n",
      "76: loss=0.551, rw_mean=0.330, rw_bound=0.450, batch=202\n",
      "77: loss=0.537, rw_mean=0.330, rw_bound=0.478, batch=210\n",
      "79: loss=0.819, rw_mean=0.390, rw_bound=0.000, batch=39\n",
      "80: loss=0.793, rw_mean=0.300, rw_bound=0.000, batch=69\n",
      "81: loss=0.763, rw_mean=0.320, rw_bound=0.000, batch=101\n",
      "82: loss=0.739, rw_mean=0.280, rw_bound=0.000, batch=129\n",
      "83: loss=0.665, rw_mean=0.430, rw_bound=0.349, batch=152\n",
      "84: loss=0.556, rw_mean=0.380, rw_bound=0.430, batch=131\n",
      "85: loss=0.573, rw_mean=0.340, rw_bound=0.387, batch=160\n",
      "86: loss=0.546, rw_mean=0.450, rw_bound=0.430, batch=176\n",
      "87: loss=0.460, rw_mean=0.440, rw_bound=0.478, batch=124\n",
      "88: loss=0.477, rw_mean=0.420, rw_bound=0.387, batch=154\n",
      "89: loss=0.443, rw_mean=0.490, rw_bound=0.478, batch=165\n",
      "91: loss=0.636, rw_mean=0.510, rw_bound=0.000, batch=51\n",
      "92: loss=0.601, rw_mean=0.570, rw_bound=0.349, batch=99\n",
      "93: loss=0.605, rw_mean=0.420, rw_bound=0.343, batch=139\n",
      "94: loss=0.492, rw_mean=0.490, rw_bound=0.430, batch=140\n",
      "95: loss=0.408, rw_mean=0.540, rw_bound=0.478, batch=115\n",
      "96: loss=0.404, rw_mean=0.540, rw_bound=0.478, batch=143\n",
      "98: loss=0.609, rw_mean=0.490, rw_bound=0.000, batch=49\n",
      "99: loss=0.497, rw_mean=0.610, rw_bound=0.387, batch=95\n",
      "100: loss=0.469, rw_mean=0.510, rw_bound=0.430, batch=118\n",
      "101: loss=0.372, rw_mean=0.630, rw_bound=0.478, batch=115\n",
      "102: loss=0.366, rw_mean=0.610, rw_bound=0.478, batch=146\n",
      "104: loss=0.585, rw_mean=0.560, rw_bound=0.000, batch=56\n",
      "105: loss=0.539, rw_mean=0.590, rw_bound=0.368, batch=109\n",
      "106: loss=0.415, rw_mean=0.630, rw_bound=0.430, batch=137\n",
      "107: loss=0.346, rw_mean=0.580, rw_bound=0.478, batch=136\n",
      "109: loss=0.544, rw_mean=0.580, rw_bound=0.000, batch=58\n",
      "110: loss=0.475, rw_mean=0.600, rw_bound=0.387, batch=108\n",
      "111: loss=0.428, rw_mean=0.570, rw_bound=0.430, batch=144\n",
      "112: loss=0.321, rw_mean=0.610, rw_bound=0.478, batch=137\n",
      "114: loss=0.478, rw_mean=0.700, rw_bound=0.244, batch=70\n",
      "115: loss=0.318, rw_mean=0.750, rw_bound=0.478, batch=94\n",
      "116: loss=0.313, rw_mean=0.700, rw_bound=0.478, batch=127\n",
      "118: loss=0.467, rw_mean=0.750, rw_bound=0.387, batch=69\n",
      "119: loss=0.387, rw_mean=0.610, rw_bound=0.430, batch=110\n",
      "120: loss=0.297, rw_mean=0.540, rw_bound=0.478, batch=110\n",
      "122: loss=0.489, rw_mean=0.690, rw_bound=0.000, batch=69\n",
      "123: loss=0.353, rw_mean=0.670, rw_bound=0.430, batch=110\n",
      "124: loss=0.290, rw_mean=0.750, rw_bound=0.478, batch=134\n",
      "126: loss=0.387, rw_mean=0.770, rw_bound=0.430, batch=64\n",
      "127: loss=0.271, rw_mean=0.710, rw_bound=0.478, batch=94\n",
      "129: loss=0.401, rw_mean=0.680, rw_bound=0.000, batch=68\n",
      "130: loss=0.261, rw_mean=0.810, rw_bound=0.478, batch=101\n",
      "Solved!\n",
      "Trained model saved to frozenlake_crossentropy.pth\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    random.seed(12345)\n",
    "    \n",
    "    # --- Training Phase ---\n",
    "    print(\"Starting training...\")\n",
    "    # Create the environment and wrap it for one-hot encoding\n",
    "    train_env = gym.make(\"FrozenLake-v1\", is_slippery=False, render_mode=\"rgb_array\")\n",
    "    train_env = DiscreteOneHotWrapper(train_env)\n",
    "    \n",
    "    obs_size = train_env.observation_space.shape[0]\n",
    "    n_actions = train_env.action_space.n\n",
    "\n",
    "    net = Net(obs_size, HIDDEN_SIZE, n_actions)\n",
    "    objective = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(params=net.parameters(), lr=0.001)\n",
    "    writer = SummaryWriter(comment=\"-frozenlake-nonslippery\")\n",
    "\n",
    "    full_batch = []\n",
    "    # Pass the RecordVideo wrapped environment to iterate_batches\n",
    "    for iter_no, batch in enumerate(iterate_batches(train_env, net, BATCH_SIZE)):\n",
    "        reward_mean = float(np.mean(list(map(lambda s: s.reward, batch))))\n",
    "        full_batch, obs, acts, reward_bound = filter_batch(full_batch + batch, PERCENTILE)\n",
    "        if not full_batch:\n",
    "            continue\n",
    "        obs_v = torch.FloatTensor(np.vstack(obs))\n",
    "        acts_v = torch.LongTensor(acts)\n",
    "        full_batch = full_batch[-500:]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        action_scores_v = net(obs_v)\n",
    "        loss_v = objective(action_scores_v, acts_v)\n",
    "        loss_v.backward()\n",
    "        optimizer.step()\n",
    "        print(\"%d: loss=%.3f, rw_mean=%.3f, \"\"rw_bound=%.3f, batch=%d\" % (iter_no, loss_v.item(), reward_mean,reward_bound, len(full_batch)))\n",
    "        writer.add_scalar(\"loss\", loss_v.item(), iter_no)\n",
    "        writer.add_scalar(\"reward_mean\", reward_mean, iter_no)\n",
    "        writer.add_scalar(\"reward_bound\", reward_bound, iter_no)\n",
    "        if reward_mean > 0.8:\n",
    "            print(\"Solved!\")\n",
    "            break\n",
    "    writer.close()\n",
    "    train_env.close() \n",
    "\n",
    "    # --- Save the trained model ---\n",
    "    torch.save(net.state_dict(), MODEL_PATH)\n",
    "    print(f\"Trained model saved to {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "445f798b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting testing phase...\n",
      "\n",
      "Testing model for 5 episodes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\.venv\\Lib\\site-packages\\gymnasium\\wrappers\\rendering.py:296: UserWarning: \u001b[33mWARN: Overwriting existing videos at c:\\Users\\User\\Desktop\\VS_Code_Projects\\Reinforcement_learning\\videos_flake_crossentropy folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Episode 1: Reward = 1.0\n",
      "Test Episode 2: Reward = 1.0\n",
      "Test Episode 3: Reward = 1.0\n",
      "Test Episode 4: Reward = 1.0\n",
      "Test Episode 5: Reward = 1.0\n",
      "Mean test reward over 5 episodes: 1.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Testing Phase ---\n",
    "print(\"\\nStarting testing phase...\")\n",
    "# Load the trained model\n",
    "loaded_net = Net(obs_size, HIDDEN_SIZE, n_actions)\n",
    "loaded_net.load_state_dict(torch.load(MODEL_PATH))\n",
    "    \n",
    "# Test the loaded model and record videos\n",
    "test_model_and_record(loaded_net, \"FrozenLake-v1\", num_test_episodes=5, video_folder=VIDEO_TEST_FOLDER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
